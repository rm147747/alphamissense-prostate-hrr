{"cells": [{"cell_type": "markdown", "id": "52036dff", "metadata": {}, "source": ["# üìä Notebook 2 ‚Äî Statistical Analysis & Publication Figures\n", "\n", "## AlphaMissense-Guided VUS Reclassification in HRR Genes for Prostate Cancer\n", "\n", "**Inputs from Notebook 1:**\n", "- `results/annotated_hrr_variants.csv` ‚Äî HRR missense variants with AlphaMissense scores\n", "- `results/patient_hrr_summary.csv` ‚Äî Patient-level summary\n", "- `data/raw/clinical_patient.csv` / `clinical_sample.csv` ‚Äî Survival & clinical data\n", "- `data/processed/alphamissense_hrr_genes.csv` ‚Äî AlphaMissense lookup for HRR genes\n", "- `data/processed/clinvar_hrr.csv` ‚Äî ClinVar classifications (if available)\n", "\n", "**Analyses:**\n", "1. Descriptive summary & AlphaMissense score distribution\n", "2. ClinVar concordance (Cohen's kappa, sensitivity/specificity)\n", "3. VUS reclassification yield\n", "4. Survival analysis (Cox PH + Kaplan-Meier)\n", "5. Sensitivity analyses (threshold, E-value, gene exclusion)\n", "6. Publication-ready figures (Fig 1‚Äì5)\n", "\n", "**Reporting:** REMARK guidelines + STROBE checklist\n"]}, {"cell_type": "markdown", "id": "b0646247", "metadata": {}, "source": ["## 1. Setup & Load Data"]}, {"cell_type": "code", "execution_count": 3, "id": "6c0abf8b", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["‚úÖ Setup complete\n"]}], "source": ["# REPRODUCIBILITY: Install dependencies via `pip install -r requirements.txt`\n# Do NOT pip-install inside the notebook ‚Äî use pinned versions from requirements.txt\n"]}, {"cell_type": "code", "execution_count": 4, "id": "b32c9728", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["üìÇ Variants loaded: 52 rows, 40 patients\n", "üìÇ Patient summary: 40 patients with HRR missense\n", "üìÇ Clinical: 15949 patients, 8854 samples\n", "üìÇ AlphaMissense HRR lookup: 554,363 predictions\n", "üìÇ ClinVar HRR: 193,148 entries\n", "\n", "============================================================\n", "QUICK DATA SANITY CHECK\n", "============================================================\n", "  Variants with AM score: 51/52 (98.1%)\n", "  AM class distribution:\n", "    benign: 31\n", "    pathogenic: 19\n", "    ambiguous: 1\n"]}], "source": ["# ============================================================\n", "# 2. LOAD ALL DATA FROM NOTEBOOK 1\n", "# ============================================================\n", "\n", "# --- Variant-level data ---\n", "df_var = pd.read_csv(RESULTS_DIR / \"annotated_hrr_variants.csv\")\n", "print(f\"üìÇ Variants loaded: {len(df_var)} rows, {df_var['sample_id'].nunique()} patients\")\n", "\n", "# --- Patient summary ---\n", "df_pat = pd.read_csv(RESULTS_DIR / \"patient_hrr_summary.csv\")\n", "print(f\"üìÇ Patient summary: {len(df_pat)} patients with HRR missense\")\n", "\n", "# --- Clinical data ---\n", "df_clin_patient = pd.read_csv(DATA_DIR / \"raw\" / \"clinical_patient.csv\")\n", "df_clin_sample = pd.read_csv(DATA_DIR / \"raw\" / \"clinical_sample.csv\")\n", "print(f\"üìÇ Clinical: {len(df_clin_patient)} patients, {len(df_clin_sample)} samples\")\n", "\n", "# --- AlphaMissense full lookup ---\n", "am_path = DATA_DIR / \"processed\" / \"alphamissense_hrr_genes.csv\"\n", "if am_path.exists():\n", "    df_am_full = pd.read_csv(am_path)\n", "    print(f\"üìÇ AlphaMissense HRR lookup: {len(df_am_full):,} predictions\")\n", "else:\n", "    df_am_full = pd.DataFrame()\n", "    print(\"‚ö†Ô∏è  AlphaMissense lookup not found ‚Äî concordance limited\")\n", "\n", "# --- ClinVar ---\n", "cv_path = DATA_DIR / \"processed\" / \"clinvar_hrr.csv\"\n", "if cv_path.exists():\n", "    df_clinvar = pd.read_csv(cv_path)\n", "    print(f\"üìÇ ClinVar HRR: {len(df_clinvar):,} entries\")\n", "else:\n", "    df_clinvar = pd.DataFrame()\n", "    print(\"‚ö†Ô∏è  ClinVar file not found ‚Äî will attempt alternative load\")\n", "    # Try the raw variant_summary if processed doesn't exist\n", "    raw_cv = DATA_DIR / \"raw\" / \"variant_summary.txt.gz\"\n", "    if raw_cv.exists():\n", "        print(\"   Found raw ClinVar ‚Äî will parse in concordance section\")\n", "\n", "# Quick sanity\n", "print(f\"\\n{'='*60}\")\n", "print(\"QUICK DATA SANITY CHECK\")\n", "print(f\"{'='*60}\")\n", "n_am = df_var[\"am_pathogenicity\"].notna().sum()\n", "print(f\"  Variants with AM score: {n_am}/{len(df_var)} ({100*n_am/len(df_var):.1f}%)\")\n", "if \"am_class\" in df_var.columns:\n", "    print(f\"  AM class distribution:\")\n", "    for c, n in df_var[\"am_class\"].value_counts().items():\n", "        print(f\"    {c}: {n}\")\n"]}, {"cell_type": "markdown", "id": "49fa01fd", "metadata": {}, "source": ["## 2. Descriptive Statistics\n", "\n", "### 2A. Variant-Level Summary\n", "### 2B. Patient-Level Table 1\n"]}, {"cell_type": "code", "execution_count": 5, "id": "5338d485", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["============================================================\n", "VARIANT-LEVEL DESCRIPTIVE SUMMARY\n", "============================================================\n", "\n", "Missense variants by HRR gene:\n", "  gene  n_variants  n_patients  mean_am  median_am  n_pathogenic  n_benign  n_ambiguous cohort\n", "   ATM          15          15 0.641073    0.70650            10         5            0      A\n", " BRCA2           3           3 0.160633    0.15260             0         3            0      A\n", " BRCA1           1           1 0.193600    0.19360             0         1            0      A\n", " CDK12           5           5 0.647580    0.99880             3         2            0      B\n", " BARD1           4           4 0.100650    0.09265             0         4            0      B\n", " PALB2           3           3 0.079900    0.07590             0         3            0      B\n", "RAD51B           3           2 0.228967    0.11690             0         2            1      B\n", " BRIP1           2           2 0.143450    0.14345             0         2            0      B\n", "RAD54L           2           2 0.319900    0.31990             1         1            0      B\n", " FANCL           1           1 0.640800    0.64080             1         0            0      B\n", "RAD51D           1           1      NaN        NaN             0         0            0      B\n", "  ATRX           3           3 0.855333    0.88870             3         0            0    Ext\n", "   ATR           2           2 0.108250    0.10825             0         2            0    Ext\n", "   NBN           2           2 0.184450    0.18445             0         2            0    Ext\n", " FANCC           1           1 0.109100    0.10910             0         1            0    Ext\n", "FANCD2           1           1 0.152400    0.15240             0         1            0    Ext\n", " FANCF           1           1 0.098800    0.09880             0         1            0    Ext\n", " FANCG           1           1 0.802100    0.80210             1         0            0    Ext\n", " RAD50           1           1 0.147200    0.14720             0         1            0    Ext\n", "\n", "AlphaMissense score distribution (n=51):\n", "  Mean ¬± SD: 0.410 ¬± 0.365\n", "  Median [IQR]: 0.194 [0.103‚Äì0.754]\n", "  Range: 0.0569 ‚Äì 0.9999\n"]}], "source": ["# ============================================================\n", "# 3. DESCRIPTIVE ‚Äî VARIANT-LEVEL\n", "# ============================================================\n", "\n", "print(\"=\" * 60)\n", "print(\"VARIANT-LEVEL DESCRIPTIVE SUMMARY\")\n", "print(\"=\" * 60)\n", "\n", "# Total missense by gene\n", "gene_summary = df_var.groupby(\"gene\").agg(\n", "    n_variants=(\"sample_id\", \"count\"),\n", "    n_patients=(\"sample_id\", \"nunique\"),\n", "    mean_am=(\"am_pathogenicity\", \"mean\"),\n", "    median_am=(\"am_pathogenicity\", \"median\"),\n", "    n_pathogenic=(\"am_class\", lambda x: (x == \"pathogenic\").sum()),\n", "    n_benign=(\"am_class\", lambda x: (x == \"benign\").sum()),\n", "    n_ambiguous=(\"am_class\", lambda x: (x == \"ambiguous\").sum()),\n", ").reset_index()\n", "\n", "gene_summary[\"cohort\"] = gene_summary[\"gene\"].apply(\n", "    lambda g: \"A\" if g in COHORT_A_GENES else (\"B\" if g in COHORT_B_GENES else \"Ext\")\n", ")\n", "gene_summary = gene_summary.sort_values([\"cohort\", \"n_variants\"], ascending=[True, False])\n", "\n", "print(\"\\nMissense variants by HRR gene:\")\n", "print(gene_summary.to_string(index=False))\n", "gene_summary.to_csv(RESULTS_DIR / \"table_gene_summary.csv\", index=False)\n", "\n", "# Score distribution stats\n", "am_scores = df_var[\"am_pathogenicity\"].dropna()\n", "print(f\"\\nAlphaMissense score distribution (n={len(am_scores)}):\")\n", "print(f\"  Mean ¬± SD: {am_scores.mean():.3f} ¬± {am_scores.std():.3f}\")\n", "print(f\"  Median [IQR]: {am_scores.median():.3f} [{am_scores.quantile(0.25):.3f}‚Äì{am_scores.quantile(0.75):.3f}]\")\n", "print(f\"  Range: {am_scores.min():.4f} ‚Äì {am_scores.max():.4f}\")\n"]}, {"cell_type": "code", "execution_count": 6, "id": "24921f8c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Available clinical columns: ['uniquePatientKey', 'patientId', 'studyId', 'clinicalAttributeId', 'value']\n", "Using patient ID column: 'patientId'\n", "\n", "‚úÖ Merged: 1299 patients with clinical data\n", "Survival-related columns found: []\n", "Demographic/clinical columns found: []\n"]}], "source": ["# ============================================================\n", "# 3B. PATIENT-LEVEL DESCRIPTIVE ‚Äî BUILD TABLE 1\n", "# ============================================================\n", "\n", "# Merge patient summary with clinical data\n", "# Detect clinical column names (vary between API/datahub format)\n", "clin_cols = df_clin_patient.columns.tolist()\n", "print(f\"Available clinical columns: {clin_cols}\")\n", "\n", "# Find the patient ID column\n", "pid_col = None\n", "for candidate in [\"PATIENT_ID\", \"patientId\", \"Patient ID\"]:\n", "    if candidate in clin_cols:\n", "        pid_col = candidate\n", "        break\n", "\n", "if pid_col is None:\n", "    print(\"‚ö†Ô∏è  Could not find patient ID column. Available:\", clin_cols[:10])\n", "    pid_col = clin_cols[0]  # fallback\n", "\n", "print(f\"Using patient ID column: '{pid_col}'\")\n", "\n", "# Extract patient ID from sample ID (TCGA format: TCGA-XX-XXXX-01 ‚Üí TCGA-XX-XXXX)\n", "df_pat[\"patient_id\"] = df_pat[\"sample_id\"].str.extract(r\"(TCGA-[A-Z0-9]+-[A-Z0-9]+)\")\n", "\n", "# Merge\n", "df_analysis = df_pat.merge(\n", "    df_clin_patient,\n", "    left_on=\"patient_id\",\n", "    right_on=pid_col,\n", "    how=\"left\"\n", ")\n", "\n", "print(f\"\\n‚úÖ Merged: {len(df_analysis)} patients with clinical data\")\n", "\n", "# Identify key clinical columns\n", "# Look for survival columns\n", "survival_cols = [c for c in df_analysis.columns if any(\n", "    k in c.upper() for k in [\"OS_\", \"DFS_\", \"PFS_\", \"SURVIVAL\", \"STATUS\", \"MONTHS\"]\n", ")]\n", "print(f\"Survival-related columns found: {survival_cols}\")\n", "\n", "# Look for age, Gleason, stage\n", "demo_cols = [c for c in df_analysis.columns if any(\n", "    k in c.upper() for k in [\"AGE\", \"GLEASON\", \"STAGE\", \"GRADE\", \"PSA\", \"T_STAGE\", \"N_STAGE\", \"M_STAGE\"]\n", ")]\n", "print(f\"Demographic/clinical columns found: {demo_cols}\")\n"]}, {"cell_type": "code", "execution_count": 7, "id": "a2e8fdce", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Pivoting clinical data from long ‚Üí wide format...\n", "  Pivoted: 494 patients √ó 37 attributes\n", "  Available attributes: ['AGE', 'BUFFA_HYPOXIA_SCORE', 'CANCER_TYPE_ACRONYM', 'DAYS_LAST_FOLLOWUP', 'DAYS_TO_BIRTH', 'DAYS_TO_INITIAL_PATHOLOGIC_DIAGNOSIS', 'DFS_MONTHS', 'DFS_STATUS', 'DSS_MONTHS', 'DSS_STATUS', 'ETHNICITY', 'FORM_COMPLETION_DATE', 'GENETIC_ANCESTRY_LABEL', 'HISTORY_NEOADJUVANT_TRTYN', 'ICD_10', 'ICD_O_3_HISTOLOGY', 'ICD_O_3_SITE', 'INFORMED_CONSENT_VERIFIED', 'IN_PANCANPATHWAYS_FREEZE', 'NEW_TUMOR_EVENT_AFTER_INITIAL_TREATMENT', 'OS_MONTHS', 'OS_STATUS', 'OTHER_PATIENT_ID', 'PATH_N_STAGE', 'PATH_T_STAGE', 'PERSON_NEOPLASM_CANCER_STATUS', 'PFS_MONTHS', 'PFS_STATUS', 'PRIOR_DX', 'RACE', 'RADIATION_THERAPY', 'RAGNUM_HYPOXIA_SCORE', 'SAMPLE_COUNT', 'SEX', 'SUBTYPE', 'WINTER_HYPOXIA_SCORE', 'patientId']\n", "  After merging sample attributes: 55 total columns\n", "\n", "‚úÖ Merged: 40 patients with clinical data\n", "\n", "Patient groups:\n", "am_group\n", "AM-Benign/Ambiguous only            21\n", "AM-Pathogenic (‚â•1 path. variant)    19\n", "Name: count, dtype: int64\n", "\n", "Survival columns: time='OS_MONTHS', status='OS_STATUS'\n", "Survival data: 40/40 patients\n", "  Events (deaths): 1\n", "  Median follow-up: 32.5 months\n", "\n", "üíæ Saved: results/analysis_dataset.csv\n", "  Columns: 71\n"]}], "source": ["# ============================================================\n", "# 3C. PIVOT CLINICAL DATA & CREATE ANALYSIS GROUPS\n", "# ============================================================\n", "\n", "# The cBioPortal API returns clinical data in LONG format:\n", "#   patientId | clinicalAttributeId | value\n", "# We need to pivot to WIDE format (one row per patient)\n", "\n", "print(\"Pivoting clinical data from long ‚Üí wide format...\")\n", "\n", "if \"clinicalAttributeId\" in df_clin_patient.columns and \"value\" in df_clin_patient.columns:\n", "    df_clin_wide = df_clin_patient.pivot_table(\n", "        index=\"patientId\",\n", "        columns=\"clinicalAttributeId\",\n", "        values=\"value\",\n", "        aggfunc=\"first\"\n", "    ).reset_index()\n", "    print(f\"  Pivoted: {len(df_clin_wide)} patients √ó {len(df_clin_wide.columns)} attributes\")\n", "    print(f\"  Available attributes: {sorted(df_clin_wide.columns.tolist())}\")\n", "else:\n", "    # Already in wide format\n", "    df_clin_wide = df_clin_patient.copy()\n", "    print(f\"  Already wide: {len(df_clin_wide)} patients\")\n", "\n", "# Also pivot sample-level if needed\n", "if \"clinicalAttributeId\" in df_clin_sample.columns:\n", "    df_sample_wide = df_clin_sample.pivot_table(\n", "        index=\"sampleId\",\n", "        columns=\"clinicalAttributeId\",\n", "        values=\"value\",\n", "        aggfunc=\"first\"\n", "    ).reset_index()\n", "    # Merge sample-level attributes (TMB, etc.) into patient table\n", "    # Use first sample per patient\n", "    df_sample_wide[\"patientId\"] = df_sample_wide[\"sampleId\"].str.extract(r\"(TCGA-[A-Z0-9]+-[A-Z0-9]+)\")\n", "    sample_attrs = df_sample_wide.drop(columns=[\"sampleId\"]).groupby(\"patientId\").first().reset_index()\n", "    df_clin_wide = df_clin_wide.merge(sample_attrs, on=\"patientId\", how=\"left\", suffixes=(\"\", \"_sample\"))\n", "    print(f\"  After merging sample attributes: {len(df_clin_wide.columns)} total columns\")\n", "\n", "# Extract patient ID from sample_id\n", "df_pat[\"patient_id\"] = df_pat[\"sample_id\"].str.extract(r\"(TCGA-[A-Z0-9]+-[A-Z0-9]+)\")\n", "\n", "# Merge\n", "df_analysis = df_pat.merge(df_clin_wide, left_on=\"patient_id\", right_on=\"patientId\", how=\"left\")\n", "print(f\"\\n‚úÖ Merged: {len(df_analysis)} patients with clinical data\")\n", "\n", "# Define AM groups\n", "if \"has_am_pathogenic\" not in df_analysis.columns:\n", "    if \"n_am_pathogenic\" in df_analysis.columns:\n", "        df_analysis[\"has_am_pathogenic\"] = df_analysis[\"n_am_pathogenic\"] > 0\n", "    else:\n", "        path_patients = df_var[df_var[\"am_class\"] == \"pathogenic\"][\"sample_id\"].unique()\n", "        df_analysis[\"has_am_pathogenic\"] = df_analysis[\"sample_id\"].isin(path_patients)\n", "\n", "df_analysis[\"am_group\"] = df_analysis[\"has_am_pathogenic\"].map({\n", "    True: \"AM-Pathogenic (‚â•1 path. variant)\",\n", "    False: \"AM-Benign/Ambiguous only\"\n", "})\n", "print(\"\\nPatient groups:\")\n", "print(df_analysis[\"am_group\"].value_counts())\n", "\n", "# Find OS columns ‚Äî TCGA PanCancer uses OS_MONTHS and OS_STATUS\n", "os_time_col = None\n", "os_status_col = None\n", "for c in df_analysis.columns:\n", "    cu = str(c).upper()\n", "    if cu in [\"OS_MONTHS\", \"OS_TIME\"]:\n", "        os_time_col = c\n", "    elif cu == \"OS_STATUS\":\n", "        os_status_col = c\n", "    elif \"OVERALL_SURVIVAL\" in cu and \"MONTH\" in cu:\n", "        os_time_col = c\n", "\n", "print(f\"\\nSurvival columns: time='{os_time_col}', status='{os_status_col}'\")\n", "\n", "if os_status_col and os_time_col:\n", "    df_analysis[\"os_event\"] = df_analysis[os_status_col].apply(\n", "        lambda x: 1 if \"deceased\" in str(x).lower() or str(x).strip() == \"1\" else 0\n", "    )\n", "    df_analysis[\"os_time\"] = pd.to_numeric(df_analysis[os_time_col], errors=\"coerce\")\n", "    valid_surv = df_analysis[[\"os_time\", \"os_event\"]].dropna()\n", "    print(f\"Survival data: {len(valid_surv)}/{len(df_analysis)} patients\")\n", "    print(f\"  Events (deaths): {valid_surv['os_event'].sum()}\")\n", "    print(f\"  Median follow-up: {valid_surv['os_time'].median():.1f} months\")\n", "else:\n", "    print(\"\\n‚ö†Ô∏è  OS columns not found in pivoted data.\")\n", "    print(\"  Available columns:\", [c for c in df_analysis.columns if any(\n", "        k in str(c).upper() for k in [\"OS\", \"SURV\", \"DEATH\", \"STATUS\", \"MONTH\", \"DFS\", \"PFS\"]\n", "    )])\n", "    df_analysis[\"os_event\"] = np.nan\n", "    df_analysis[\"os_time\"] = np.nan\n", "\n", "# DFS\n", "for c in df_analysis.columns:\n", "    cu = str(c).upper()\n", "    if cu in [\"DFS_MONTHS\"]:\n", "        df_analysis[\"dfs_time\"] = pd.to_numeric(df_analysis[c], errors=\"coerce\")\n", "    if cu in [\"DFS_STATUS\"]:\n", "        df_analysis[\"dfs_event\"] = df_analysis[c].apply(\n", "            lambda x: 1 if \"recur\" in str(x).lower() or \"progress\" in str(x).lower() or str(x).strip() == \"1\" else 0\n", "        )\n", "\n", "# Add max_am_score from variant data\n", "max_am = df_var.groupby(\"sample_id\")[\"am_pathogenicity\"].max().reset_index()\n", "max_am.columns = [\"sample_id\", \"max_am_score\"]\n", "df_analysis = df_analysis.merge(max_am, on=\"sample_id\", how=\"left\")\n", "\n", "# Save\n", "df_analysis.to_csv(RESULTS_DIR / \"analysis_dataset.csv\", index=False)\n", "print(f\"\\nüíæ Saved: {RESULTS_DIR / 'analysis_dataset.csv'}\")\n", "print(f\"  Columns: {len(df_analysis.columns)}\")\n"]}, {"cell_type": "markdown", "id": "3686062c", "metadata": {}, "source": ["## 3. Concordance: AlphaMissense vs. ClinVar\n", "\n", "This is a key validation step. We check how well AlphaMissense agrees with ClinVar's expert-curated classifications for variants that have been previously classified.\n", "\n", "**Metrics:**\n", "- Cohen's kappa (chance-corrected agreement)\n", "- Sensitivity / Specificity for pathogenic detection\n", "- Confusion matrix\n", "\n", "**Why this matters:** If AM agrees with ClinVar on known variants (kappa > 0.70), it provides confidence that AM's reclassification of VUS is meaningful.\n"]}, {"cell_type": "code", "execution_count": 8, "id": "9ceabfe5", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["ClinVar data available: 193148 entries\n", "Columns: ['cv_gene', 'cv_name', 'cv_significance', 'cv_class']\n", "\n", "ClinVar simplified distribution:\n", "cv_simple\n", "VUS      80630\n", "B/LB     66719\n", "Other    32342\n", "P/LP     13457\n", "Name: count, dtype: int64\n", "\n", "üìä ClinVar landscape for HRR genes:\n", "   Pathogenic/Likely Pathogenic: 13457\n", "   Benign/Likely Benign: 66719\n", "   VUS: 80630 ‚Üê RECLASSIFICATION OPPORTUNITY\n", "   Other/Conflicting: 32342\n"]}], "source": ["# ============================================================\n", "# 4. CONCORDANCE ANALYSIS ‚Äî AlphaMissense vs ClinVar\n", "# ============================================================\n", "\n", "# Strategy: Use the AlphaMissense full lookup (all possible substitutions\n", "# for HRR genes) and cross-reference with ClinVar annotations.\n", "#\n", "# We match on: gene + protein_change (e.g., BRCA2 R2842H)\n", "# ClinVar gives: Pathogenic, Likely_Pathogenic, VUS, Likely_Benign, Benign\n", "# AlphaMissense gives: pathogenic (>0.564), ambiguous (0.34‚Äì0.564), benign (<0.34)\n", "\n", "from scipy.stats import fisher_exact\n", "\n", "# First, check what ClinVar data we have\n", "if len(df_clinvar) > 0:\n", "    print(f\"ClinVar data available: {len(df_clinvar)} entries\")\n", "    print(f\"Columns: {df_clinvar.columns.tolist()}\")\n", "    cv_data = df_clinvar.copy()\n", "elif (DATA_DIR / \"raw\" / \"variant_summary.txt.gz\").exists():\n", "    print(\"Parsing ClinVar from raw file (filtering for HRR genes)...\")\n", "    import gzip\n", "    HRR_GENES_ALL = sorted(set(COHORT_A_GENES + COHORT_B_GENES + [\n", "        \"FANCA\", \"FANCC\", \"FANCD2\", \"FANCE\", \"FANCF\", \"FANCG\",\n", "        \"NBN\", \"MRE11\", \"RAD50\", \"ATR\", \"ATRX\"\n", "    ]))\n", "    records = []\n", "    with gzip.open(DATA_DIR / \"raw\" / \"variant_summary.txt.gz\", 'rt', errors='replace') as f:\n", "        header = f.readline().strip().split('\\t')\n", "        col_map = {h: i for i, h in enumerate(header)}\n", "        for line in f:\n", "            parts = line.strip().split('\\t')\n", "            gene = parts[col_map.get(\"GeneSymbol\", 0)] if \"GeneSymbol\" in col_map else \"\"\n", "            if gene in HRR_GENES_ALL:\n", "                var_type = parts[col_map.get(\"Type\", 0)] if \"Type\" in col_map else \"\"\n", "                name = parts[col_map.get(\"Name\", 0)] if \"Name\" in col_map else \"\"\n", "                sig = parts[col_map.get(\"ClinicalSignificance\", 0)] if \"ClinicalSignificance\" in col_map else \"\"\n", "                if \"single nucleotide\" in var_type.lower() or \"missense\" in name.lower():\n", "                    records.append({\n", "                        \"cv_gene\": gene,\n", "                        \"cv_name\": name,\n", "                        \"cv_significance\": sig,\n", "                    })\n", "    cv_data = pd.DataFrame(records)\n", "    print(f\"  Parsed {len(cv_data)} ClinVar HRR SNV/missense entries\")\n", "else:\n", "    cv_data = pd.DataFrame()\n", "    print(\"‚ö†Ô∏è  No ClinVar data available ‚Äî skipping concordance\")\n", "\n", "if len(cv_data) > 0:\n", "    # Simplify ClinVar classification\n", "    def simplify_cv(sig):\n", "        sig = str(sig).lower()\n", "        if \"pathogenic\" in sig and \"conflicting\" not in sig and \"benign\" not in sig:\n", "            return \"P/LP\"\n", "        elif \"benign\" in sig and \"conflicting\" not in sig and \"pathogenic\" not in sig:\n", "            return \"B/LB\"\n", "        elif \"uncertain\" in sig:\n", "            return \"VUS\"\n", "        else:\n", "            return \"Other\"\n", "\n", "    cv_data[\"cv_simple\"] = cv_data.get(\"cv_significance\", cv_data.get(\"cv_clinical_significance\", \"\")).apply(simplify_cv)\n", "\n", "    print(\"\\nClinVar simplified distribution:\")\n", "    print(cv_data[\"cv_simple\"].value_counts())\n", "\n", "    # Count how many are VUS ‚Äî this is the reclassification opportunity\n", "    n_vus = (cv_data[\"cv_simple\"] == \"VUS\").sum()\n", "    n_plp = (cv_data[\"cv_simple\"] == \"P/LP\").sum()\n", "    n_blb = (cv_data[\"cv_simple\"] == \"B/LB\").sum()\n", "    print(f\"\\nüìä ClinVar landscape for HRR genes:\")\n", "    print(f\"   Pathogenic/Likely Pathogenic: {n_plp}\")\n", "    print(f\"   Benign/Likely Benign: {n_blb}\")\n", "    print(f\"   VUS: {n_vus} ‚Üê RECLASSIFICATION OPPORTUNITY\")\n", "    print(f\"   Other/Conflicting: {(cv_data['cv_simple'] == 'Other').sum()}\")\n"]}, {"cell_type": "code", "execution_count": 9, "id": "a0884da2", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["ClinVar entries with parseable protein change: 113170/193148\n", "\n", "‚úÖ Matched ClinVar √ó AlphaMissense: 104776 variants\n", "   Known (P/LP or B/LB) with AM score: 5414\n", "\n", "============================================================\n", "CONCORDANCE: AlphaMissense vs ClinVar\n", "============================================================\n", "Cohen's kappa: 0.733\n", "\n", "Confusion matrix (rows=ClinVar, cols=AM):\n", "              AM_Benign  AM_Pathogenic\n", "  CV_B/LB       3856        198\n", "  CV_P/LP        328       1032\n", "\n", "Sensitivity (for pathogenic): 0.759\n", "Specificity: 0.951\n", "PPV: 0.839\n", "NPV: 0.922\n", "Accuracy: 0.903\n", "\n", "üíæ Saved: results/concordance_results.csv\n"]}], "source": ["# ============================================================\n", "# 4B. CONCORDANCE ‚Äî MATCH VARIANTS BETWEEN AM AND CLINVAR\n", "# ============================================================\n", "\n", "# For concordance, we need to match AM predictions with ClinVar classifications.\n", "# We'll use the variants that appear in our TCGA dataset as the link.\n", "\n", "# Extract protein changes from ClinVar names (format varies)\n", "import re\n", "\n", "def extract_protein_from_clinvar(name):\n", "    \"\"\"Extract protein change from ClinVar Name field.\n", "    Handles formats like: 'NM_000059.4(BRCA2):c.8524C>T (p.Arg2842Cys)'\n", "    \"\"\"\n", "    # Look for p. notation\n", "    match = re.search(r'p\\.([A-Z][a-z]{2})(\\d+)([A-Z][a-z]{2})', str(name))\n", "    if match:\n", "        aa3to1 = {\n", "            'Ala':'A','Arg':'R','Asn':'N','Asp':'D','Cys':'C','Gln':'Q',\n", "            'Glu':'E','Gly':'G','His':'H','Ile':'I','Leu':'L','Lys':'K',\n", "            'Met':'M','Phe':'F','Pro':'P','Ser':'S','Thr':'T','Trp':'W',\n", "            'Tyr':'Y','Val':'V','Ter':'*'\n", "        }\n", "        ref = aa3to1.get(match.group(1), '?')\n", "        pos = match.group(2)\n", "        alt = aa3to1.get(match.group(3), '?')\n", "        return f\"{ref}{pos}{alt}\"\n", "    # Try 1-letter\n", "    match1 = re.search(r'p\\.([A-Z*])(\\d+)([A-Z*])', str(name))\n", "    if match1:\n", "        return f\"{match1.group(1)}{match1.group(2)}{match1.group(3)}\"\n", "    return None\n", "\n", "if len(cv_data) > 0 and len(df_am_full) > 0:\n", "    # Parse protein changes from ClinVar\n", "    cv_data[\"protein_change_parsed\"] = cv_data[\"cv_name\"].apply(extract_protein_from_clinvar)\n", "    cv_parsed = cv_data[cv_data[\"protein_change_parsed\"].notna()].copy()\n", "    print(f\"ClinVar entries with parseable protein change: {len(cv_parsed)}/{len(cv_data)}\")\n", "\n", "    # Build AM lookup: gene + protein_variant ‚Üí am_class, am_pathogenicity\n", "    # Map UniProt back to gene\n", "    UNIPROT_TO_GENE = {\n", "        \"P38398\":\"BRCA1\",\"P51587\":\"BRCA2\",\"Q13315\":\"ATM\",\"Q86YC2\":\"PALB2\",\n", "        \"Q9BX63\":\"BRIP1\",\"Q99728\":\"BARD1\",\"Q9NYV4\":\"CDK12\",\"O14757\":\"CHEK1\",\n", "        \"O96017\":\"CHEK2\",\"Q9NW38\":\"FANCL\",\"O15315\":\"RAD51B\",\"O43502\":\"RAD51C\",\n", "        \"O75771\":\"RAD51D\",\"Q92698\":\"RAD54L\",\"O15360\":\"FANCA\",\"Q00597\":\"FANCC\",\n", "        \"Q9BXW9\":\"FANCD2\",\"Q9HB96\":\"FANCE\",\"Q9NPI8\":\"FANCF\",\"O15287\":\"FANCG\",\n", "        \"O60934\":\"NBN\",\"P49959\":\"MRE11\",\"Q92878\":\"RAD50\",\"Q13535\":\"ATR\",\"P46100\":\"ATRX\",\n", "    }\n", "\n", "    df_am_full[\"am_gene\"] = df_am_full[\"uniprot_id\"].map(UNIPROT_TO_GENE)\n", "    df_am_full[\"am_pchange\"] = df_am_full[\"protein_variant\"]  # format: R175H\n", "\n", "    # Create matching key: gene + protein_change\n", "    df_am_full[\"match_key\"] = df_am_full[\"am_gene\"] + \"_\" + df_am_full[\"am_pchange\"]\n", "    cv_parsed[\"match_key\"] = cv_parsed[\"cv_gene\"] + \"_\" + cv_parsed[\"protein_change_parsed\"]\n", "\n", "    # Merge\n", "    concordance = cv_parsed.merge(\n", "        df_am_full[[\"match_key\", \"am_pathogenicity\", \"am_class\"]].drop_duplicates(\"match_key\"),\n", "        on=\"match_key\",\n", "        how=\"inner\"\n", "    )\n", "    print(f\"\\n‚úÖ Matched ClinVar √ó AlphaMissense: {len(concordance)} variants\")\n", "\n", "    # Filter to only P/LP and B/LB (exclude VUS for concordance ‚Äî those are the unknowns)\n", "    conc_known = concordance[concordance[\"cv_simple\"].isin([\"P/LP\", \"B/LB\"])].copy()\n", "    print(f\"   Known (P/LP or B/LB) with AM score: {len(conc_known)}\")\n", "\n", "    if len(conc_known) > 0:\n", "        # Binary classification for kappa: AM pathogenic vs not, ClinVar P/LP vs not\n", "        conc_known[\"cv_binary\"] = (conc_known[\"cv_simple\"] == \"P/LP\").astype(int)\n", "        conc_known[\"am_binary\"] = (conc_known[\"am_class\"] == \"pathogenic\").astype(int)\n", "\n", "        # Cohen's kappa\n", "        from sklearn.metrics import cohen_kappa_score, confusion_matrix, classification_report\n", "        kappa = cohen_kappa_score(conc_known[\"cv_binary\"], conc_known[\"am_binary\"])\n", "        print(f\"\\n{'='*60}\")\n", "        print(f\"CONCORDANCE: AlphaMissense vs ClinVar\")\n", "        print(f\"{'='*60}\")\n", "        print(f\"Cohen's kappa: {kappa:.3f}\")\n", "\n", "        # Confusion matrix\n", "        cm = confusion_matrix(conc_known[\"cv_binary\"], conc_known[\"am_binary\"])\n", "        print(f\"\\nConfusion matrix (rows=ClinVar, cols=AM):\")\n", "        print(f\"              AM_Benign  AM_Pathogenic\")\n", "        print(f\"  CV_B/LB     {cm[0,0]:6d}     {cm[0,1]:6d}\")\n", "        print(f\"  CV_P/LP     {cm[1,0]:6d}     {cm[1,1]:6d}\")\n", "\n", "        # Sensitivity & Specificity\n", "        TP, FP, FN, TN = cm[1,1], cm[0,1], cm[1,0], cm[0,0]\n", "        sens = TP / (TP + FN) if (TP + FN) > 0 else np.nan\n", "        spec = TN / (TN + FP) if (TN + FP) > 0 else np.nan\n", "        ppv = TP / (TP + FP) if (TP + FP) > 0 else np.nan\n", "        npv = TN / (TN + FN) if (TN + FN) > 0 else np.nan\n", "        acc = (TP + TN) / (TP + FP + FN + TN)\n", "\n", "        print(f\"\\nSensitivity (for pathogenic): {sens:.3f}\")\n", "        print(f\"Specificity: {spec:.3f}\")\n", "        print(f\"PPV: {ppv:.3f}\")\n", "        print(f\"NPV: {npv:.3f}\")\n", "        print(f\"Accuracy: {acc:.3f}\")\n", "\n", "        # Save concordance results\n", "        conc_results = pd.DataFrame({\n", "            \"Metric\": [\"Cohen's kappa\", \"Sensitivity\", \"Specificity\", \"PPV\", \"NPV\", \"Accuracy\",\n", "                       \"TP\", \"FP\", \"FN\", \"TN\", \"Total variants\"],\n", "            \"Value\": [kappa, sens, spec, ppv, npv, acc, TP, FP, FN, TN, len(conc_known)]\n", "        })\n", "        conc_results.to_csv(RESULTS_DIR / \"concordance_results.csv\", index=False)\n", "        print(f\"\\nüíæ Saved: {RESULTS_DIR / 'concordance_results.csv'}\")\n", "    else:\n", "        print(\"‚ö†Ô∏è  No known (P/LP or B/LB) variants matched ‚Äî concordance not computed\")\n", "        kappa = np.nan\n", "else:\n", "    print(\"‚ö†Ô∏è  Need both ClinVar + AlphaMissense lookup for concordance analysis\")\n", "    print(\"   This can be run once ClinVar data is available.\")\n", "    kappa = np.nan\n", "    concordance = pd.DataFrame()\n"]}, {"cell_type": "markdown", "id": "f9e2e6e0", "metadata": {}, "source": ["## 4. VUS Reclassification Yield\n", "\n", "**The key clinical question:** How many previously unclassified VUS does AlphaMissense reclassify as pathogenic or benign?\n", "\n", "This directly impacts the paper's clinical narrative ‚Äî each reclassified VUS is a patient whose variant annotation could potentially inform future PARP inhibitor considerations (pending clinical validation).\n", ""]}, {"cell_type": "code", "execution_count": 10, "id": "cb9c1741", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["============================================================\n", "VUS RECLASSIFICATION ANALYSIS\n", "============================================================\n", "\n", "Total VUS in ClinVar matched to AlphaMissense: 74246\n", "\n", "  Reclassified as PATHOGENIC: 15930 (21.5%)\n", "  Reclassified as BENIGN:     50982 (68.7%)\n", "  Remain AMBIGUOUS:           7334 (9.9%)\n", "  TOTAL RECLASSIFIED:         66912 (90.1%)\n", "\n", "  Reclassification by gene:\n", "am_class  ambiguous  benign  pathogenic\n", "cv_gene                                \n", "ATM            1748    9072        3508\n", "ATR             476    2852         808\n", "ATRX            106     972         388\n", "BARD1           326    2488         842\n", "BRCA1           196    2920         396\n", "BRCA2           466    5272         780\n", "BRIP1           434    3664        1292\n", "CDK12           136    1504         302\n", "CHEK1             4      32          42\n", "CHEK2           346    1386        1684\n", "FANCA           432    3526         516\n", "FANCC           204    1350         130\n", "FANCD2          120     980         158\n", "FANCE            66     474          48\n", "FANCF            58     388          62\n", "FANCG           102     808         128\n", "FANCL            70     346          88\n", "MRE11           232    1364         712\n", "NBN             238    2390         520\n", "PALB2           366    4008         536\n", "RAD50           614    2770        1470\n", "RAD51B           90     316         138\n", "RAD51C          148     630         394\n", "RAD51D          232     842         412\n", "RAD54L          124     628         576\n", "\n", "üíæ Saved: results/vus_reclassification.csv\n", "\n", "============================================================\n", "CLINICAL IMPACT ESTIMATE\n", "============================================================\n", "  If 15930 VUS are truly pathogenic:\n", "  ‚Üí These patients could gain PARP inhibitor eligibility\n", "  If 50982 VUS are truly benign:\n", "  ‚Üí These patients can be spared unnecessary genetic counseling anxiety\n"]}], "source": ["# ============================================================\n", "# 5. VUS RECLASSIFICATION YIELD\n", "# ============================================================\n", "\n", "if len(concordance) > 0:\n", "    # Filter concordance to VUS only\n", "    vus_reclass = concordance[concordance[\"cv_simple\"] == \"VUS\"].copy()\n", "    n_vus_total = len(vus_reclass)\n", "    print(f\"{'='*60}\")\n", "    print(f\"VUS RECLASSIFICATION ANALYSIS\")\n", "    print(f\"{'='*60}\")\n", "    print(f\"\\nTotal VUS in ClinVar matched to AlphaMissense: {n_vus_total}\")\n", "\n", "    if n_vus_total > 0:\n", "        n_to_path = (vus_reclass[\"am_class\"] == \"pathogenic\").sum()\n", "        n_to_ben = (vus_reclass[\"am_class\"] == \"benign\").sum()\n", "        n_remain_amb = (vus_reclass[\"am_class\"] == \"ambiguous\").sum()\n", "\n", "        print(f\"\\n  Reclassified as PATHOGENIC: {n_to_path} ({100*n_to_path/n_vus_total:.1f}%)\")\n", "        print(f\"  Reclassified as BENIGN:     {n_to_ben} ({100*n_to_ben/n_vus_total:.1f}%)\")\n", "        print(f\"  Remain AMBIGUOUS:           {n_remain_amb} ({100*n_remain_amb/n_vus_total:.1f}%)\")\n", "        print(f\"  TOTAL RECLASSIFIED:         {n_to_path + n_to_ben} ({100*(n_to_path+n_to_ben)/n_vus_total:.1f}%)\")\n", "\n", "        # By gene\n", "        print(f\"\\n  Reclassification by gene:\")\n", "        vus_by_gene = vus_reclass.groupby(\"cv_gene\")[\"am_class\"].value_counts().unstack(fill_value=0)\n", "        print(vus_by_gene.to_string())\n", "\n", "        # Save\n", "        vus_reclass.to_csv(RESULTS_DIR / \"vus_reclassification.csv\", index=False)\n", "        print(f\"\\nüíæ Saved: {RESULTS_DIR / 'vus_reclassification.csv'}\")\n", "\n", "        # Clinical impact estimate\n", "        print(f\"\\n{'='*60}\")\n", "        print(f\"CLINICAL IMPACT ESTIMATE\")\n", "        print(f\"{'='*60}\")\n", "        print(f\"  If {n_to_path} VUS are truly pathogenic:\")\n", "        print(f\"  ‚Üí These patients have variants predicted pathogenic by AlphaMissense (hypothesis-generating; not for clinical decision-making)\")\n", "        print(f\"  If {n_to_ben} VUS are truly benign:\")\n", "        print(f\"  ‚Üí These patients can be spared unnecessary genetic counseling anxiety\")\n", "    else:\n", "        print(\"  No VUS found in matched set\")\n", "else:\n", "    print(\"‚ö†Ô∏è  VUS reclassification analysis requires ClinVar √ó AM concordance data\")\n", "    print(\"   Proceeding to survival analysis using AM classification directly\")\n", "    # For the TCGA variants, classify as VUS everything not in ClinVar\n", "    print(f\"\\n  In TCGA-PRAD HRR missense variants:\")\n", "    print(f\"  AM-pathogenic: {(df_var['am_class']=='pathogenic').sum()}\")\n", "    print(f\"  AM-benign: {(df_var['am_class']=='benign').sum()}\")\n", "    print(f\"  AM-ambiguous: {(df_var['am_class']=='ambiguous').sum()}\")\n", ""]}, {"cell_type": "markdown", "id": "f50c0eed", "metadata": {}, "source": ["## 5. Survival Analysis\n", "\n", "### Primary Analysis: Cox Proportional Hazards\n", "- **Outcome:** Overall Survival (OS)\n", "- **Primary exposure:** ‚â•1 AM-pathogenic HRR variant (binary)\n", "- **Covariates:** Age, Gleason score (where available)\n", "- **Complementary:** RMST (Restricted Mean Survival Time) at œÑ = 90th percentile\n", "\n", "### Secondary: Kaplan-Meier Curves (Fig 3)\n", "\n", "**Note on power:** With n~41 HRR-mutated patients and limited events in TCGA-PRAD (localized disease, long survival), the primary value is **effect estimation** rather than definitive hypothesis testing. The PARP cohort validation (Notebook 3) provides the clinically relevant test.\n"]}, {"cell_type": "code", "execution_count": 11, "id": "8113bb37", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["============================================================\n", "SURVIVAL ANALYSIS\n", "============================================================\n", "Patients with valid OS data: 40\n", "  AM-Pathogenic group: 19\n", "  AM-Benign/Ambiguous: 21\n", "  Total events (deaths): 1\n", "\n", "‚ö†Ô∏è  Insufficient events for Cox regression.\n", "   TCGA-PRAD is primarily localized disease with few deaths.\n", "   This is expected ‚Äî the survival analysis will be exploratory.\n", "   Definitive testing will come from the mCRPC PARP cohort (Notebook 3).\n"]}], "source": ["# ============================================================\n", "# 6A. SURVIVAL ANALYSIS ‚Äî COX PH\n", "# ============================================================\n", "from lifelines import CoxPHFitter, KaplanMeierFitter\n", "from lifelines.statistics import logrank_test\n", "\n", "# Prepare survival dataset\n", "df_surv = df_analysis.dropna(subset=[\"os_time\", \"os_event\"]).copy()\n", "df_surv = df_surv[df_surv[\"os_time\"] > 0].copy()\n", "\n", "print(f\"{'='*60}\")\n", "print(f\"SURVIVAL ANALYSIS\")\n", "print(f\"{'='*60}\")\n", "print(f\"Patients with valid OS data: {len(df_surv)}\")\n", "print(f\"  AM-Pathogenic group: {df_surv['has_am_pathogenic'].sum()}\")\n", "print(f\"  AM-Benign/Ambiguous: {(~df_surv['has_am_pathogenic']).sum()}\")\n", "print(f\"  Total events (deaths): {df_surv['os_event'].sum():.0f}\")\n", "\n", "if len(df_surv) < 10 or df_surv[\"os_event\"].sum() < 3:\n", "    print(\"\\n‚ö†Ô∏è  Insufficient events for Cox regression.\")\n", "    print(\"   TCGA-PRAD is primarily localized disease with few deaths.\")\n", "    print(\"   This is expected ‚Äî the survival analysis will be exploratory.\")\n", "    print(\"   Definitive testing will come from the mCRPC PARP cohort (Notebook 3).\")\n", "    cox_result = None\n", "else:\n", "    # Prepare covariates\n", "    surv_cols = [\"os_time\", \"os_event\", \"has_am_pathogenic\"]\n", "\n", "    # Try to add age as covariate\n", "    age_col = None\n", "    for c in df_surv.columns:\n", "        if \"AGE\" in c.upper() and \"DIAG\" in c.upper():\n", "            age_col = c\n", "            break\n", "        elif c.upper() == \"AGE\":\n", "            age_col = c\n", "            break\n", "\n", "    if age_col:\n", "        df_surv[\"age_numeric\"] = pd.to_numeric(df_surv[age_col], errors=\"coerce\")\n", "        if df_surv[\"age_numeric\"].notna().sum() > 10:\n", "            surv_cols.append(\"age_numeric\")\n", "            print(f\"  Including covariate: age (n={df_surv['age_numeric'].notna().sum()})\")\n", "\n", "    # Fit Cox model\n", "    df_cox = df_surv[surv_cols].dropna().copy()\n", "    df_cox[\"has_am_pathogenic\"] = df_cox[\"has_am_pathogenic\"].astype(int)\n", "\n", "    print(f\"\\nCox PH model (n={len(df_cox)}, events={df_cox['os_event'].sum():.0f}):\")\n", "\n", "    try:\n", "        cph = CoxPHFitter()\n", "        cph.fit(df_cox, duration_col=\"os_time\", event_col=\"os_event\")\n", "        cph.print_summary()\n", "\n", "        # Extract HR for AM-pathogenic\n", "        hr = np.exp(cph.params_[\"has_am_pathogenic\"])\n", "        ci_low = np.exp(cph.confidence_intervals_.loc[\"has_am_pathogenic\", \"95% lower-bound\"])\n", "        ci_high = np.exp(cph.confidence_intervals_.loc[\"has_am_pathogenic\", \"95% upper-bound\"])\n", "        p_val = cph.summary.loc[\"has_am_pathogenic\", \"p\"]\n", "\n", "        print(f\"\\n{'='*60}\")\n", "        print(f\"PRIMARY RESULT: AM-Pathogenic HRR\")\n", "        print(f\"{'='*60}\")\n", "        print(f\"  HR: {hr:.2f} (95% CI: {ci_low:.2f}‚Äì{ci_high:.2f})\")\n", "        print(f\"  p-value: {p_val:.4f}\")\n", "\n", "        # PH assumption check\n", "        print(f\"\\nProportional hazards test:\")\n", "        try:\n", "            ph_test = cph.check_assumptions(df_cox, show_plots=False)\n", "            print(\"  ‚úÖ PH assumption OK\")\n", "        except Exception as e:\n", "            print(f\"  ‚ö†Ô∏è  PH test: {e}\")\n", "\n", "        cox_result = {\"hr\": hr, \"ci_low\": ci_low, \"ci_high\": ci_high, \"p\": p_val}\n", "\n", "    except Exception as e:\n", "        print(f\"‚ö†Ô∏è  Cox model failed: {e}\")\n", "        print(\"   Likely due to very few events. Proceeding with KM only.\")\n", "        cox_result = None\n"]}, {"cell_type": "code", "execution_count": 12, "id": "7a6cc610", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "============================================================\n", "KAPLAN-MEIER ANALYSIS\n", "============================================================\n", "Log-rank test: œá¬≤=0.895, p=0.3442\n", "\n", "Median OS:\n", "  AM-Pathogenic: inf months\n", "  AM-Benign/Amb: inf months\n", "\n", "RMST (œÑ=69.3 months):\n"]}, {"ename": "AttributeError", "evalue": "module 'numpy' has no attribute 'trapz'", "output_type": "error", "traceback": ["\u001b[31m---------------------------------------------------------------------------\u001b[39m", "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)", "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     52\u001b[39m     \u001b[38;5;66;03m# Trapezoidal integration\u001b[39;00m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.trapz(s, t)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m rmst_path = \u001b[43mcompute_rmst\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkmf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m rmst_ben = compute_rmst(kmf_ben, tau)\n\u001b[32m     57\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  AM-Pathogenic: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmst_path\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m months\u001b[39m\u001b[33m\"\u001b[39m)\n", "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36mcompute_rmst\u001b[39m\u001b[34m(kmf, tau)\u001b[39m\n\u001b[32m     51\u001b[39m s = np.concatenate([[\u001b[32m1.0\u001b[39m], surv[mask].values, [surv[mask].iloc[-\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m mask.sum() > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m]])\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# Trapezoidal integration\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrapz\u001b[49m(s, t)\n", "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/alphamissense-prostate-hrr/.venv/lib/python3.12/site-packages/numpy/__init__.py:792\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr)\u001b[39m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchar\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchar\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m char.chararray\n\u001b[32m--> \u001b[39m\u001b[32m792\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n", "\u001b[31mAttributeError\u001b[39m: module 'numpy' has no attribute 'trapz'"]}], "source": ["# ============================================================\n", "# 6B. KAPLAN-MEIER CURVES\n", "# ============================================================\n", "\n", "print(\"\\n\" + \"=\"*60)\n", "print(\"KAPLAN-MEIER ANALYSIS\")\n", "print(\"=\"*60)\n", "\n", "if len(df_surv) >= 5:\n", "    # Split by AM group\n", "    grp_path = df_surv[df_surv[\"has_am_pathogenic\"] == True]\n", "    grp_ben = df_surv[df_surv[\"has_am_pathogenic\"] == False]\n", "\n", "    kmf_path = KaplanMeierFitter()\n", "    kmf_ben = KaplanMeierFitter()\n", "\n", "    if len(grp_path) >= 2 and len(grp_ben) >= 2:\n", "        kmf_path.fit(\n", "            grp_path[\"os_time\"], grp_path[\"os_event\"],\n", "            label=f\"AM-Pathogenic (n={len(grp_path)})\"\n", "        )\n", "        kmf_ben.fit(\n", "            grp_ben[\"os_time\"], grp_ben[\"os_event\"],\n", "            label=f\"AM-Benign/Ambig (n={len(grp_ben)})\"\n", "        )\n", "\n", "        # Log-rank test\n", "        lr = logrank_test(\n", "            grp_path[\"os_time\"], grp_ben[\"os_time\"],\n", "            grp_path[\"os_event\"], grp_ben[\"os_event\"]\n", "        )\n", "        print(f\"Log-rank test: œá¬≤={lr.test_statistic:.3f}, p={lr.p_value:.4f}\")\n", "\n", "        # Median survival\n", "        print(f\"\\nMedian OS:\")\n", "        print(f\"  AM-Pathogenic: {kmf_path.median_survival_time_:.1f} months\")\n", "        print(f\"  AM-Benign/Amb: {kmf_ben.median_survival_time_:.1f} months\")\n", "\n", "        # RMST (Restricted Mean Survival Time)\n", "        tau = df_surv[\"os_time\"].quantile(0.9)\n", "        print(f\"\\nRMST (œÑ={tau:.1f} months):\")\n", "\n", "        # Simple RMST via trapezoidal integration of KM curves\n", "        def compute_rmst(kmf, tau):\n", "            \"\"\"Compute RMST from KaplanMeierFitter up to time tau.\"\"\"\n", "            times = kmf.survival_function_.index\n", "            surv = kmf.survival_function_.iloc[:, 0]\n", "            # Restrict to tau\n", "            mask = times <= tau\n", "            t = np.concatenate([[0], times[mask].values, [tau]])\n", "            s = np.concatenate([[1.0], surv[mask].values, [surv[mask].iloc[-1] if mask.sum() > 0 else 0]])\n", "            # Trapezoidal integration\n", "            return np.trapz(s, t)\n", "\n", "        rmst_path = compute_rmst(kmf_path, tau)\n", "        rmst_ben = compute_rmst(kmf_ben, tau)\n", "        print(f\"  AM-Pathogenic: {rmst_path:.1f} months\")\n", "        print(f\"  AM-Benign/Amb: {rmst_ben:.1f} months\")\n", "        print(f\"  Œî RMST: {rmst_path - rmst_ben:.1f} months\")\n", "\n", "    else:\n", "        print(\"‚ö†Ô∏è  Too few patients in one group for KM analysis\")\n", "        lr = None\n", "else:\n", "    print(\"‚ö†Ô∏è  Insufficient patients with survival data\")\n", "    lr = None\n"]}, {"cell_type": "markdown", "id": "0a9e0fa1", "metadata": {}, "source": ["## 6. Sensitivity Analyses\n", "\n", "Three pre-specified sensitivity analyses:\n", "\n", "1. **Threshold variation:** Test AM score as continuous + alternative cutoffs (0.34, 0.50, 0.564, 0.80)\n", "2. **E-value:** Assess robustness to unmeasured confounding\n", "3. **Gene exclusion (leave-one-gene-out):** Test if results are driven by a single gene\n"]}, {"cell_type": "code", "execution_count": 13, "id": "51058a66", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["============================================================\n", "SENSITIVITY 1: AlphaMissense Threshold Variation\n", "============================================================\n", "Patients for sensitivity: 40\n", "  With max_am_score: 39\n", "  Events: 1\n", "  Threshold ‚â•0.340: n_path=20, events=1 ‚Äî insufficient\n", "  Threshold ‚â•0.500: n_path=20, events=1 ‚Äî insufficient\n", "  Threshold ‚â•0.564: n_path=19, events=1 ‚Äî insufficient\n", "  Threshold ‚â•0.700: n_path=14, events=1 ‚Äî insufficient\n", "  Threshold ‚â•0.800: n_path=13, events=1 ‚Äî insufficient\n", "\n", "üíæ Saved: results/sensitivity_threshold.csv\n"]}], "source": ["# ============================================================\n", "# 7A. SENSITIVITY ‚Äî THRESHOLD VARIATION\n", "# ============================================================\n", "\n", "print(\"=\"*60)\n", "print(\"SENSITIVITY 1: AlphaMissense Threshold Variation\")\n", "print(\"=\"*60)\n", "\n", "# Use df_analysis which already has max_am_score from the merge\n", "df_sens = df_analysis.dropna(subset=[\"os_time\", \"os_event\"]).copy()\n", "df_sens = df_sens[df_sens[\"os_time\"] > 0]\n", "\n", "# If max_am_score not in df_analysis, compute it\n", "if \"max_am_score\" not in df_sens.columns:\n", "    max_am = df_var.groupby(\"sample_id\")[\"am_pathogenicity\"].max().reset_index()\n", "    max_am.columns = [\"sample_id\", \"max_am_score\"]\n", "    df_sens = df_sens.merge(max_am, on=\"sample_id\", how=\"left\")\n", "\n", "print(f\"Patients for sensitivity: {len(df_sens)}\")\n", "print(f\"  With max_am_score: {df_sens['max_am_score'].notna().sum()}\")\n", "print(f\"  Events: {df_sens['os_event'].sum():.0f}\")\n", "\n", "thresholds = [0.34, 0.50, 0.564, 0.70, 0.80]\n", "threshold_results = []\n", "\n", "for thresh in thresholds:\n", "    has_score = df_sens[\"max_am_score\"].notna()\n", "    df_t = df_sens[has_score].copy()\n", "    df_t[f\"path_{thresh}\"] = (df_t[\"max_am_score\"] >= thresh).astype(int)\n", "    n_path = df_t[f\"path_{thresh}\"].sum()\n", "    n_ben = len(df_t) - n_path\n", "\n", "    if n_path >= 2 and n_ben >= 2 and df_t[\"os_event\"].sum() >= 3:\n", "        try:\n", "            cph_s = CoxPHFitter()\n", "            cph_s.fit(\n", "                df_t[[\"os_time\", \"os_event\", f\"path_{thresh}\"]].dropna(),\n", "                duration_col=\"os_time\", event_col=\"os_event\"\n", "            )\n", "            hr = np.exp(cph_s.params_[f\"path_{thresh}\"])\n", "            ci = np.exp(cph_s.confidence_intervals_.loc[f\"path_{thresh}\"])\n", "            p = cph_s.summary.loc[f\"path_{thresh}\", \"p\"]\n", "            threshold_results.append({\n", "                \"threshold\": thresh, \"n_pathogenic\": n_path, \"n_benign\": n_ben,\n", "                \"HR\": hr, \"CI_low\": ci.iloc[0], \"CI_high\": ci.iloc[1], \"p_value\": p\n", "            })\n", "            print(f\"  Threshold ‚â•{thresh:.3f}: n_path={n_path}, HR={hr:.2f} \"\n", "                  f\"(95% CI {ci.iloc[0]:.2f}‚Äì{ci.iloc[1]:.2f}), p={p:.4f}\")\n", "        except Exception as e:\n", "            threshold_results.append({\n", "                \"threshold\": thresh, \"n_pathogenic\": n_path, \"n_benign\": n_ben,\n", "                \"HR\": np.nan, \"CI_low\": np.nan, \"CI_high\": np.nan, \"p_value\": np.nan\n", "            })\n", "            print(f\"  Threshold ‚â•{thresh:.3f}: n_path={n_path} ‚Äî model failed ({e})\")\n", "    else:\n", "        threshold_results.append({\n", "            \"threshold\": thresh, \"n_pathogenic\": n_path, \"n_benign\": n_ben,\n", "            \"HR\": np.nan, \"CI_low\": np.nan, \"CI_high\": np.nan, \"p_value\": np.nan\n", "        })\n", "        print(f\"  Threshold ‚â•{thresh:.3f}: n_path={n_path}, events={df_t['os_event'].sum():.0f} ‚Äî insufficient\")\n", "\n", "df_thresh = pd.DataFrame(threshold_results)\n", "df_thresh.to_csv(RESULTS_DIR / \"sensitivity_threshold.csv\", index=False)\n", "print(f\"\\nüíæ Saved: {RESULTS_DIR / 'sensitivity_threshold.csv'}\")\n"]}, {"cell_type": "code", "execution_count": 14, "id": "06275bfd", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "============================================================\n", "SENSITIVITY 2: E-value for Unmeasured Confounding\n", "============================================================\n", "  E-value not computed (Cox model not available)\n"]}], "source": ["# ============================================================\n", "# 7B. SENSITIVITY ‚Äî E-VALUE\n", "# ============================================================\n", "\n", "print(\"\\n\" + \"=\"*60)\n", "print(\"SENSITIVITY 2: E-value for Unmeasured Confounding\")\n", "print(\"=\"*60)\n", "\n", "def compute_evalue(hr):\n", "    \"\"\"Compute E-value for a hazard ratio.\n", "    E-value = HR + sqrt(HR*(HR-1)) for HR >= 1\n", "    For HR < 1, use 1/HR.\n", "    \"\"\"\n", "    if pd.isna(hr) or hr <= 0:\n", "        return np.nan\n", "    rr = hr if hr >= 1 else 1/hr\n", "    return rr + np.sqrt(rr * (rr - 1))\n", "\n", "if cox_result is not None:\n", "    hr = cox_result[\"hr\"]\n", "    ci_bound = cox_result[\"ci_low\"] if hr >= 1 else cox_result[\"ci_high\"]\n", "\n", "    e_point = compute_evalue(hr)\n", "    e_ci = compute_evalue(ci_bound)\n", "\n", "    print(f\"  Observed HR: {hr:.2f}\")\n", "    print(f\"  E-value (point estimate): {e_point:.2f}\")\n", "    print(f\"  E-value (CI bound): {e_ci:.2f}\")\n", "    print(f\"\\n  Interpretation:\")\n", "    if e_point > 2.0:\n", "        print(f\"  ‚úÖ E-value > 2.0: robust to moderate unmeasured confounding\")\n", "    elif e_point > 1.5:\n", "        print(f\"  ‚ö†Ô∏è  E-value 1.5‚Äì2.0: moderate robustness\")\n", "    else:\n", "        print(f\"  ‚ùå E-value < 1.5: result sensitive to unmeasured confounding\")\n", "else:\n", "    print(\"  E-value not computed (Cox model not available)\")\n"]}, {"cell_type": "code", "execution_count": 15, "id": "8aa4fb11", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "============================================================\n", "SENSITIVITY 3: Leave-One-Gene-Out (LOGO)\n", "============================================================\n", "  Excl. ATM       : insufficient (n_path=9)\n", "  Excl. ATR       : insufficient (n_path=19)\n", "  Excl. ATRX      : insufficient (n_path=16)\n", "  Excl. BARD1     : insufficient (n_path=19)\n", "  Excl. BRCA1     : insufficient (n_path=19)\n", "  Excl. BRCA2     : insufficient (n_path=19)\n", "  Excl. BRIP1     : insufficient (n_path=19)\n", "  Excl. CDK12     : insufficient (n_path=16)\n", "  Excl. FANCC     : insufficient (n_path=19)\n", "  Excl. FANCD2    : insufficient (n_path=19)\n", "  Excl. FANCF     : insufficient (n_path=19)\n", "  Excl. FANCG     : insufficient (n_path=18)\n", "  Excl. FANCL     : insufficient (n_path=18)\n", "  Excl. NBN       : insufficient (n_path=19)\n", "  Excl. PALB2     : insufficient (n_path=19)\n", "  Excl. RAD50     : insufficient (n_path=19)\n", "  Excl. RAD51B    : insufficient (n_path=19)\n", "  Excl. RAD51D    : insufficient (n_path=19)\n", "  Excl. RAD54L    : insufficient (n_path=18)\n", "\n", "üíæ Saved: results/sensitivity_logo.csv\n"]}], "source": ["# ============================================================\n", "# 7C. SENSITIVITY ‚Äî LEAVE-ONE-GENE-OUT (LOGO)\n", "# ============================================================\n", "\n", "print(\"\\n\" + \"=\"*60)\n", "print(\"SENSITIVITY 3: Leave-One-Gene-Out (LOGO)\")\n", "print(\"=\"*60)\n", "\n", "# For each HRR gene, exclude all its variants and re-run the analysis\n", "genes_present = df_var[\"gene\"].unique()\n", "logo_results = []\n", "\n", "for exclude_gene in sorted(genes_present):\n", "    # Recompute patient-level AM status excluding this gene\n", "    vars_excl = df_var[df_var[\"gene\"] != exclude_gene]\n", "    path_patients_excl = set(\n", "        vars_excl[vars_excl[\"am_class\"] == \"pathogenic\"][\"sample_id\"].unique()\n", "    )\n", "\n", "    # Re-create analysis flag\n", "    df_logo = df_surv.copy()\n", "    df_logo[\"am_path_logo\"] = df_logo[\"sample_id\"].isin(path_patients_excl).astype(int)\n", "\n", "    n_path = df_logo[\"am_path_logo\"].sum()\n", "    n_ben = len(df_logo) - n_path\n", "\n", "    if n_path >= 2 and n_ben >= 2 and df_logo[\"os_event\"].sum() >= 3:\n", "        try:\n", "            cph_logo = CoxPHFitter()\n", "            cph_logo.fit(\n", "                df_logo[[\"os_time\", \"os_event\", \"am_path_logo\"]].dropna(),\n", "                duration_col=\"os_time\", event_col=\"os_event\"\n", "            )\n", "            hr_l = np.exp(cph_logo.params_[\"am_path_logo\"])\n", "            ci_l = np.exp(cph_logo.confidence_intervals_.loc[\"am_path_logo\"])\n", "            p_l = cph_logo.summary.loc[\"am_path_logo\", \"p\"]\n", "            logo_results.append({\n", "                \"excluded_gene\": exclude_gene,\n", "                \"n_path\": n_path, \"n_ben\": n_ben,\n", "                \"HR\": hr_l, \"CI_low\": ci_l.iloc[0], \"CI_high\": ci_l.iloc[1], \"p\": p_l\n", "            })\n", "            print(f\"  Excl. {exclude_gene:10s}: n_path={n_path:3d}, HR={hr_l:.2f} \"\n", "                  f\"({ci_l.iloc[0]:.2f}‚Äì{ci_l.iloc[1]:.2f}), p={p_l:.4f}\")\n", "        except:\n", "            logo_results.append({\n", "                \"excluded_gene\": exclude_gene, \"n_path\": n_path, \"n_ben\": n_ben,\n", "                \"HR\": np.nan, \"CI_low\": np.nan, \"CI_high\": np.nan, \"p\": np.nan\n", "            })\n", "            print(f\"  Excl. {exclude_gene:10s}: model failed\")\n", "    else:\n", "        logo_results.append({\n", "            \"excluded_gene\": exclude_gene, \"n_path\": n_path, \"n_ben\": n_ben,\n", "            \"HR\": np.nan, \"CI_low\": np.nan, \"CI_high\": np.nan, \"p\": np.nan\n", "        })\n", "        print(f\"  Excl. {exclude_gene:10s}: insufficient (n_path={n_path})\")\n", "\n", "df_logo_res = pd.DataFrame(logo_results)\n", "df_logo_res.to_csv(RESULTS_DIR / \"sensitivity_logo.csv\", index=False)\n", "print(f\"\\nüíæ Saved: {RESULTS_DIR / 'sensitivity_logo.csv'}\")\n"]}, {"cell_type": "markdown", "id": "2f3bf9a6", "metadata": {}, "source": ["## 7. Publication-Ready Figures\n", "\n", "**Figure 1:** Study flowchart + AlphaMissense score distribution\n", "**Figure 2:** Concordance heatmap (AM vs ClinVar) + VUS Sankey\n", "**Figure 3:** Kaplan-Meier survival curves\n", "**Figure 4:** Sensitivity forest plot (threshold variation + LOGO)\n", "**Figure 5:** Gene-level summary heatmap\n"]}, {"cell_type": "code", "execution_count": 16, "id": "24edfed8", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["‚úÖ Figure 1 saved\n"]}], "source": ["# ============================================================\n", "# 8A. FIGURE 1 ‚Äî AlphaMissense Score Distribution + Classification\n", "# ============================================================\n", "\n", "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n", "\n", "# Panel A: Score distribution histogram\n", "ax = axes[0]\n", "scores = df_var[\"am_pathogenicity\"].dropna()\n", "\n", "ax.hist(scores, bins=50, color=\"#4C72B0\", edgecolor=\"white\", alpha=0.85)\n", "ax.axvline(0.34, color=\"#E74C3C\", linestyle=\"--\", linewidth=1.5, label=\"Benign/Ambiguous (0.34)\")\n", "ax.axvline(0.564, color=\"#2ECC71\", linestyle=\"--\", linewidth=1.5, label=\"Ambiguous/Pathogenic (0.564)\")\n", "\n", "# Shade regions\n", "ax.axvspan(0, 0.34, alpha=0.08, color=\"#3498DB\", label=\"_\")\n", "ax.axvspan(0.34, 0.564, alpha=0.08, color=\"#F39C12\", label=\"_\")\n", "ax.axvspan(0.564, 1.0, alpha=0.08, color=\"#E74C3C\", label=\"_\")\n", "\n", "ax.set_xlabel(\"AlphaMissense Pathogenicity Score\")\n", "ax.set_ylabel(\"Number of Variants\")\n", "ax.set_title(\"A) AlphaMissense Score Distribution\\n(HRR missense variants, TCGA-PRAD)\")\n", "ax.legend(fontsize=8)\n", "ax.set_xlim(0, 1)\n", "\n", "# Add text annotations\n", "n_ben = (df_var[\"am_class\"] == \"benign\").sum()\n", "n_amb = (df_var[\"am_class\"] == \"ambiguous\").sum()\n", "n_pat = (df_var[\"am_class\"] == \"pathogenic\").sum()\n", "ax.text(0.17, ax.get_ylim()[1]*0.85, f\"Benign\\nn={n_ben}\", ha=\"center\", fontsize=8, color=\"#3498DB\")\n", "ax.text(0.45, ax.get_ylim()[1]*0.85, f\"Ambiguous\\nn={n_amb}\", ha=\"center\", fontsize=8, color=\"#F39C12\")\n", "ax.text(0.78, ax.get_ylim()[1]*0.85, f\"Pathogenic\\nn={n_pat}\", ha=\"center\", fontsize=8, color=\"#E74C3C\")\n", "\n", "# Panel B: By gene (top genes)\n", "ax = axes[1]\n", "gene_am = df_var.groupby(\"gene\").agg(\n", "    mean_score=(\"am_pathogenicity\", \"mean\"),\n", "    n_variants=(\"am_pathogenicity\", \"count\"),\n", "    pct_pathogenic=(\"am_class\", lambda x: 100*(x==\"pathogenic\").sum()/len(x))\n", ").reset_index()\n", "gene_am = gene_am.sort_values(\"n_variants\", ascending=True)\n", "\n", "# Only show genes with ‚â•2 variants for readability\n", "gene_am_plot = gene_am[gene_am[\"n_variants\"] >= 2]\n", "\n", "colors = []\n", "for _, row in gene_am_plot.iterrows():\n", "    if row[\"gene\"] in COHORT_A_GENES:\n", "        colors.append(\"#E74C3C\")\n", "    elif row[\"gene\"] in COHORT_B_GENES:\n", "        colors.append(\"#3498DB\")\n", "    else:\n", "        colors.append(\"#95A5A6\")\n", "\n", "ax.barh(gene_am_plot[\"gene\"], gene_am_plot[\"n_variants\"], color=colors, edgecolor=\"white\")\n", "ax.set_xlabel(\"Number of Missense Variants\")\n", "ax.set_title(\"B) HRR Missense Variants by Gene\")\n", "\n", "# Legend\n", "patches = [\n", "    mpatches.Patch(color=\"#E74C3C\", label=\"Cohort A (BRCA1/2, ATM)\"),\n", "    mpatches.Patch(color=\"#3498DB\", label=\"Cohort B (PROfound)\"),\n", "    mpatches.Patch(color=\"#95A5A6\", label=\"Extended DDR\"),\n", "]\n", "ax.legend(handles=patches, fontsize=8, loc=\"lower right\")\n", "\n", "plt.tight_layout()\n", "plt.savefig(FIG_DIR / \"Fig1_AM_distribution.png\", dpi=300)\n", "plt.savefig(FIG_DIR / \"Fig1_AM_distribution.pdf\")\n", "plt.show()\n", "print(\"‚úÖ Figure 1 saved\")\n"]}, {"cell_type": "code", "execution_count": 17, "id": "1592cf9c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["‚úÖ Figure 2 saved\n"]}], "source": ["# ============================================================\n", "# 8B. FIGURE 2 ‚Äî Concordance Heatmap (AM vs ClinVar)\n", "# ============================================================\n", "\n", "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n", "\n", "# Panel A: Confusion matrix heatmap\n", "ax = axes[0]\n", "if len(concordance) > 0 and 'conc_known' in dir() and len(conc_known) > 0:\n", "    # 3x3 confusion: ClinVar (P/LP, VUS, B/LB) √ó AM (pathogenic, ambiguous, benign)\n", "    all_conc = concordance[concordance[\"cv_simple\"].isin([\"P/LP\", \"VUS\", \"B/LB\"])].copy()\n", "\n", "    cv_order = [\"P/LP\", \"VUS\", \"B/LB\"]\n", "    am_order = [\"pathogenic\", \"ambiguous\", \"benign\"]\n", "\n", "    ct = pd.crosstab(\n", "        all_conc[\"cv_simple\"],\n", "        all_conc[\"am_class\"],\n", "    ).reindex(index=cv_order, columns=am_order, fill_value=0)\n", "\n", "    sns.heatmap(ct, annot=True, fmt=\"d\", cmap=\"YlOrRd\", ax=ax,\n", "                cbar_kws={\"label\": \"Number of variants\"})\n", "    ax.set_xlabel(\"AlphaMissense Classification\")\n", "    ax.set_ylabel(\"ClinVar Classification\")\n", "    ax.set_title(\"A) AlphaMissense vs ClinVar\\nConcordance Matrix\")\n", "\n", "    # Add kappa annotation\n", "    if not np.isnan(kappa):\n", "        ax.text(0.02, 0.98, f\"Cohen's Œ∫ = {kappa:.3f}\",\n", "                transform=ax.transAxes, fontsize=10, va=\"top\",\n", "                bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8))\n", "else:\n", "    ax.text(0.5, 0.5, \"Concordance data\\nnot available\",\n", "            ha=\"center\", va=\"center\", fontsize=12, color=\"gray\",\n", "            transform=ax.transAxes)\n", "    ax.set_title(\"A) AlphaMissense vs ClinVar\")\n", "\n", "# Panel B: VUS Reclassification (bar chart as Sankey alternative)\n", "ax = axes[1]\n", "if len(concordance) > 0:\n", "    vus_data = concordance[concordance[\"cv_simple\"] == \"VUS\"]\n", "    if len(vus_data) > 0:\n", "        reclass_counts = vus_data[\"am_class\"].value_counts().reindex(\n", "            [\"pathogenic\", \"ambiguous\", \"benign\"], fill_value=0\n", "        )\n", "        bars = ax.bar(\n", "            reclass_counts.index,\n", "            reclass_counts.values,\n", "            color=[\"#E74C3C\", \"#F39C12\", \"#3498DB\"],\n", "            edgecolor=\"white\"\n", "        )\n", "        ax.set_ylabel(\"Number of ClinVar VUS\")\n", "        ax.set_title(f\"B) VUS Reclassification by AlphaMissense\\n(n={len(vus_data)} VUS)\")\n", "        ax.set_xlabel(\"AlphaMissense Reclassification\")\n", "\n", "        # Add count labels\n", "        for bar, val in zip(bars, reclass_counts.values):\n", "            if val > 0:\n", "                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n", "                        str(val), ha=\"center\", va=\"bottom\", fontsize=11, fontweight=\"bold\")\n", "    else:\n", "        ax.text(0.5, 0.5, \"No VUS found\\nin matched data\",\n", "                ha=\"center\", va=\"center\", fontsize=12, color=\"gray\",\n", "                transform=ax.transAxes)\n", "else:\n", "    ax.text(0.5, 0.5, \"ClinVar √ó AM matching\\nnot available\",\n", "            ha=\"center\", va=\"center\", fontsize=12, color=\"gray\",\n", "            transform=ax.transAxes)\n", "    ax.set_title(\"B) VUS Reclassification\")\n", "\n", "plt.tight_layout()\n", "plt.savefig(FIG_DIR / \"Fig2_concordance.png\", dpi=300)\n", "plt.savefig(FIG_DIR / \"Fig2_concordance.pdf\")\n", "plt.show()\n", "print(\"‚úÖ Figure 2 saved\")\n"]}, {"cell_type": "code", "execution_count": 18, "id": "2a76d7ea", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["‚úÖ Figure 3 saved\n"]}], "source": ["# ============================================================\n", "# 8C. FIGURE 3 ‚Äî KAPLAN-MEIER CURVES\n", "# ============================================================\n", "\n", "fig, ax = plt.subplots(figsize=(8, 6))\n", "\n", "if len(df_surv) >= 5 and 'kmf_path' in dir():\n", "    # Plot KM curves\n", "    kmf_path.plot_survival_function(\n", "        ax=ax, color=\"#E74C3C\", linewidth=2, ci_show=True, ci_alpha=0.15\n", "    )\n", "    kmf_ben.plot_survival_function(\n", "        ax=ax, color=\"#3498DB\", linewidth=2, ci_show=True, ci_alpha=0.15\n", "    )\n", "\n", "    ax.set_xlabel(\"Time (months)\")\n", "    ax.set_ylabel(\"Overall Survival Probability\")\n", "    ax.set_title(\"Overall Survival by AlphaMissense HRR Classification\\n(TCGA-PRAD, patients with HRR missense variants)\")\n", "    ax.set_ylim(0, 1.05)\n", "\n", "    # Add log-rank p-value\n", "    if lr is not None:\n", "        p_text = f\"Log-rank p = {lr.p_value:.4f}\" if lr.p_value >= 0.0001 else f\"Log-rank p < 0.0001\"\n", "        ax.text(0.98, 0.02, p_text, transform=ax.transAxes,\n", "                fontsize=10, ha=\"right\", va=\"bottom\",\n", "                bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8))\n", "\n", "    # Add number at risk table below\n", "    # (Simple version ‚Äî lifelines has built-in but can be tricky)\n", "    ax.legend(loc=\"lower left\", fontsize=10)\n", "\n", "    # Add HR annotation if available\n", "    if cox_result is not None:\n", "        hr_text = f\"HR = {cox_result['hr']:.2f} (95% CI {cox_result['ci_low']:.2f}‚Äì{cox_result['ci_high']:.2f})\"\n", "        ax.text(0.98, 0.10, hr_text, transform=ax.transAxes,\n", "                fontsize=9, ha=\"right\", va=\"bottom\",\n", "                bbox=dict(boxstyle=\"round\", facecolor=\"lightyellow\", alpha=0.9))\n", "\n", "else:\n", "    ax.text(0.5, 0.5, \"Insufficient survival data\\nfor Kaplan-Meier analysis\\n\\n\"\n", "            \"(Expected for TCGA-PRAD:\\nlocalized disease, few events)\\n\\n\"\n", "            \"Definitive analysis in Notebook 3\\n(mCRPC PARP inhibitor cohort)\",\n", "            ha=\"center\", va=\"center\", fontsize=12, color=\"gray\",\n", "            transform=ax.transAxes)\n", "    ax.set_title(\"Overall Survival by AlphaMissense HRR Classification\")\n", "\n", "plt.tight_layout()\n", "plt.savefig(FIG_DIR / \"Fig3_kaplan_meier.png\", dpi=300)\n", "plt.savefig(FIG_DIR / \"Fig3_kaplan_meier.pdf\")\n", "plt.show()\n", "print(\"‚úÖ Figure 3 saved\")\n"]}, {"cell_type": "code", "execution_count": 19, "id": "e982397e", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["‚úÖ Figure 4 saved\n"]}], "source": ["# ============================================================\n", "# 8D. FIGURE 4 ‚Äî SENSITIVITY FOREST PLOT\n", "# ============================================================\n", "\n", "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n", "\n", "# Panel A: Threshold variation\n", "ax = axes[0]\n", "if len(df_thresh) > 0 and df_thresh[\"HR\"].notna().any():\n", "    valid = df_thresh.dropna(subset=[\"HR\"])\n", "    y_pos = range(len(valid))\n", "\n", "    ax.errorbar(\n", "        valid[\"HR\"], y_pos,\n", "        xerr=[valid[\"HR\"] - valid[\"CI_low\"], valid[\"CI_high\"] - valid[\"HR\"]],\n", "        fmt=\"o\", color=\"#2C3E50\", markersize=8, capsize=5, linewidth=1.5\n", "    )\n", "    ax.axvline(1.0, color=\"gray\", linestyle=\"--\", linewidth=1)\n", "    ax.set_yticks(list(y_pos))\n", "    ax.set_yticklabels([f\"‚â•{t:.3f} (n={int(n)})\" for t, n in zip(valid[\"threshold\"], valid[\"n_pathogenic\"])])\n", "    ax.set_xlabel(\"Hazard Ratio (95% CI)\")\n", "    ax.set_title(\"A) Threshold Variation\")\n", "    ax.set_xlim(0, max(3, valid[\"CI_high\"].max() * 1.2))\n", "else:\n", "    ax.text(0.5, 0.5, \"Threshold sensitivity\\nnot available\\n(insufficient events)\",\n", "            ha=\"center\", va=\"center\", fontsize=11, color=\"gray\",\n", "            transform=ax.transAxes)\n", "    ax.set_title(\"A) Threshold Variation\")\n", "\n", "# Panel B: Leave-One-Gene-Out\n", "ax = axes[1]\n", "if len(df_logo_res) > 0 and df_logo_res[\"HR\"].notna().any():\n", "    valid_logo = df_logo_res.dropna(subset=[\"HR\"])\n", "    y_pos = range(len(valid_logo))\n", "\n", "    ax.errorbar(\n", "        valid_logo[\"HR\"], y_pos,\n", "        xerr=[valid_logo[\"HR\"] - valid_logo[\"CI_low\"], valid_logo[\"CI_high\"] - valid_logo[\"HR\"]],\n", "        fmt=\"s\", color=\"#8E44AD\", markersize=8, capsize=5, linewidth=1.5\n", "    )\n", "    ax.axvline(1.0, color=\"gray\", linestyle=\"--\", linewidth=1)\n", "    ax.set_yticks(list(y_pos))\n", "    ax.set_yticklabels([f\"Excl. {g}\" for g in valid_logo[\"excluded_gene\"]])\n", "    ax.set_xlabel(\"Hazard Ratio (95% CI)\")\n", "    ax.set_title(\"B) Leave-One-Gene-Out\")\n", "    ax.set_xlim(0, max(3, valid_logo[\"CI_high\"].max() * 1.2))\n", "\n", "    # Add reference line for main analysis\n", "    if cox_result is not None:\n", "        ax.axvline(cox_result[\"hr\"], color=\"#E74C3C\", linestyle=\":\", linewidth=1, alpha=0.7)\n", "else:\n", "    ax.text(0.5, 0.5, \"LOGO sensitivity\\nnot available\\n(insufficient events)\",\n", "            ha=\"center\", va=\"center\", fontsize=11, color=\"gray\",\n", "            transform=ax.transAxes)\n", "    ax.set_title(\"B) Leave-One-Gene-Out\")\n", "\n", "plt.tight_layout()\n", "plt.savefig(FIG_DIR / \"Fig4_sensitivity.png\", dpi=300)\n", "plt.savefig(FIG_DIR / \"Fig4_sensitivity.pdf\")\n", "plt.show()\n", "print(\"‚úÖ Figure 4 saved\")\n"]}, {"cell_type": "code", "execution_count": 20, "id": "05878f35", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["‚úÖ Figure 5 saved\n"]}], "source": ["# ============================================================\n", "# 8E. FIGURE 5 ‚Äî GENE-LEVEL HEATMAP (AM classification √ó Gene √ó Patients)\n", "# ============================================================\n", "\n", "fig, ax = plt.subplots(figsize=(10, 8))\n", "\n", "# Create a patient √ó gene matrix showing AM classification\n", "# Rows = patients with HRR variants, Columns = genes\n", "patients = df_var[\"sample_id\"].unique()\n", "genes = sorted(df_var[\"gene\"].unique())\n", "\n", "# Map: 0 = no variant, 1 = benign, 2 = ambiguous, 3 = pathogenic\n", "matrix = np.zeros((len(patients), len(genes)))\n", "pat_to_idx = {p: i for i, p in enumerate(patients)}\n", "gene_to_idx = {g: i for i, g in enumerate(genes)}\n", "\n", "for _, row in df_var.iterrows():\n", "    pi = pat_to_idx[row[\"sample_id\"]]\n", "    gi = gene_to_idx[row[\"gene\"]]\n", "    if row[\"am_class\"] == \"pathogenic\":\n", "        matrix[pi, gi] = max(matrix[pi, gi], 3)\n", "    elif row[\"am_class\"] == \"ambiguous\":\n", "        matrix[pi, gi] = max(matrix[pi, gi], 2)\n", "    elif row[\"am_class\"] == \"benign\":\n", "        matrix[pi, gi] = max(matrix[pi, gi], 1)\n", "\n", "# Sort patients by number of pathogenic variants (descending)\n", "path_count = (matrix == 3).sum(axis=1)\n", "sort_idx = np.argsort(-path_count)\n", "matrix = matrix[sort_idx]\n", "\n", "# Custom colormap\n", "from matplotlib.colors import ListedColormap\n", "cmap = ListedColormap([\"#FFFFFF\", \"#3498DB\", \"#F39C12\", \"#E74C3C\"])\n", "\n", "im = ax.imshow(matrix, aspect=\"auto\", cmap=cmap, vmin=0, vmax=3, interpolation=\"nearest\")\n", "\n", "ax.set_xticks(range(len(genes)))\n", "ax.set_xticklabels(genes, rotation=45, ha=\"right\", fontsize=8)\n", "ax.set_ylabel(f\"Patients (n={len(patients)})\")\n", "ax.set_title(\"AlphaMissense Classification of HRR Missense Variants\\n(TCGA-PRAD)\")\n", "\n", "# Colorbar legend\n", "cbar = plt.colorbar(im, ax=ax, ticks=[0, 1, 2, 3], shrink=0.6)\n", "cbar.ax.set_yticklabels([\"No variant\", \"AM-Benign\", \"AM-Ambiguous\", \"AM-Pathogenic\"])\n", "\n", "# Mark cohort A genes\n", "for gi, gene in enumerate(genes):\n", "    if gene in COHORT_A_GENES:\n", "        ax.get_xticklabels()[gi].set_fontweight(\"bold\")\n", "        ax.get_xticklabels()[gi].set_color(\"#E74C3C\")\n", "\n", "plt.tight_layout()\n", "plt.savefig(FIG_DIR / \"Fig5_gene_heatmap.png\", dpi=300)\n", "plt.savefig(FIG_DIR / \"Fig5_gene_heatmap.pdf\")\n", "plt.show()\n", "print(\"‚úÖ Figure 5 saved\")\n"]}, {"cell_type": "markdown", "id": "162f7da7", "metadata": {}, "source": ["## 8. Summary of Results & Export"]}, {"cell_type": "code", "execution_count": 21, "id": "81e8d698", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["======================================================================\n", "  NOTEBOOK 2 ‚Äî EXECUTIVE SUMMARY OF RESULTS\n", "======================================================================\n", "\n", "üìä DATASET\n", "   TCGA-PRAD: 52 HRR missense variants in 40 patients\n", "   Genes: 19 HRR genes\n", "\n", "üî¨ AlphaMissense CLASSIFICATION\n", "   Pathogenic  : 19 variants (36.5%)\n", "   Ambiguous   : 1 variants (1.9%)\n", "   Benign      : 31 variants (59.6%)\n", "\n", "üîó CONCORDANCE (AM vs ClinVar)\n", "   Cohen's kappa: 0.733\n", "\n", "üìà SURVIVAL (OS)\n", "   Cox model: not computed (insufficient events)\n", "   Expected for localized TCGA-PRAD ‚Äî see Notebook 3 for mCRPC\n", "   Log-rank: p=0.3442\n", "\n", "üìã OUTPUT FILES\n", "   ‚úÖ figures/Fig1_AM_distribution.png\n", "   ‚úÖ figures/Fig2_concordance.png\n", "   ‚úÖ figures/Fig3_kaplan_meier.png\n", "   ‚úÖ figures/Fig4_sensitivity.png\n", "   ‚úÖ figures/Fig5_gene_heatmap.png\n", "   ‚úÖ results/analysis_dataset.csv\n", "   ‚úÖ results/annotated_hrr_variants.csv\n", "   ‚úÖ results/concordance_results.csv\n", "   ‚úÖ results/patient_hrr_summary.csv\n", "   ‚úÖ results/sensitivity_logo.csv\n", "   ‚úÖ results/sensitivity_threshold.csv\n", "   ‚úÖ results/table_gene_summary.csv\n", "   ‚úÖ results/vus_reclassification.csv\n", "\n", "======================================================================\n", "  PUBLICATION ASSESSMENT\n", "======================================================================\n", "\n", "  Key question: Is there signal for publication?\n", "  ‚ö†Ô∏è  Exploratory ‚Äî only 1 events in TCGA-PRAD (localized disease)\n", "     This is EXPECTED and does not invalidate the paper.\n", "     The paper's strength comes from:\n", "       1. VUS reclassification yield (direct clinical utility)\n", "       2. Concordance with ClinVar (validation of the tool)\n", "       3. Notebook 3 will add mCRPC PARP cohort for treatment response\n", "     Target: JCO Precision Oncology (brief communication / tools validation)\n", "\n", "  NEXT STEP: Notebook 3 ‚Äî Validation in mCRPC PARP Inhibitor Cohort\n", "  This will provide the clinically definitive test with treatment response data.\n"]}], "source": ["# ============================================================\n", "# 9. EXECUTIVE SUMMARY\n", "# ============================================================\n", "\n", "print(\"=\" * 70)\n", "print(\"  NOTEBOOK 2 ‚Äî EXECUTIVE SUMMARY OF RESULTS\")\n", "print(\"=\" * 70)\n", "\n", "print(f\"\\nüìä DATASET\")\n", "print(f\"   TCGA-PRAD: {len(df_var)} HRR missense variants in {df_var['sample_id'].nunique()} patients\")\n", "print(f\"   Genes: {df_var['gene'].nunique()} HRR genes\")\n", "\n", "print(f\"\\nüî¨ AlphaMissense CLASSIFICATION\")\n", "for c in [\"pathogenic\", \"ambiguous\", \"benign\"]:\n", "    n = (df_var[\"am_class\"] == c).sum()\n", "    print(f\"   {c.capitalize():12s}: {n} variants ({100*n/len(df_var):.1f}%)\")\n", "\n", "if not np.isnan(kappa) if isinstance(kappa, float) else True:\n", "    print(f\"\\nüîó CONCORDANCE (AM vs ClinVar)\")\n", "    print(f\"   Cohen's kappa: {kappa:.3f}\")\n", "\n", "print(f\"\\nüìà SURVIVAL (OS)\")\n", "if cox_result is not None:\n", "    print(f\"   HR (AM-Pathogenic vs Benign/Ambig): {cox_result['hr']:.2f} \"\n", "          f\"(95% CI {cox_result['ci_low']:.2f}‚Äì{cox_result['ci_high']:.2f})\")\n", "    print(f\"   p-value: {cox_result['p']:.4f}\")\n", "else:\n", "    print(f\"   Cox model: not computed (insufficient events)\")\n", "    print(f\"   Expected for localized TCGA-PRAD ‚Äî see Notebook 3 for mCRPC\")\n", "\n", "if lr is not None:\n", "    print(f\"   Log-rank: p={lr.p_value:.4f}\")\n", "\n", "print(f\"\\nüìã OUTPUT FILES\")\n", "output_files = list(RESULTS_DIR.glob(\"*.csv\")) + list(FIG_DIR.glob(\"*.png\"))\n", "for f in sorted(output_files):\n", "    print(f\"   ‚úÖ {f}\")\n", "\n", "print(f\"\\n{'='*70}\")\n", "print(f\"  PUBLICATION ASSESSMENT\")\n", "print(f\"{'='*70}\")\n", "print(f\"\\n  Key question: Is there signal for publication?\")\n", "n_events = df_analysis[\"os_event\"].sum() if \"os_event\" in df_analysis else 0\n", "if n_events >= 5 and cox_result is not None:\n", "    print(f\"  ‚úÖ Yes ‚Äî survival signal detected with {n_events:.0f} events\")\n", "    print(f\"     HR = {cox_result['hr']:.2f}, which {'crosses' if cox_result['ci_low'] <= 1 <= cox_result['ci_high'] else 'does not cross'} 1.0\")\n", "else:\n", "    print(f\"  ‚ö†Ô∏è  Exploratory ‚Äî only {n_events:.0f} events in TCGA-PRAD (localized disease)\")\n", "    print(f\"     This is EXPECTED and does not invalidate the paper.\")\n", "    print(f\"     The paper's strength comes from:\")\n", "    print(f\"       1. VUS reclassification yield (computational reclassification yield)\")\n", "    print(f\"       2. Concordance with ClinVar (validation of the tool)\")\n", "    print(f\"       3. Notebook 3 will add mCRPC PARP cohort for treatment response\")\n", "    print(f\"     Target: JCO Precision Oncology (brief communication / tools validation)\")\n", "\n", "print(f\"\\n  NEXT STEP: Notebook 3 ‚Äî Validation in mCRPC PARP Inhibitor Cohort\")\n", "print(f\"  This will provide the clinically definitive test with treatment response data.\")\n", ""]}, {"cell_type": "markdown", "metadata": {}, "source": ["## ‚ö†Ô∏è Limitations & Intended Use", "", "**This analysis is hypothesis-generating and not intended for clinical decision-making.**", "", "Key limitations:", "- AlphaMissense predictions are **computational annotations**, not clinical reclassifications per ACMG/AMP standards.", "- The VUS \"reclassification\" reported here is a **computational triage** ‚Äî it does not replace expert curation, functional assays, or clinical-grade variant interpretation.", "- Concordance with ClinVar does not guarantee correctness for individual variants, particularly in under-represented genes or populations.", "- Survival analysis is **univariate** (no adjustment for age, stage, treatment, or other confounders) and should be interpreted as associative, not causal.", "- These results require **prospective clinical validation** before any integration into treatment decisions or molecular tumor board workflows.", "", "For clinical use, AlphaMissense scores should be considered as **PP3/BP4-level supporting evidence** within the ACMG/AMP framework, not as standalone determinants."]}, {"cell_type": "markdown", "id": "aeeec2a2", "metadata": {}, "source": ["## ‚úÖ Notebook 2 Complete!\n", "\n", "### Key Results Files:\n", "| File | Description |\n", "|------|-------------|\n", "| `results/analysis_dataset.csv` | Full analysis dataset (variants + clinical + AM) |\n", "| `results/table_gene_summary.csv` | Gene-level summary table |\n", "| `results/concordance_results.csv` | AM vs ClinVar concordance metrics |\n", "| `results/vus_reclassification.csv` | VUS reclassification details |\n", "| `results/sensitivity_threshold.csv` | Threshold variation results |\n", "| `results/sensitivity_logo.csv` | Leave-one-gene-out results |\n", "| `figures/Fig1_AM_distribution.png/pdf` | AM score distribution + gene barplot |\n", "| `figures/Fig2_concordance.png/pdf` | Concordance heatmap + VUS reclassification |\n", "| `figures/Fig3_kaplan_meier.png/pdf` | Kaplan-Meier survival curves |\n", "| `figures/Fig4_sensitivity.png/pdf` | Sensitivity forest plots |\n", "| `figures/Fig5_gene_heatmap.png/pdf` | Patient √ó Gene heatmap |\n", "\n", "### Next: Notebook 3 ‚Äî Validation in PARP Inhibitor Cohort\n", "- Download mCRPC cohorts (MSK-IMPACT, SU2C/PCF) from cBioPortal\n", "- Filter for patients treated with PARP inhibitors (olaparib, rucaparib)\n", "- Repeat AlphaMissense annotation + survival analysis\n", "- Correlate AM reclassification with PARP response\n", "\n", "---\n", "*Notebook created by Research OS ‚Äî Clinical Computational Oncology Pipeline*\n", "*AlphaMissense: Cheng et al., Science 2023. DOI: 10.1126/science.adg7492*\n", "*Survival analysis: lifelines (Davidson-Pilon, JOSS 2019)*\n"]}], "metadata": {"kernelspec": {"display_name": ".venv", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.12.3"}}, "nbformat": 4, "nbformat_minor": 5}