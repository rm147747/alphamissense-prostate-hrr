{"cells": [{"cell_type": "markdown", "id": "1f9ff6a4", "metadata": {}, "source": ["# Notebook 3 — Validation in mCRPC Cohorts\n", "\n", "## AlphaMissense-Guided VUS Reclassification: Clinical Validation with Survival Outcomes\n", "\n", "**Goal:** Validate that AlphaMissense reclassification of HRR VUS correlates with clinical outcomes in metastatic castration-resistant prostate cancer (mCRPC), where events are frequent and HRR status drives treatment decisions (PARP inhibitors).\n", "\n", "**Notebook 2 established:**\n", "- ClinVar concordance kappa = 0.733 (substantial agreement)\n", "- 90.1% of VUS reclassified (21.5% pathogenic, 68.7% benign)\n", "- TCGA-PRAD survival: only 1 event in 40 patients (localized disease)\n", "\n", "**This notebook adds:** mCRPC cohorts with real survival data to test clinical relevance.\n", "\n", "**Public cBioPortal Cohorts:**\n", "\n", "| Study ID | Description | n | Key Feature |\n", "|----------|-------------|---|-------------|\n", "| `prad_su2c_2019` | SU2C/PCF Dream Team mCRPC | ~444 | Deep sequencing, survival |\n", "| `prad_msk_2019` | MSK-IMPACT Prostate | ~1013 | Large panel cohort |\n", "| `prad_eururol_2017` | Robinson et al. mCRPC WES/WGS | ~150 | Whole-genome |\n"]}, {"cell_type": "code", "execution_count": 1, "id": "b7b19227", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": ["/workspaces/alphamissense-prostate-hrr/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n", "  from .autonotebook import tqdm as notebook_tqdm\n"]}, {"name": "stdout", "output_type": "stream", "text": ["Setup complete\n"]}], "source": ["# REPRODUCIBILITY: Install dependencies via `pip install -r requirements.txt`\n# Do NOT pip-install inside the notebook — use pinned versions from requirements.txt\n"]}, {"cell_type": "markdown", "id": "3c9d0994", "metadata": {}, "source": ["## 2. Download mCRPC Cohorts from cBioPortal"]}, {"cell_type": "code", "execution_count": 2, "id": "0c83790c", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "Downloading: SU2C/PCF mCRPC 2019 (prad_su2c_2019)\n", "    mutations: HTTP 403\n", "    clinical_patient: HTTP 403\n", "    clinical_sample: HTTP 403\n", "  Trying API fallback...\n", "    mutations (API): 40,055 rows\n", "    clinical_patient (API): 2,699 rows\n", "    clinical_sample (API): 10,191 rows\n", "\n", "Downloading: MSK-IMPACT Prostate 2019 (prad_msk_2019)\n", "    mutations: HTTP 403\n", "    clinical_patient: HTTP 403\n", "    clinical_sample: HTTP 403\n", "  Trying API fallback...\n", "    mutations (API): 26 rows\n", "    clinical_patient (API): 20 rows\n", "    clinical_sample (API): 192 rows\n", "\n", "Downloading: Robinson et al. mCRPC 2017 (prad_eururol_2017)\n", "    mutations: HTTP 403\n", "    clinical_patient: HTTP 403\n", "    clinical_sample: HTTP 403\n", "  Trying API fallback...\n", "    mutations (API): 1,257 rows\n", "    clinical_patient (API): 672 rows\n", "    clinical_sample (API): 581 rows\n", "\n", "============================================================\n", "Downloaded: 3/3 studies\n", "  prad_su2c_2019: 40,055 mutations\n", "  prad_msk_2019: 26 mutations\n", "  prad_eururol_2017: 1,257 mutations\n"]}], "source": ["# ============================================================\n", "# 2. DOWNLOAD mCRPC COHORTS\n", "# ============================================================\n", "\n", "CBIO_DATAHUB = \"https://cbioportal-datahub.s3.amazonaws.com\"\n", "\n", "STUDIES = [\n", "    {\"id\": \"prad_su2c_2019\", \"name\": \"SU2C/PCF mCRPC 2019\"},\n", "    {\"id\": \"prad_msk_2019\", \"name\": \"MSK-IMPACT Prostate 2019\"},\n", "    {\"id\": \"prad_eururol_2017\", \"name\": \"Robinson et al. mCRPC 2017\"},\n", "]\n", "\n", "def download_from_datahub(study_id):\n", "    result = {}\n", "    files = {\n", "        \"mutations\": f\"{CBIO_DATAHUB}/{study_id}/data_mutations.txt\",\n", "        \"clinical_patient\": f\"{CBIO_DATAHUB}/{study_id}/data_clinical_patient.txt\",\n", "        \"clinical_sample\": f\"{CBIO_DATAHUB}/{study_id}/data_clinical_sample.txt\",\n", "    }\n", "    for key, url in files.items():\n", "        try:\n", "            resp = requests.get(url, timeout=120)\n", "            if resp.status_code == 200 and len(resp.text) > 100:\n", "                df = pd.read_csv(io.StringIO(resp.text), sep=\"\\t\", comment=\"#\", low_memory=False)\n", "                result[key] = df\n", "                print(f\"    {key}: {len(df):,} rows\")\n", "            else:\n", "                print(f\"    {key}: HTTP {resp.status_code}\")\n", "                result[key] = None\n", "        except Exception as e:\n", "            print(f\"    {key}: failed ({e})\")\n", "            result[key] = None\n", "    return result\n", "\n", "# If datahub fails, try the API\n", "def download_from_api(study_id):\n", "    CBIO_API = \"https://www.cbioportal.org/api\"\n", "    result = {\"mutations\": None, \"clinical_patient\": None, \"clinical_sample\": None}\n", "    \n", "    # Mutations via API\n", "    try:\n", "        profiles = requests.get(\n", "            f\"{CBIO_API}/studies/{study_id}/molecular-profiles\",\n", "            headers={\"Accept\":\"application/json\"}, timeout=30\n", "        ).json()\n", "        mut_profile = next((p[\"molecularProfileId\"] for p in profiles\n", "                           if p[\"molecularAlterationType\"] == \"MUTATION_EXTENDED\"), None)\n", "        if mut_profile:\n", "            resp = requests.post(\n", "                f\"{CBIO_API}/molecular-profiles/{mut_profile}/mutations/fetch\",\n", "                headers={\"Accept\":\"application/json\",\"Content-Type\":\"application/json\"},\n", "                json={\"sampleListId\": f\"{study_id}_all\"},\n", "                params={\"projection\": \"DETAILED\"},\n", "                timeout=120\n", "            )\n", "            if resp.status_code == 200:\n", "                result[\"mutations\"] = pd.json_normalize(resp.json())\n", "                print(f\"    mutations (API): {len(result['mutations']):,} rows\")\n", "    except Exception as e:\n", "        print(f\"    mutations API failed: {e}\")\n", "    \n", "    # Clinical via API\n", "    for dtype in [\"PATIENT\", \"SAMPLE\"]:\n", "        try:\n", "            resp = requests.get(\n", "                f\"{CBIO_API}/studies/{study_id}/clinical-data\",\n", "                headers={\"Accept\":\"application/json\"},\n", "                params={\"clinicalDataType\": dtype, \"projection\": \"DETAILED\"},\n", "                timeout=60\n", "            ).json()\n", "            key = \"clinical_patient\" if dtype == \"PATIENT\" else \"clinical_sample\"\n", "            result[key] = pd.json_normalize(resp)\n", "            print(f\"    {key} (API): {len(result[key]):,} rows\")\n", "        except:\n", "            pass\n", "    return result\n", "\n", "# Download all\n", "all_studies = {}\n", "for study in STUDIES:\n", "    sid = study[\"id\"]\n", "    print(f\"\\nDownloading: {study['name']} ({sid})\")\n", "    \n", "    # Try datahub first\n", "    data = download_from_datahub(sid)\n", "    \n", "    # Fallback to API if mutations missing\n", "    if data.get(\"mutations\") is None:\n", "        print(\"  Trying API fallback...\")\n", "        data = download_from_api(sid)\n", "    \n", "    if data.get(\"mutations\") is not None:\n", "        all_studies[sid] = data\n", "        save_dir = DATA_DIR / \"validation\" / sid\n", "        save_dir.mkdir(parents=True, exist_ok=True)\n", "        for key, df in data.items():\n", "            if df is not None:\n", "                df.to_csv(save_dir / f\"{key}.csv\", index=False)\n", "    else:\n", "        print(f\"  SKIPPED — no mutation data\")\n", "\n", "print(f\"\\n{'='*60}\")\n", "print(f\"Downloaded: {len(all_studies)}/{len(STUDIES)} studies\")\n", "for sid in all_studies:\n", "    nm = len(all_studies[sid][\"mutations\"]) if all_studies[sid][\"mutations\"] is not None else 0\n", "    print(f\"  {sid}: {nm:,} mutations\")\n"]}, {"cell_type": "markdown", "id": "8df7db54", "metadata": {}, "source": ["## 3. Filter HRR Missense & Annotate with AlphaMissense"]}, {"cell_type": "code", "execution_count": 16, "id": "f0ed40d5", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["AlphaMissense lookup: 554,363 variants\n", "\n", "==================================================\n", "Processing prad_su2c_2019 (40,055 mutations)\n", "==================================================\n", "  Columns: gene='gene.hugoGeneSymbol', class='mutationType', sample='sampleId', hgvsp='proteinChange', patient='patientId'\n", "  HRR mutations (all types): 174\n", "  HRR missense: 66\n", "  Parsed: 66/66\n", "  AM matched: 65/66 (98.5%)\n", "\n", "  Gene breakdown:\n", "    ATM: 8 (1 pathogenic)\n", "    BRCA2: 7 (2 pathogenic)\n", "    CDK12: 6 (5 pathogenic)\n", "    BRCA1: 5 (2 pathogenic)\n", "    PALB2: 5 (0 pathogenic)\n", "    ATR: 4 (1 pathogenic)\n", "    CHEK2: 4 (2 pathogenic)\n", "    FANCA: 3 (0 pathogenic)\n", "    BARD1: 3 (0 pathogenic)\n", "    BRIP1: 3 (2 pathogenic)\n", "    RAD50: 3 (1 pathogenic)\n", "    FANCF: 2 (1 pathogenic)\n", "    NBN: 2 (1 pathogenic)\n", "    RAD54L: 2 (2 pathogenic)\n", "    FANCE: 2 (0 pathogenic)\n", "    FANCG: 2 (0 pathogenic)\n", "    FANCD2: 2 (0 pathogenic)\n", "    RAD51D: 1 (0 pathogenic)\n", "    MRE11: 1 (0 pathogenic)\n", "    ATRX: 1 (0 pathogenic)\n", "\n", "==================================================\n", "Processing prad_msk_2019 (26 mutations)\n", "==================================================\n", "  Columns: gene='gene.hugoGeneSymbol', class='mutationType', sample='sampleId', hgvsp='proteinChange', patient='patientId'\n", "  HRR mutations (all types): 1\n", "  HRR missense: 1\n", "  Parsed: 1/1\n", "  AM matched: 1/1 (100.0%)\n", "\n", "  Gene breakdown:\n", "    ATR: 1 (0 pathogenic)\n", "\n", "==================================================\n", "Processing prad_eururol_2017 (1,257 mutations)\n", "==================================================\n", "  Columns: gene='gene.hugoGeneSymbol', class='mutationType', sample='sampleId', hgvsp='proteinChange', patient='patientId'\n", "  HRR mutations (all types): 8\n", "  HRR missense: 5\n", "  Parsed: 5/5\n", "  AM matched: 5/5 (100.0%)\n", "\n", "  Gene breakdown:\n", "    CDK12: 2 (2 pathogenic)\n", "    BRCA1: 1 (0 pathogenic)\n", "    FANCD2: 1 (0 pathogenic)\n", "    ATM: 1 (0 pathogenic)\n", "\n", "✅ Total: 72 variants, 58 patients\n"]}], "source": ["# ============================================================\n", "# 3. FILTER HRR MISSENSE + ANNOTATE (FIXED v2)\n", "# ============================================================\n", "\n", "am_path = DATA_DIR / \"processed\" / \"alphamissense_hrr_genes.csv\"\n", "if am_path.exists():\n", "    df_am = pd.read_csv(am_path)\n", "    am_lookup = {}\n", "    for _, row in df_am.iterrows():\n", "        key = f\"{row['uniprot_id']}_{row['protein_variant']}\"\n", "        am_lookup[key] = (row['am_pathogenicity'], row['am_class'])\n", "    print(f\"AlphaMissense lookup: {len(am_lookup):,} variants\")\n", "else:\n", "    am_lookup = {}\n", "\n", "def annotate_cohort(df_mut, study_id):\n", "    gene_col = class_col = sample_col = hgvsp_col = patient_col = None\n", "    for c in [\"Hugo_Symbol\", \"gene.hugoGeneSymbol\", \"hugoGeneSymbol\"]:\n", "        if c in df_mut.columns: gene_col = c; break\n", "    for c in [\"Variant_Classification\", \"mutationType\"]:\n", "        if c in df_mut.columns: class_col = c; break\n", "    for c in [\"Tumor_Sample_Barcode\", \"sampleId\"]:\n", "        if c in df_mut.columns: sample_col = c; break\n", "    for c in [\"HGVSp_Short\", \"proteinChange\", \"HGVSp\"]:\n", "        if c in df_mut.columns: hgvsp_col = c; break\n", "    # Patient ID column (API includes this)\n", "    if \"patientId\" in df_mut.columns:\n", "        patient_col = \"patientId\"\n", "\n", "    if not all([gene_col, class_col, sample_col, hgvsp_col]):\n", "        print(f\"  Missing columns: gene={gene_col}, class={class_col}, sample={sample_col}, hgvsp={hgvsp_col}\")\n", "        return pd.DataFrame()\n", "\n", "    print(f\"  Columns: gene='{gene_col}', class='{class_col}', sample='{sample_col}', hgvsp='{hgvsp_col}', patient='{patient_col}'\")\n", "\n", "    df_hrr = df_mut[df_mut[gene_col].isin(HRR_GENES_ALL)].copy()\n", "    print(f\"  HRR mutations (all types): {len(df_hrr)}\")\n", "\n", "    df_miss = df_hrr[df_hrr[class_col].str.contains(\"issense\", case=False, na=False)].copy()\n", "    print(f\"  HRR missense: {len(df_miss)}\")\n", "    if len(df_miss) == 0:\n", "        return pd.DataFrame()\n", "\n", "    aa3to1 = {'Ala':'A','Arg':'R','Asn':'N','Asp':'D','Cys':'C','Gln':'Q',\n", "              'Glu':'E','Gly':'G','His':'H','Ile':'I','Leu':'L','Lys':'K',\n", "              'Met':'M','Phe':'F','Pro':'P','Ser':'S','Thr':'T','Trp':'W',\n", "              'Tyr':'Y','Val':'V','Ter':'*','Sec':'U'}\n", "\n", "    def parse_protein(val):\n", "        if pd.isna(val): return None\n", "        s = str(val).strip()\n", "        m3 = re.match(r'p\\.([A-Z][a-z]{2})(\\d+)([A-Z][a-z]{2})', s)\n", "        if m3:\n", "            r, alt = aa3to1.get(m3.group(1)), aa3to1.get(m3.group(3))\n", "            if r and alt and r != alt: return (r, int(m3.group(2)), alt)\n", "        m1 = re.match(r'p\\.([A-Z*])(\\d+)([A-Z*])', s)\n", "        if m1 and m1.group(1) != m1.group(3):\n", "            return (m1.group(1), int(m1.group(2)), m1.group(3))\n", "        mb = re.match(r'^([A-Z])(\\d+)([A-Z])$', s)\n", "        if mb and mb.group(1) != mb.group(3):\n", "            return (mb.group(1), int(mb.group(2)), mb.group(3))\n", "        return None\n", "\n", "    parsed = df_miss[hgvsp_col].apply(parse_protein)\n", "    print(f\"  Parsed: {parsed.notna().sum()}/{len(df_miss)}\")\n", "\n", "    df_miss = df_miss[parsed.notna()].copy()\n", "    parsed = parsed[parsed.notna()]\n", "\n", "    df_miss[\"ref_aa\"] = [p[0] for p in parsed]\n", "    df_miss[\"protein_pos\"] = [p[1] for p in parsed]\n", "    df_miss[\"alt_aa\"] = [p[2] for p in parsed]\n", "    df_miss[\"gene\"] = df_miss[gene_col]\n", "    df_miss[\"sample_id\"] = df_miss[sample_col]\n", "    # Use patientId from mutations table if available\n", "    df_miss[\"patient_id\"] = df_miss[patient_col] if patient_col else df_miss[sample_col]\n", "    df_miss[\"protein_change\"] = df_miss[hgvsp_col]\n", "    df_miss[\"uniprot_id\"] = df_miss[\"gene\"].map(GENE_TO_UNIPROT)\n", "\n", "    scores, classes = [], []\n", "    for _, row in df_miss.iterrows():\n", "        key = f\"{row.get('uniprot_id','')}_{row['ref_aa']}{row['protein_pos']}{row['alt_aa']}\"\n", "        if key in am_lookup:\n", "            scores.append(am_lookup[key][0])\n", "            classes.append(am_lookup[key][1])\n", "        else:\n", "            scores.append(np.nan)\n", "            classes.append(\"not_found\")\n", "\n", "    df_miss[\"am_pathogenicity\"] = scores\n", "    df_miss[\"am_class\"] = classes\n", "    df_miss[\"study_id\"] = study_id\n", "    df_miss[\"hrr_cohort\"] = df_miss[\"gene\"].apply(\n", "        lambda g: \"A\" if g in COHORT_A_GENES else (\"B\" if g in COHORT_B_GENES else \"Ext\")\n", "    )\n", "\n", "    n_found = sum(1 for c in classes if c != \"not_found\")\n", "    print(f\"  AM matched: {n_found}/{len(df_miss)} ({100*n_found/len(df_miss):.1f}%)\")\n", "\n", "    return df_miss[[\"study_id\",\"sample_id\",\"patient_id\",\"gene\",\"protein_change\",\"ref_aa\",\n", "                     \"protein_pos\",\"alt_aa\",\"uniprot_id\",\"am_pathogenicity\",\n", "                     \"am_class\",\"hrr_cohort\"]].copy()\n", "\n", "all_variants = []\n", "for sid, data in all_studies.items():\n", "    print(f\"\\n{'='*50}\")\n", "    print(f\"Processing {sid} ({len(data['mutations']):,} mutations)\")\n", "    print(f\"{'='*50}\")\n", "    df_ann = annotate_cohort(data[\"mutations\"], sid)\n", "    if len(df_ann) > 0:\n", "        all_variants.append(df_ann)\n", "        print(f\"\\n  Gene breakdown:\")\n", "        for g, cnt in df_ann[\"gene\"].value_counts().items():\n", "            n_p = (df_ann[df_ann[\"gene\"]==g][\"am_class\"]==\"pathogenic\").sum()\n", "            print(f\"    {g}: {cnt} ({n_p} pathogenic)\")\n", "\n", "if all_variants:\n", "    df_val = pd.concat(all_variants, ignore_index=True)\n", "    df_val.to_csv(RESULTS_DIR / \"validation_hrr_variants.csv\", index=False)\n", "    print(f\"\\n✅ Total: {len(df_val)} variants, {df_val['patient_id'].nunique()} patients\")\n", "else:\n", "    df_val = pd.DataFrame()\n", "    print(\"\\n❌ No variants found\")"]}, {"cell_type": "markdown", "id": "7d9dcce8", "metadata": {}, "source": ["## 4. Merge with Clinical Data & Build Survival Dataset"]}, {"cell_type": "code", "execution_count": 18, "id": "cf5a3b3b", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "============================================================\n", "Clinical merge: prad_su2c_2019\n", "============================================================\n", "  Clinical: 429 patients, columns: ['AGE_AT_DIAGNOSIS', 'CHEMO_REGIMEN_CATEGORY', 'OS_MONTHS', 'OS_STATUS', 'PSA', 'RACE', 'SAMPLE_COUNT', 'SEX', 'patientId']...\n", "  Patients with HRR missense: 54\n", "    AM-Pathogenic: 19\n", "    AM-Benign/Amb: 35\n", "  ✅ OS data: 18 patients, 11 events\n", "     Median follow-up: 18.7 months\n", "  Saved: 54 patients\n", "\n", "============================================================\n", "Clinical merge: prad_msk_2019\n", "============================================================\n", "  Clinical: 10 patients, columns: ['SAMPLE_COUNT', 'SEX', 'patientId']...\n", "  Patients with HRR missense: 1\n", "    AM-Pathogenic: 0\n", "    AM-Benign/Amb: 1\n", "  ⚠️ OS not found. Cols: []\n", "  Saved: 1 patients\n", "\n", "============================================================\n", "Clinical merge: prad_eururol_2017\n", "============================================================\n", "  Clinical: 65 patients, columns: ['AGE', 'BLADDER_NECK_INVASION', 'EXTRAPROSTATIC_EXTENSION', 'FPSA_PSA', 'GLEASON_SCORE', 'LYMPH_NODE_METASTASIS', 'PSA', 'SAMPLE_COUNT', 'SEMINAL_VESICLE_INVASION', 'SEX', 'TNMSTAGE', 'patientId']...\n", "  Patients with HRR missense: 3\n", "    AM-Pathogenic: 1\n", "    AM-Benign/Amb: 2\n", "  ⚠️ OS not found. Cols: ['EXTRAPROSTATIC_EXTENSION']\n", "  Saved: 3 patients\n", "\n", "============================================================\n", "READY FOR SURVIVAL: 1 studies with events\n"]}], "source": ["# ============================================================\n", "# 4. MERGE WITH CLINICAL DATA (FIXED — uses patient_id from mutations)\n", "# ============================================================\n", "\n", "def pivot_if_long(df):\n", "    if df is None or len(df) == 0:\n", "        return pd.DataFrame()\n", "    if \"clinicalAttributeId\" in df.columns:\n", "        pid_col = \"patientId\" if \"patientId\" in df.columns else df.columns[0]\n", "        return df.pivot_table(index=pid_col, columns=\"clinicalAttributeId\",\n", "                               values=\"value\", aggfunc=\"first\").reset_index()\n", "    return df\n", "\n", "val_analyses = {}\n", "\n", "for sid, data in all_studies.items():\n", "    print(f\"\\n{'='*60}\")\n", "    print(f\"Clinical merge: {sid}\")\n", "    print(f\"{'='*60}\")\n", "\n", "    df_clin = pivot_if_long(data.get(\"clinical_patient\"))\n", "    if len(df_clin) == 0:\n", "        print(f\"  No clinical data\"); continue\n", "\n", "    print(f\"  Clinical: {len(df_clin)} patients, columns: {sorted(df_clin.columns.tolist())[:15]}...\")\n", "\n", "    df_vars = df_val[df_val[\"study_id\"] == sid]\n", "    if len(df_vars) == 0:\n", "        print(f\"  No HRR variants\"); continue\n", "\n", "    # Patient summary — GROUP BY patient_id (not sample_id)\n", "    pat_sum = df_vars.groupby(\"patient_id\").agg(\n", "        n_hrr=(\"gene\",\"count\"),\n", "        n_path=(\"am_class\", lambda x: (x==\"pathogenic\").sum()),\n", "        n_ben=(\"am_class\", lambda x: (x==\"benign\").sum()),\n", "        max_am=(\"am_pathogenicity\",\"max\"),\n", "        genes=(\"gene\", lambda x: \",\".join(sorted(x.unique()))),\n", "    ).reset_index()\n", "    pat_sum[\"has_am_pathogenic\"] = pat_sum[\"n_path\"] > 0\n", "\n", "    print(f\"  Patients with HRR missense: {len(pat_sum)}\")\n", "    print(f\"    AM-Pathogenic: {pat_sum['has_am_pathogenic'].sum()}\")\n", "    print(f\"    AM-Benign/Amb: {(~pat_sum['has_am_pathogenic']).sum()}\")\n", "\n", "    # Merge using patient_id directly\n", "    df_m = pat_sum.merge(df_clin, left_on=\"patient_id\", right_on=\"patientId\", how=\"left\")\n", "\n", "    # Find OS columns\n", "    os_time_col = os_status_col = None\n", "    for c in df_m.columns:\n", "        cu = str(c).upper()\n", "        if cu in [\"OS_MONTHS\",\"OS_TIME\"]: os_time_col = c\n", "        elif cu in [\"OS_STATUS\"]: os_status_col = c\n", "\n", "    if os_time_col and os_status_col:\n", "        df_m[\"os_time\"] = pd.to_numeric(df_m[os_time_col], errors=\"coerce\")\n", "        df_m[\"os_event\"] = df_m[os_status_col].apply(\n", "            lambda x: 1 if any(k in str(x).lower() for k in [\"deceased\",\"dead\"])\n", "                        or str(x).strip().startswith(\"1\") else 0\n", "        )\n", "        valid = df_m.dropna(subset=[\"os_time\",\"os_event\"])\n", "        valid = valid[valid[\"os_time\"] > 0]\n", "        print(f\"  ✅ OS data: {len(valid)} patients, {valid['os_event'].sum():.0f} events\")\n", "        print(f\"     Median follow-up: {valid['os_time'].median():.1f} months\")\n", "    else:\n", "        print(f\"  ⚠️ OS not found. Cols: {[c for c in df_m.columns if 'OS' in str(c).upper()]}\")\n", "        df_m[\"os_time\"] = np.nan\n", "        df_m[\"os_event\"] = np.nan\n", "\n", "    df_m.to_csv(RESULTS_DIR / f\"validation_{sid}.csv\", index=False)\n", "    val_analyses[sid] = df_m\n", "    print(f\"  Saved: {len(df_m)} patients\")\n", "\n", "print(f\"\\n{'='*60}\")\n", "print(f\"READY FOR SURVIVAL: {sum(1 for d in val_analyses.values() if d['os_event'].sum()>0)} studies with events\")"]}, {"cell_type": "markdown", "id": "976338d6", "metadata": {}, "source": ["## 5. Survival Analysis — Validation Cohorts"]}, {"cell_type": "code", "execution_count": 19, "id": "8d83403b", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "============================================================\n", "SURVIVAL: prad_su2c_2019\n", "============================================================\n", "  n=18, events=11, AM-Path=8, AM-Ben=10\n"]}, {"name": "stdout", "output_type": "stream", "text": ["  HR = 0.77 (95% CI 0.19-3.13), p=0.7103\n", "  Log-rank p=0.7096\n", "  Median OS: Path=28.9, Ben=31.5\n", "\n", "============================================================\n", "SURVIVAL: prad_msk_2019\n", "============================================================\n", "  n=0, events=0, AM-Path=0, AM-Ben=0\n", "  Insufficient for survival analysis\n", "\n", "============================================================\n", "SURVIVAL: prad_eururol_2017\n", "============================================================\n", "  n=0, events=0, AM-Path=0, AM-Ben=0\n", "  Insufficient for survival analysis\n", "\n", "Cox results summary:\n", "  prad_su2c_2019: HR=0.77 (0.19-3.13), p=0.7103\n"]}], "source": ["# ============================================================\n", "# 5. SURVIVAL ANALYSIS\n", "# ============================================================\n", "\n", "cox_results = {}\n", "\n", "for sid, df in val_analyses.items():\n", "    print(f\"\\n{'='*60}\")\n", "    print(f\"SURVIVAL: {sid}\")\n", "    print(f\"{'='*60}\")\n", "    \n", "    df_surv = df.dropna(subset=[\"os_time\",\"os_event\"]).copy()\n", "    df_surv = df_surv[df_surv[\"os_time\"] > 0]\n", "    \n", "    n_ev = df_surv[\"os_event\"].sum()\n", "    n_p = df_surv[\"has_am_pathogenic\"].sum()\n", "    n_b = (~df_surv[\"has_am_pathogenic\"]).sum()\n", "    print(f\"  n={len(df_surv)}, events={n_ev:.0f}, AM-Path={n_p}, AM-Ben={n_b}\")\n", "    \n", "    if n_ev < 3 or n_p < 2 or n_b < 2:\n", "        print(f\"  Insufficient for survival analysis\")\n", "        continue\n", "    \n", "    # Cox PH\n", "    try:\n", "        df_cox = df_surv[[\"os_time\",\"os_event\",\"has_am_pathogenic\"]].dropna()\n", "        df_cox[\"has_am_pathogenic\"] = df_cox[\"has_am_pathogenic\"].astype(int)\n", "        \n", "        cph = CoxPHFitter()\n", "        cph.fit(df_cox, duration_col=\"os_time\", event_col=\"os_event\")\n", "        \n", "        hr = np.exp(cph.params_[\"has_am_pathogenic\"])\n", "        ci = np.exp(cph.confidence_intervals_.loc[\"has_am_pathogenic\"])\n", "        p = cph.summary.loc[\"has_am_pathogenic\", \"p\"]\n", "        \n", "        print(f\"  HR = {hr:.2f} (95% CI {ci.iloc[0]:.2f}-{ci.iloc[1]:.2f}), p={p:.4f}\")\n", "        cox_results[sid] = {\"hr\":hr,\"ci_low\":ci.iloc[0],\"ci_high\":ci.iloc[1],\n", "                            \"p\":p,\"n\":len(df_cox),\"events\":n_ev}\n", "    except Exception as e:\n", "        print(f\"  Cox failed: {e}\")\n", "    \n", "    # KM Plot\n", "    grp_p = df_surv[df_surv[\"has_am_pathogenic\"]]\n", "    grp_b = df_surv[~df_surv[\"has_am_pathogenic\"]]\n", "    \n", "    kmf_p = KaplanMeierFitter()\n", "    kmf_b = KaplanMeierFitter()\n", "    kmf_p.fit(grp_p[\"os_time\"], grp_p[\"os_event\"], label=f\"AM-Pathogenic (n={len(grp_p)})\")\n", "    kmf_b.fit(grp_b[\"os_time\"], grp_b[\"os_event\"], label=f\"AM-Benign/Amb (n={len(grp_b)})\")\n", "    \n", "    lr = logrank_test(grp_p[\"os_time\"], grp_b[\"os_time\"], grp_p[\"os_event\"], grp_b[\"os_event\"])\n", "    print(f\"  Log-rank p={lr.p_value:.4f}\")\n", "    print(f\"  Median OS: Path={kmf_p.median_survival_time_:.1f}, Ben={kmf_b.median_survival_time_:.1f}\")\n", "    \n", "    fig, ax = plt.subplots(figsize=(8, 6))\n", "    kmf_p.plot_survival_function(ax=ax, color=\"#E74C3C\", linewidth=2, ci_show=True, ci_alpha=0.15)\n", "    kmf_b.plot_survival_function(ax=ax, color=\"#3498DB\", linewidth=2, ci_show=True, ci_alpha=0.15)\n", "    ax.set_xlabel(\"Time (months)\")\n", "    ax.set_ylabel(\"Overall Survival Probability\")\n", "    ax.set_title(f\"Overall Survival by AM HRR Classification\\n{sid}\")\n", "    ax.set_ylim(0, 1.05)\n", "    \n", "    p_txt = f\"Log-rank p = {lr.p_value:.4f}\" if lr.p_value >= 0.0001 else \"p < 0.0001\"\n", "    ax.text(0.98, 0.02, p_txt, transform=ax.transAxes, fontsize=10,\n", "            ha=\"right\", va=\"bottom\", bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8))\n", "    if sid in cox_results:\n", "        cr = cox_results[sid]\n", "        ax.text(0.98, 0.10, f\"HR = {cr['hr']:.2f} ({cr['ci_low']:.2f}-{cr['ci_high']:.2f})\",\n", "                transform=ax.transAxes, fontsize=9, ha=\"right\", va=\"bottom\",\n", "                bbox=dict(boxstyle=\"round\", facecolor=\"lightyellow\", alpha=0.9))\n", "    \n", "    ax.legend(loc=\"lower left\")\n", "    plt.tight_layout()\n", "    plt.savefig(FIG_DIR / f\"Fig_KM_{sid}.png\", dpi=300)\n", "    plt.savefig(FIG_DIR / f\"Fig_KM_{sid}.pdf\")\n", "    plt.show()\n", "\n", "print(f\"\\nCox results summary:\")\n", "for sid, cr in cox_results.items():\n", "    print(f\"  {sid}: HR={cr['hr']:.2f} ({cr['ci_low']:.2f}-{cr['ci_high']:.2f}), p={cr['p']:.4f}\")\n"]}, {"cell_type": "markdown", "id": "bed667be", "metadata": {}, "source": ["## 6. Pooled mCRPC Analysis"]}, {"cell_type": "code", "execution_count": 20, "id": "78edd934", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["============================================================\n", "POOLED mCRPC ANALYSIS\n", "============================================================\n", "\n", "Pooled: 18 patients, 11 events\n", "  AM-Path: 8, AM-Ben/Amb: 10\n", "\n", "  POOLED HR = 0.77 (0.19-3.13), p=0.7103\n", "  Pooled KM saved\n"]}], "source": ["# ============================================================\n", "# 6. POOLED ANALYSIS\n", "# ============================================================\n", "\n", "print(\"=\"*60)\n", "print(\"POOLED mCRPC ANALYSIS\")\n", "print(\"=\"*60)\n", "\n", "if val_analyses:\n", "    dfs = []\n", "    for sid, df in val_analyses.items():\n", "        df_tmp = df.copy()\n", "        df_tmp[\"study\"] = sid\n", "        dfs.append(df_tmp)\n", "    \n", "    df_pool = pd.concat(dfs, ignore_index=True)\n", "    df_ps = df_pool.dropna(subset=[\"os_time\",\"os_event\"]).copy()\n", "    df_ps = df_ps[df_ps[\"os_time\"] > 0]\n", "    \n", "    n_ev = df_ps[\"os_event\"].sum()\n", "    n_p = df_ps[\"has_am_pathogenic\"].sum()\n", "    n_b = (~df_ps[\"has_am_pathogenic\"]).sum()\n", "    print(f\"\\nPooled: {len(df_ps)} patients, {n_ev:.0f} events\")\n", "    print(f\"  AM-Path: {n_p}, AM-Ben/Amb: {n_b}\")\n", "    \n", "    if n_ev >= 5 and n_p >= 3 and n_b >= 3:\n", "        df_cox = df_ps[[\"os_time\",\"os_event\",\"has_am_pathogenic\",\"study\"]].dropna().copy()\n", "        df_cox[\"has_am_pathogenic\"] = df_cox[\"has_am_pathogenic\"].astype(int)\n", "        \n", "        if df_cox[\"study\"].nunique() > 1:\n", "            df_cox = pd.get_dummies(df_cox, columns=[\"study\"], drop_first=True)\n", "        else:\n", "            df_cox = df_cox.drop(columns=[\"study\"])\n", "        \n", "        try:\n", "            cph = CoxPHFitter()\n", "            cph.fit(df_cox, duration_col=\"os_time\", event_col=\"os_event\")\n", "            hr = np.exp(cph.params_[\"has_am_pathogenic\"])\n", "            ci = np.exp(cph.confidence_intervals_.loc[\"has_am_pathogenic\"])\n", "            p = cph.summary.loc[\"has_am_pathogenic\", \"p\"]\n", "            print(f\"\\n  POOLED HR = {hr:.2f} ({ci.iloc[0]:.2f}-{ci.iloc[1]:.2f}), p={p:.4f}\")\n", "        except Exception as e:\n", "            print(f\"  Pooled Cox failed: {e}\")\n", "            hr = ci = p = None\n", "        \n", "        # Pooled KM\n", "        grp_p = df_ps[df_ps[\"has_am_pathogenic\"]]\n", "        grp_b = df_ps[~df_ps[\"has_am_pathogenic\"]]\n", "        \n", "        kmf_p = KaplanMeierFitter()\n", "        kmf_b = KaplanMeierFitter()\n", "        kmf_p.fit(grp_p[\"os_time\"], grp_p[\"os_event\"], label=f\"AM-Pathogenic (n={len(grp_p)})\")\n", "        kmf_b.fit(grp_b[\"os_time\"], grp_b[\"os_event\"], label=f\"AM-Benign/Amb (n={len(grp_b)})\")\n", "        \n", "        lr = logrank_test(grp_p[\"os_time\"], grp_b[\"os_time\"], grp_p[\"os_event\"], grp_b[\"os_event\"])\n", "        \n", "        fig, ax = plt.subplots(figsize=(8, 6))\n", "        kmf_p.plot_survival_function(ax=ax, color=\"#E74C3C\", linewidth=2.5, ci_show=True, ci_alpha=0.15)\n", "        kmf_b.plot_survival_function(ax=ax, color=\"#3498DB\", linewidth=2.5, ci_show=True, ci_alpha=0.15)\n", "        ax.set_xlabel(\"Time (months)\")\n", "        ax.set_ylabel(\"Overall Survival Probability\")\n", "        ax.set_title(\"Overall Survival by AlphaMissense HRR Classification\\n(Pooled mCRPC Validation)\")\n", "        ax.set_ylim(0, 1.05)\n", "        \n", "        p_txt = f\"Log-rank p = {lr.p_value:.4f}\" if lr.p_value >= 0.0001 else \"p < 0.0001\"\n", "        ax.text(0.98, 0.02, p_txt, transform=ax.transAxes, fontsize=10,\n", "                ha=\"right\", va=\"bottom\", bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8))\n", "        if hr is not None:\n", "            ax.text(0.98, 0.10, f\"HR = {hr:.2f} ({ci.iloc[0]:.2f}-{ci.iloc[1]:.2f})\",\n", "                    transform=ax.transAxes, fontsize=9, ha=\"right\", va=\"bottom\",\n", "                    bbox=dict(boxstyle=\"round\", facecolor=\"lightyellow\", alpha=0.9))\n", "        \n", "        ax.legend(loc=\"lower left\")\n", "        plt.tight_layout()\n", "        plt.savefig(FIG_DIR / \"Fig6_KM_pooled_mCRPC.png\", dpi=300)\n", "        plt.savefig(FIG_DIR / \"Fig6_KM_pooled_mCRPC.pdf\")\n", "        plt.show()\n", "        print(\"  Pooled KM saved\")\n", "    else:\n", "        print(f\"  Insufficient for pooled analysis\")\n", "else:\n", "    print(\"  No validation data\")\n"]}, {"cell_type": "markdown", "id": "8beb988b", "metadata": {}, "source": ["## 7. Study Summary — Ready for Manuscript"]}, {"cell_type": "code", "execution_count": 21, "id": "d17c82b8", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["======================================================================\n", "  COMPLETE STUDY SUMMARY\n", "======================================================================\n", "\n", "  DISCOVERY (TCGA-PRAD, Notebook 2)\n", "    Concordance: kappa=0.733\n", "    VUS reclassified: 90.1%\n", "    Survival: 1 event / 40 patients (exploratory)\n", "\n", "  VALIDATION (mCRPC, Notebook 3)\n", "    prad_su2c_2019: 54 pts, 11 events\n", "      HR=0.77 (0.19-3.13), p=0.7103\n", "    prad_msk_2019: 1 pts, 0 events\n", "    prad_eururol_2017: 3 pts, 0 events\n", "\n", "  TARGET JOURNALS\n", "    Tier 1: JCO Precision Oncology\n", "    Tier 2: European Urology Oncology / Prostate Cancer Prostatic Dis\n", "    Tier 3: Cancers / Frontiers in Oncology\n", "\n", "  OUTPUT FILES\n", "    results/analysis_dataset.csv\n", "    results/annotated_hrr_variants.csv\n", "    results/concordance_results.csv\n", "    results/patient_hrr_summary.csv\n", "    results/sensitivity_logo.csv\n", "    results/sensitivity_threshold.csv\n", "    results/table_gene_summary.csv\n", "    results/validation_hrr_variants.csv\n", "    results/validation_prad_eururol_2017.csv\n", "    results/validation_prad_msk_2019.csv\n", "    results/validation_prad_su2c_2019.csv\n", "    results/vus_reclassification.csv\n", "    figures/Fig1_AM_distribution.png\n", "    figures/Fig2_concordance.png\n", "    figures/Fig3_kaplan_meier.png\n", "    figures/Fig4_sensitivity.png\n", "    figures/Fig5_gene_heatmap.png\n", "    figures/Fig6_KM_pooled_mCRPC.png\n", "    figures/Fig_KM_prad_su2c_2019.png\n", "\n", "======================================================================\n", "  Notebook 3 complete. Paper package ready.\n", "======================================================================\n"]}], "source": ["# ============================================================\n", "# 7. EXECUTIVE SUMMARY\n", "# ============================================================\n", "\n", "print(\"=\" * 70)\n", "print(\"  COMPLETE STUDY SUMMARY\")\n", "print(\"=\" * 70)\n", "\n", "# Notebook 2 results\n", "conc_path = RESULTS_DIR / \"concordance_results.csv\"\n", "if conc_path.exists():\n", "    conc = pd.read_csv(conc_path)\n", "    kappa = conc[conc[\"Metric\"]==\"Cohen's kappa\"][\"Value\"].values[0]\n", "    print(f\"\\n  DISCOVERY (TCGA-PRAD, Notebook 2)\")\n", "    print(f\"    Concordance: kappa={kappa:.3f}\")\n", "    print(f\"    VUS reclassified: 90.1%\")\n", "    print(f\"    Survival: 1 event / 40 patients (exploratory)\")\n", "\n", "# Notebook 3 results\n", "print(f\"\\n  VALIDATION (mCRPC, Notebook 3)\")\n", "for sid, df in val_analyses.items():\n", "    n_ev = df[\"os_event\"].sum() if \"os_event\" in df.columns else 0\n", "    print(f\"    {sid}: {len(df)} pts, {n_ev:.0f} events\")\n", "    if sid in cox_results:\n", "        cr = cox_results[sid]\n", "        print(f\"      HR={cr['hr']:.2f} ({cr['ci_low']:.2f}-{cr['ci_high']:.2f}), p={cr['p']:.4f}\")\n", "\n", "print(f\"\\n  TARGET JOURNALS\")\n", "print(f\"    Tier 1: JCO Precision Oncology\")\n", "print(f\"    Tier 2: European Urology Oncology / Prostate Cancer Prostatic Dis\")\n", "print(f\"    Tier 3: Cancers / Frontiers in Oncology\")\n", "\n", "print(f\"\\n  OUTPUT FILES\")\n", "for f in sorted(RESULTS_DIR.glob(\"*.csv\")):\n", "    print(f\"    {f}\")\n", "for f in sorted(FIG_DIR.glob(\"*.png\")):\n", "    print(f\"    {f}\")\n", "\n", "print(f\"\\n{'='*70}\")\n", "print(f\"  Notebook 3 complete. Paper package ready.\")\n", "print(f\"{'='*70}\")\n"]}, {"cell_type": "code", "execution_count": 14, "id": "f3dbf574", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["Variant sample IDs (first 5): ['MO_1012-Tumor-Subcutaneous_nodule' 'MO_1013-Tumor' 'MO_1071-Tumor'\n", " 'MO_1130-Tumor' 'MO_1176-Tumor']\n", "Extracted patient IDs (first 5): ['MO_1012-Tumor-Subcutaneous_nodule', 'MO_1013-Tumor', 'MO_1071-Tumor', 'MO_1130-Tumor', 'MO_1176-Tumor']\n", "\n", "Clinical patient IDs (first 5): ['1115015' '1115016' '1115019' '1115020' '1115021']\n", "\n", "Overlap: 0 / 54 variant patients\n", "Direct sampleId vs patientId overlap: 0\n", "\n", "Format comparison:\n", "  Variant sample: MO_1012-Tumor-Subcutaneous_nodule\n", "  Extracted patient: MO_1012-Tumor-Subcutaneous_nodule\n", "  Clinical patient: 1115015\n"]}], "source": ["# DEBUG — patient ID matching\n", "sid = \"prad_su2c_2019\"\n", "data = all_studies[sid]\n", "df_vars = df_val[df_val[\"study_id\"] == sid]\n", "\n", "# IDs from variants\n", "var_ids = df_vars[\"sample_id\"].unique()\n", "print(f\"Variant sample IDs (first 5): {var_ids[:5]}\")\n", "\n", "# Extract patient IDs \n", "import re\n", "def extract_pid(s):\n", "    s = str(s)\n", "    m = re.match(r'(TCGA-[A-Z0-9]+-[A-Z0-9]+)', s)\n", "    if m: return m.group(1)\n", "    for suffix in [\"-T\", \"-Tm\", \"-T1\", \"-M1\"]:\n", "        if s.endswith(suffix): return s[:-len(suffix)]\n", "    return s\n", "\n", "var_patient_ids = [extract_pid(s) for s in var_ids]\n", "print(f\"Extracted patient IDs (first 5): {var_patient_ids[:5]}\")\n", "\n", "# IDs from clinical\n", "from io import StringIO\n", "df_clin = data[\"clinical_patient\"]\n", "if \"clinicalAttributeId\" in df_clin.columns:\n", "    df_wide = df_clin.pivot_table(index=\"patientId\", columns=\"clinicalAttributeId\",\n", "                                   values=\"value\", aggfunc=\"first\").reset_index()\n", "else:\n", "    df_wide = df_clin\n", "    \n", "clin_ids = df_wide[\"patientId\"].unique()\n", "print(f\"\\nClinical patient IDs (first 5): {clin_ids[:5]}\")\n", "\n", "# Check overlap\n", "overlap = set(var_patient_ids) & set(clin_ids)\n", "print(f\"\\nOverlap: {len(overlap)} / {len(var_patient_ids)} variant patients\")\n", "\n", "if len(overlap) == 0:\n", "    # Try direct sample_id match\n", "    overlap2 = set(var_ids) & set(clin_ids)\n", "    print(f\"Direct sampleId vs patientId overlap: {len(overlap2)}\")\n", "    \n", "    # Show format difference\n", "    print(f\"\\nFormat comparison:\")\n", "    print(f\"  Variant sample: {var_ids[0]}\")\n", "    print(f\"  Extracted patient: {var_patient_ids[0]}\")\n", "    print(f\"  Clinical patient: {clin_ids[0]}\")"]}, {"cell_type": "code", "execution_count": 15, "id": "1bbe2617", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["patientId in mutations? True\n", "Sample mapping (first 5):\n", "                         sampleId patientId\n", "             DFCI.11-104.02-Tumor   1115019\n", "             DFCI.11-104.13-Tumor   1115020\n", "               MO_1008-Tumor_Dura   5115022\n", "MO_1012-Tumor-Subcutaneous_nodule   6115012\n", "                    MO_1013-Tumor   6115013\n", "                    MO_1014-Tumor   6115014\n", "                    MO_1015-Tumor   5115023\n", "                    MO_1020-Tumor   5115024\n", "                    MO_1040-Tumor   5115026\n", "                    MO_1054-Tumor   5115027\n"]}], "source": ["# DEBUG — check if mutations have patientId\n", "df_mut = all_studies[\"prad_su2c_2019\"][\"mutations\"]\n", "print(\"patientId in mutations?\", \"patientId\" in df_mut.columns)\n", "print(\"Sample mapping (first 5):\")\n", "mapping = df_mut[[\"sampleId\",\"patientId\"]].drop_duplicates().head(10)\n", "print(mapping.to_string(index=False))"]}, {"cell_type": "code", "execution_count": 8, "id": "15314886", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["\n", "=== prad_su2c_2019: 40055 rows ===\n", "Columns: ['uniqueSampleKey', 'uniquePatientKey', 'molecularProfileId', 'sampleId', 'patientId', 'entrezGeneId', 'studyId', 'center', 'mutationStatus', 'validationStatus', 'tumorAltCount', 'tumorRefCount', 'startPosition', 'endPosition', 'referenceAllele']\n", "Sample row:\n", "{'uniqueSampleKey': 'REZDSS4xMS0xMDQuMDItVHVtb3I6cHJhZF9zdTJjXzIwMTk', 'uniquePatientKey': 'MTExNTAxOTpwcmFkX3N1MmNfMjAxOQ', 'molecularProfileId': 'prad_su2c_2019_mutations', 'sampleId': 'DFCI.11-104.02-Tumor', 'patientId': '1115019', 'entrezGeneId': 366, 'studyId': 'prad_su2c_2019', 'center': 'broad.mit.edu', 'mutationStatus': 'Somatic', 'validationStatus': 'Untested', 'tumorAltCount': 15.0, 'tumorRefCount': 94.0, 'startPosition': 58430811, 'endPosition': 58430811, 'referenceAllele': 'T', 'proteinChange': 'L16Q', 'mutationType': 'Missense_Mutation', 'ncbiBuild': 'GRCh37', 'variantType': 'SNP', 'keyword': 'AQP9 L16 missense', 'chr': '15', 'variantAllele': 'A', 'refseqMrnaId': 'NM_020980.3', 'proteinPosStart': 16, 'proteinPosEnd': 16, 'gene.entrezGeneId': 366, 'gene.hugoGeneSymbol': 'AQP9', 'gene.type': 'protein-coding'}\n", "\n", "Gene column 'entrezGeneId' — unique genes sample: [ 366 1280 1291 1302 1537 2132 2312 2313 2634 2902]\n", "\n", "Gene column 'gene.entrezGeneId' — unique genes sample: [ 366 1280 1291 1302 1537 2132 2312 2313 2634 2902]\n", "\n", "Gene column 'gene.hugoGeneSymbol' — unique genes sample: ['AQP9' 'COL2A1' 'COL6A1' 'COL11A2' 'CYC1' 'EXT2' 'FLG' 'FLI1' 'GBP2'\n", " 'GRIN1']\n", "\n", "Gene column 'gene.type' — unique genes sample: ['protein-coding' 'other' 'pseudogene' 'ncRNA' ' ' 'unknown' 'miRNA'\n", " 'snoRNA']\n", "Classification column 'mutationType': ['Missense_Mutation' 'Nonsense_Mutation' 'Splice_Site' 'Frame_Shift_Del'\n", " 'Frame_Shift_Ins' 'In_Frame_Del' 'Splice_Region' 'Nonstop_Mutation'\n", " 'In_Frame_Ins' 'Translation_Start_Site']\n", "Classification column 'variantType': ['SNP' 'DEL' 'INS']\n", "Classification column 'gene.type': ['protein-coding' 'other' 'pseudogene' 'ncRNA' ' ' 'unknown' 'miRNA'\n", " 'snoRNA']\n", "Protein column 'proteinChange': ['L16Q' 'A569G' 'C609*' 'H858Y' 'A75V']\n", "Protein column 'proteinPosStart': [ 16 569 609 858  75]\n", "Protein column 'proteinPosEnd': [ 16 569 609 858  75]\n"]}], "source": ["# DEBUG — Cole numa célula nova e rode\n", "for sid, data in all_studies.items():\n", "    df = data[\"mutations\"]\n", "    print(f\"\\n=== {sid}: {len(df)} rows ===\")\n", "    print(f\"Columns: {df.columns[:15].tolist()}\")\n", "    print(f\"Sample row:\")\n", "    print(df.iloc[0].to_dict())\n", "    # Check for gene column\n", "    for c in df.columns:\n", "        if \"gene\" in c.lower() or \"hugo\" in c.lower() or \"symbol\" in c.lower():\n", "            print(f\"\\nGene column '{c}' — unique genes sample: {df[c].dropna().unique()[:10]}\")\n", "    # Check for variant classification\n", "    for c in df.columns:\n", "        if \"class\" in c.lower() or \"type\" in c.lower() or \"consequence\" in c.lower():\n", "            vals = df[c].dropna().unique()[:10]\n", "            print(f\"Classification column '{c}': {vals}\")\n", "    # Check for protein change\n", "    for c in df.columns:\n", "        if \"protein\" in c.lower() or \"hgvs\" in c.lower() or \"amino\" in c.lower():\n", "            vals = df[c].dropna().unique()[:5]\n", "            print(f\"Protein column '{c}': {vals}\")\n", "    break  # just check SU2C"]}, {"cell_type": "markdown", "id": "993f4a7f", "metadata": {}, "source": ["## Done!\n", "\n", "### Next Steps:\n", "1. Review figures and results\n", "2. Draft manuscript\n", "3. Submit to JCO Precision Oncology\n", "\n", "---\n", "*Research OS — Clinical Computational Oncology Pipeline*\n"]}], "metadata": {"kernelspec": {"display_name": ".venv", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.12.3"}}, "nbformat": 4, "nbformat_minor": 5}