{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4649137c",
   "metadata": {},
   "source": [
    "# Notebook 4 \u2014 Pan-Cancer AlphaMissense HRR Analysis (v2 FIX)\n\n**Critical fix (2026-02-16):** The cBioPortal API changed behavior \u2014 `entrezGeneIds: []` now returns zero mutations instead of all mutations. Fixed by passing explicit Entrez Gene IDs for HRR genes, with fallback strategies.\n\n**Changes from FIXED v1:**\n1. `fetch_mutations()` now uses `HRR_ENTREZ_IDS` (explicit gene list) instead of `[]`\n2. Added fallback: alternate sample list IDs + gene-by-gene query\n3. Added diagnostic print for API response status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84aec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. SETUP \u2014 GLOBAL SEEDS + PACKAGES\n",
    "# ============================================================\n",
    "import subprocess, sys\n",
    "for p in [\"pandas\",\"numpy\",\"matplotlib\",\"seaborn\",\"scipy\",\"lifelines\",\"requests\",\"tqdm\",\"scikit-learn\"]:\n",
    "    subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",p])\n",
    "\n",
    "# \u2500\u2500 GLOBAL SEEDS (MUST be first) \u2500\u2500\n",
    "import random\n",
    "import numpy as np\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib; matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import requests, io, json, re, warnings, time\n",
    "warnings.filterwarnings('ignore')\n",
    "from lifelines import CoxPHFitter, KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test, multivariate_logrank_test\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix\n",
    "\n",
    "DATA_DIR = Path(\"data\"); RESULTS_DIR = Path(\"results\"); FIG_DIR = Path(\"figures\")\n",
    "for d in [DATA_DIR, RESULTS_DIR, FIG_DIR, DATA_DIR/\"pancancer\"]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "plt.rcParams.update({'font.family':'sans-serif','font.size':10,'figure.dpi':300,\n",
    "                     'savefig.dpi':300,'savefig.bbox':'tight'})\n",
    "\n",
    "# Package versions for reproducibility\n",
    "print(\"=== PACKAGE VERSIONS ===\")\n",
    "for pkg_name in [\"pandas\",\"numpy\",\"scipy\",\"lifelines\",\"sklearn\",\"matplotlib\",\"seaborn\"]:\n",
    "    try:\n",
    "        mod = __import__(pkg_name)\n",
    "        print(f\"  {pkg_name}: {mod.__version__}\")\n",
    "    except:\n",
    "        pass\n",
    "print(f\"  Python: {sys.version}\")\n",
    "print(f\"  Random seed: {SEED}\")\n",
    "print(f\"  Data download date: {pd.Timestamp.now().strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Gene lists\n",
    "COHORT_A = [\"BRCA1\",\"BRCA2\",\"ATM\"]\n",
    "COHORT_B = [\"PALB2\",\"BRIP1\",\"BARD1\",\"CDK12\",\"CHEK1\",\"CHEK2\",\"FANCL\",\n",
    "            \"RAD51B\",\"RAD51C\",\"RAD51D\",\"RAD54L\"]\n",
    "EXPANDED = [\"FANCA\",\"FANCC\",\"FANCD2\",\"FANCE\",\"FANCF\",\"FANCG\",\n",
    "            \"NBN\",\"MRE11\",\"RAD50\",\"ATR\",\"ATRX\"]\n",
    "HRR_ALL = sorted(set(COHORT_A + COHORT_B + EXPANDED))\n",
    "\n",
    "GENE_TO_UNIPROT = {\n",
    "    \"BRCA1\":\"P38398\",\"BRCA2\":\"P51587\",\"ATM\":\"Q13315\",\"PALB2\":\"Q86YC2\",\n",
    "    \"BRIP1\":\"Q9BX63\",\"BARD1\":\"Q99728\",\"CDK12\":\"Q9NYV4\",\"CHEK1\":\"O14757\",\n",
    "    \"CHEK2\":\"O96017\",\"FANCL\":\"Q9NW38\",\"RAD51B\":\"O15315\",\"RAD51C\":\"O43502\",\n",
    "    \"RAD51D\":\"O75771\",\"RAD54L\":\"Q92698\",\"FANCA\":\"O15360\",\"FANCC\":\"Q00597\",\n",
    "    \"FANCD2\":\"Q9BXW9\",\"FANCE\":\"Q9HB96\",\"FANCF\":\"Q9NPI8\",\"FANCG\":\"O15287\",\n",
    "    \"NBN\":\"O60934\",\"MRE11\":\"P49959\",\"RAD50\":\"Q92878\",\"ATR\":\"Q13535\",\"ATRX\":\"P46100\",\n",
    "}\n",
    "\n",
    "TCGA_STUDIES = [\n",
    "    (\"brca_tcga_pan_can_atlas_2018\", \"Breast\"),\n",
    "    (\"ov_tcga_pan_can_atlas_2018\", \"Ovarian\"),\n",
    "    (\"paad_tcga_pan_can_atlas_2018\", \"Pancreas\"),\n",
    "    (\"prad_tcga_pan_can_atlas_2018\", \"Prostate\"),\n",
    "    (\"blca_tcga_pan_can_atlas_2018\", \"Bladder\"),\n",
    "    (\"ucec_tcga_pan_can_atlas_2018\", \"Endometrial\"),\n",
    "    (\"luad_tcga_pan_can_atlas_2018\", \"Lung Adeno\"),\n",
    "    (\"lusc_tcga_pan_can_atlas_2018\", \"Lung Squamous\"),\n",
    "    (\"coadread_tcga_pan_can_atlas_2018\", \"Colorectal\"),\n",
    "    (\"stad_tcga_pan_can_atlas_2018\", \"Gastric\"),\n",
    "    (\"hnsc_tcga_pan_can_atlas_2018\", \"Head & Neck\"),\n",
    "    (\"skcm_tcga_pan_can_atlas_2018\", \"Melanoma\"),\n",
    "    (\"lihc_tcga_pan_can_atlas_2018\", \"Liver\"),\n",
    "    (\"chol_tcga_pan_can_atlas_2018\", \"Cholangiocarcinoma\"),\n",
    "    (\"esca_tcga_pan_can_atlas_2018\", \"Esophageal\"),\n",
    "    (\"kirc_tcga_pan_can_atlas_2018\", \"Kidney ccRCC\"),\n",
    "    (\"kirp_tcga_pan_can_atlas_2018\", \"Kidney Papillary\"),\n",
    "    (\"gbm_tcga_pan_can_atlas_2018\", \"Glioblastoma\"),\n",
    "    (\"lgg_tcga_pan_can_atlas_2018\", \"Low Grade Glioma\"),\n",
    "    (\"sarc_tcga_pan_can_atlas_2018\", \"Sarcoma\"),\n",
    "    (\"thca_tcga_pan_can_atlas_2018\", \"Thyroid\"),\n",
    "    (\"cesc_tcga_pan_can_atlas_2018\", \"Cervical\"),\n",
    "    (\"acc_tcga_pan_can_atlas_2018\", \"Adrenocortical\"),\n",
    "    (\"meso_tcga_pan_can_atlas_2018\", \"Mesothelioma\"),\n",
    "    (\"uvm_tcga_pan_can_atlas_2018\", \"Uveal Melanoma\"),\n",
    "    (\"dlbc_tcga_pan_can_atlas_2018\", \"DLBCL\"),\n",
    "    (\"tgct_tcga_pan_can_atlas_2018\", \"Testicular\"),\n",
    "    (\"thym_tcga_pan_can_atlas_2018\", \"Thymoma\"),\n",
    "    (\"pcpg_tcga_pan_can_atlas_2018\", \"Pheochromocytoma\"),\n",
    "    (\"kich_tcga_pan_can_atlas_2018\", \"Kidney Chromophobe\"),\n",
    "    (\"ucs_tcga_pan_can_atlas_2018\", \"Uterine Carcinosarcoma\"),\n",
    "]\n",
    "\n",
    "print(f\"\\nSetup complete. {len(TCGA_STUDIES)} TCGA studies. Seed={SEED}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe178dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2. LOAD ALPHAMISSENSE LOOKUP (from Notebook 1)\n",
    "# ============================================================\n",
    "am_path = DATA_DIR / \"processed\" / \"alphamissense_hrr_genes.csv\"\n",
    "if am_path.exists():\n",
    "    df_am = pd.read_csv(am_path)\n",
    "    am_lookup = {}\n",
    "    for _, row in df_am.iterrows():\n",
    "        key = f\"{row['uniprot_id']}_{row['protein_variant']}\"\n",
    "        am_lookup[key] = (row['am_pathogenicity'], row['am_class'])\n",
    "    print(f\"AlphaMissense lookup: {len(am_lookup):,} variants\")\n",
    "else:\n",
    "    print(\"ERROR: Run Notebook 1 first to generate AlphaMissense lookup!\")\n",
    "    am_lookup = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c249c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n# 3. DOWNLOAD + FILTER + ANNOTATE \u2014 ALL TCGA STUDIES\n# ============================================================\n\nCBIO_API = \"https://www.cbioportal.org/api\"\n\naa3to1 = {'Ala':'A','Arg':'R','Asn':'N','Asp':'D','Cys':'C','Gln':'Q',\n          'Glu':'E','Gly':'G','His':'H','Ile':'I','Leu':'L','Lys':'K',\n          'Met':'M','Phe':'F','Pro':'P','Ser':'S','Thr':'T','Trp':'W',\n          'Tyr':'Y','Val':'V','Ter':'*','Sec':'U'}\n\ndef parse_protein(val):\n    if pd.isna(val): return None\n    s = str(val).strip()\n    m3 = re.match(r'p\\.([A-Z][a-z]{2})(\\d+)([A-Z][a-z]{2})', s)\n    if m3:\n        r, alt = aa3to1.get(m3.group(1)), aa3to1.get(m3.group(3))\n        if r and alt and r != alt: return (r, int(m3.group(2)), alt)\n    m1 = re.match(r'p\\.([A-Z*])(\\d+)([A-Z*])', s)\n    if m1 and m1.group(1) != m1.group(3):\n        return (m1.group(1), int(m1.group(2)), m1.group(3))\n    mb = re.match(r'^([A-Z])(\\d+)([A-Z])$', s)\n    if mb and mb.group(1) != mb.group(3):\n        return (mb.group(1), int(mb.group(2)), mb.group(3))\n    return None\n\n# Entrez Gene IDs for HRR genes (NCBI Gene)\nHRR_ENTREZ = {\n    \"BRCA1\":672,\"BRCA2\":675,\"ATM\":472,\"PALB2\":79728,\"BRIP1\":83990,\n    \"BARD1\":580,\"CDK12\":51755,\"CHEK1\":1111,\"CHEK2\":11200,\"FANCL\":55120,\n    \"RAD51B\":5890,\"RAD51C\":5889,\"RAD51D\":5892,\"RAD54L\":8438,\n    \"FANCA\":2175,\"FANCC\":2176,\"FANCD2\":2177,\"FANCE\":2178,\"FANCF\":2188,\n    \"FANCG\":2189,\"NBN\":4683,\"MRE11\":4361,\"RAD50\":10111,\"ATR\":545,\n    \"ATRX\":546,\n}\nHRR_ENTREZ_IDS = list(HRR_ENTREZ.values())\n\ndef fetch_mutations(study_id):\n    \"\"\"Fetch mutations from cBioPortal API.\n    \n    FIX (2026-02-16): The cBioPortal API now interprets entrezGeneIds=[] as\n    \"no genes\" instead of \"all genes\". We use two strategies:\n      1. Primary: fetch HRR genes by Entrez ID (faster, targeted)\n      2. Fallback: fetch all mutations via /mutations endpoint\n    \"\"\"\n    try:\n        # Get molecular profile\n        profiles = requests.get(\n            f\"{CBIO_API}/studies/{study_id}/molecular-profiles\",\n            headers={\"Accept\":\"application/json\"}, timeout=30\n        ).json()\n        mut_profile = next((p[\"molecularProfileId\"] for p in profiles\n                           if p[\"molecularAlterationType\"]==\"MUTATION_EXTENDED\"), None)\n        if not mut_profile:\n            print(f\"    No mutation profile found\")\n            return None\n\n        # \u2500\u2500 STRATEGY 1: Fetch HRR genes by Entrez ID \u2500\u2500\n        resp = requests.post(\n            f\"{CBIO_API}/molecular-profiles/{mut_profile}/mutations/fetch\",\n            headers={\"Accept\":\"application/json\",\"Content-Type\":\"application/json\"},\n            json={\"sampleListId\": f\"{study_id}_all\",\n                  \"entrezGeneIds\": HRR_ENTREZ_IDS},\n            params={\"projection\":\"DETAILED\"}, timeout=180\n        )\n        if resp.status_code == 200:\n            data = resp.json()\n            if len(data) > 0:\n                return pd.json_normalize(data)\n\n        # \u2500\u2500 STRATEGY 2: Fallback \u2014 try without sampleListId filter \u2500\u2500\n        # Some studies use different sample list naming\n        sample_lists = requests.get(\n            f\"{CBIO_API}/studies/{study_id}/sample-lists\",\n            headers={\"Accept\":\"application/json\"}, timeout=30\n        ).json()\n        alt_lists = [sl[\"sampleListId\"] for sl in sample_lists\n                     if \"all\" in sl.get(\"sampleListId\",\"\").lower()\n                     or sl.get(\"category\",\"\") == \"all_cases_in_study\"]\n        \n        for sl_id in alt_lists:\n            if sl_id == f\"{study_id}_all\":\n                continue  # already tried\n            resp2 = requests.post(\n                f\"{CBIO_API}/molecular-profiles/{mut_profile}/mutations/fetch\",\n                headers={\"Accept\":\"application/json\",\"Content-Type\":\"application/json\"},\n                json={\"sampleListId\": sl_id,\n                      \"entrezGeneIds\": HRR_ENTREZ_IDS},\n                params={\"projection\":\"DETAILED\"}, timeout=180\n            )\n            if resp2.status_code == 200:\n                data2 = resp2.json()\n                if len(data2) > 0:\n                    print(f\"    Used alternate sample list: {sl_id}\")\n                    return pd.json_normalize(data2)\n\n        # \u2500\u2500 STRATEGY 3: Last resort \u2014 gene-by-gene query \u2500\u2500\n        print(f\"    Trying gene-by-gene fetch...\")\n        all_muts = []\n        for gene, eid in HRR_ENTREZ.items():\n            try:\n                r = requests.get(\n                    f\"{CBIO_API}/molecular-profiles/{mut_profile}/mutations\",\n                    headers={\"Accept\":\"application/json\"},\n                    params={\"sampleListId\": f\"{study_id}_all\",\n                            \"entrezGeneId\": eid,\n                            \"projection\":\"DETAILED\"},\n                    timeout=30\n                )\n                if r.status_code == 200:\n                    muts = r.json()\n                    if muts:\n                        all_muts.extend(muts)\n            except:\n                pass\n        if all_muts:\n            return pd.json_normalize(all_muts)\n\n        print(f\"    All strategies returned 0 mutations\")\n        return None\n\n    except Exception as e:\n        print(f\"    Mutation fetch failed: {e}\")\n    return None\n\ndef fetch_clinical(study_id):\n    try:\n        resp = requests.get(\n            f\"{CBIO_API}/studies/{study_id}/clinical-data\",\n            headers={\"Accept\":\"application/json\"},\n            params={\"clinicalDataType\":\"PATIENT\",\"projection\":\"DETAILED\"}, timeout=60\n        ).json()\n        df = pd.json_normalize(resp)\n        if \"clinicalAttributeId\" in df.columns:\n            return df.pivot_table(index=\"patientId\", columns=\"clinicalAttributeId\",\n                                   values=\"value\", aggfunc=\"first\").reset_index()\n        return df\n    except:\n        return pd.DataFrame()\n\ndef annotate_study(df_mut, study_id, tumor_name):\n    gene_col = next((c for c in [\"Hugo_Symbol\",\"gene.hugoGeneSymbol\",\"hugoGeneSymbol\"]\n                     if c in df_mut.columns), None)\n    class_col = next((c for c in [\"Variant_Classification\",\"mutationType\"]\n                      if c in df_mut.columns), None)\n    sample_col = next((c for c in [\"Tumor_Sample_Barcode\",\"sampleId\"]\n                       if c in df_mut.columns), None)\n    hgvsp_col = next((c for c in [\"HGVSp_Short\",\"proteinChange\",\"HGVSp\"]\n                      if c in df_mut.columns), None)\n    patient_col = \"patientId\" if \"patientId\" in df_mut.columns else None\n    if not all([gene_col, class_col, sample_col, hgvsp_col]):\n        return pd.DataFrame()\n    df_hrr = df_mut[df_mut[gene_col].isin(HRR_ALL)]\n    df_miss = df_hrr[df_hrr[class_col].str.contains(\"issense\", case=False, na=False)].copy()\n    if len(df_miss) == 0: return pd.DataFrame()\n    parsed = df_miss[hgvsp_col].apply(parse_protein)\n    df_miss = df_miss[parsed.notna()].copy()\n    parsed = parsed[parsed.notna()]\n    if len(df_miss) == 0: return pd.DataFrame()\n    df_miss[\"ref_aa\"] = [p[0] for p in parsed]\n    df_miss[\"protein_pos\"] = [p[1] for p in parsed]\n    df_miss[\"alt_aa\"] = [p[2] for p in parsed]\n    df_miss[\"gene\"] = df_miss[gene_col]\n    df_miss[\"sample_id\"] = df_miss[sample_col]\n    df_miss[\"patient_id\"] = df_miss[patient_col] if patient_col else df_miss[sample_col]\n    df_miss[\"uniprot_id\"] = df_miss[\"gene\"].map(GENE_TO_UNIPROT)\n    scores, classes = [], []\n    for _, row in df_miss.iterrows():\n        key = f\"{row.get('uniprot_id','')}_{row['ref_aa']}{row['protein_pos']}{row['alt_aa']}\"\n        if key in am_lookup:\n            scores.append(am_lookup[key][0])\n            classes.append(am_lookup[key][1])\n        else:\n            scores.append(np.nan)\n            classes.append(\"not_found\")\n    df_miss[\"am_pathogenicity\"] = scores\n    df_miss[\"am_class\"] = classes\n    df_miss[\"study_id\"] = study_id\n    df_miss[\"tumor_type\"] = tumor_name\n    return df_miss[[\"study_id\",\"tumor_type\",\"sample_id\",\"patient_id\",\"gene\",\n                     \"am_pathogenicity\",\"am_class\"]].copy()\n\n# \u2500\u2500 VALIDATED EVENT CODING \u2500\u2500\n# FIX: Explicit mapping with validation, not heuristic string matching\ndef code_os_event(val):\n    \"\"\"Explicit OS_STATUS coding with validation.\n    TCGA PanCan Atlas uses: '1:DECEASED' / '0:LIVING'\n    Some studies use: 'DECEASED' / 'LIVING'\n    \"\"\"\n    s = str(val).strip().upper()\n    if s in [\"1:DECEASED\", \"DECEASED\", \"DEAD\"]:\n        return 1\n    elif s in [\"0:LIVING\", \"LIVING\", \"ALIVE\"]:\n        return 0\n    elif s.startswith(\"1:\"):\n        return 1\n    elif s.startswith(\"0:\"):\n        return 0\n    else:\n        return np.nan  # UNKNOWN \u2192 missing, not guessed\n\n# === MAIN LOOP ===\nall_variants = []\nall_clinical = {}\nstudy_summary = []\nos_status_values = {}  # Track unique OS_STATUS values per study for validation\n\nfor i, (sid, tumor) in enumerate(TCGA_STUDIES):\n    print(f\"\\n[{i+1}/{len(TCGA_STUDIES)}] {tumor} ({sid})\")\n    df_mut = fetch_mutations(sid)\n    if df_mut is None or len(df_mut) == 0:\n        print(f\"  No mutations \u2014 skipping\")\n        study_summary.append({\"study_id\":sid,\"tumor\":tumor,\"n_mutations\":0,\n                              \"n_hrr_missense\":0,\"n_patients\":0})\n        time.sleep(0.5)\n        continue\n    print(f\"  Mutations: {len(df_mut):,}\")\n    df_ann = annotate_study(df_mut, sid, tumor)\n    n_hrr = len(df_ann)\n    n_pat = df_ann[\"patient_id\"].nunique() if n_hrr > 0 else 0\n    n_path = (df_ann[\"am_class\"]==\"pathogenic\").sum() if n_hrr > 0 else 0\n    print(f\"  HRR missense: {n_hrr} in {n_pat} patients ({n_path} AM-pathogenic)\")\n    study_summary.append({\"study_id\":sid,\"tumor\":tumor,\"n_mutations\":len(df_mut),\n                          \"n_hrr_missense\":n_hrr,\"n_patients\":n_pat})\n    if n_hrr > 0:\n        all_variants.append(df_ann)\n    df_clin = fetch_clinical(sid)\n    if len(df_clin) > 0:\n        all_clinical[sid] = df_clin\n        # Track OS_STATUS values for validation\n        os_col = next((c for c in df_clin.columns if str(c).upper() == \"OS_STATUS\"), None)\n        if os_col:\n            unique_vals = df_clin[os_col].dropna().unique().tolist()\n            os_status_values[tumor] = unique_vals\n        print(f\"  Clinical: {len(df_clin)} patients\")\n    time.sleep(1.0)\n\n# Combine\nif all_variants:\n    df_all = pd.concat(all_variants, ignore_index=True)\n    df_all.to_csv(RESULTS_DIR / \"pancancer_hrr_variants.csv\", index=False)\n    print(f\"\\n{'='*60}\")\n    print(f\"PAN-CANCER SUMMARY\")\n    print(f\"{'='*60}\")\n    print(f\"Total: {len(df_all)} HRR missense variants\")\n    print(f\"Patients: {df_all['patient_id'].nunique()}\")\n    print(f\"Tumor types: {df_all['tumor_type'].nunique()}\")\n    print(f\"AM-Pathogenic: {(df_all['am_class']=='pathogenic').sum()}\")\n    print(f\"AM-Benign: {(df_all['am_class']=='benign').sum()}\")\nelse:\n    df_all = pd.DataFrame()\n    print(\"\\nNo variants found\")\n\n# \u2500\u2500 VALIDATE EVENT CODING \u2500\u2500\nprint(\"\\n=== OS_STATUS VALUES BY STUDY (for audit) ===\")\nfor tumor, vals in sorted(os_status_values.items()):\n    print(f\"  {tumor:25s}: {vals}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c1a130",
   "metadata": {},
   "source": [
    "## 4. Survival Analysis \u2014 TRUE Stratified Cox + Stratified Log-Rank\n",
    "\n",
    "**FIX:** Uses `strata=['tumor']` in lifelines CoxPHFitter (separate baseline hazard per tumor type), NOT dummy variable adjustment with ridge penalty.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382f3d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4. PER-TUMOR COX + TRUE STRATIFIED POOLED COX + STRATIFIED LOG-RANK\n",
    "# ============================================================\n",
    "\n",
    "cox_results = {}    # per-tumor unadjusted Cox\n",
    "km_data = {}        # for KM plots\n",
    "cox_details = {}    # store coef + SE directly (not reverse-engineered)\n",
    "\n",
    "if len(df_all) == 0:\n",
    "    print(\"No variants to analyze\")\n",
    "else:\n",
    "    for sid, tumor in TCGA_STUDIES:\n",
    "        df_vars = df_all[df_all[\"study_id\"] == sid]\n",
    "        if len(df_vars) == 0: continue\n",
    "        df_clin = all_clinical.get(sid, pd.DataFrame())\n",
    "        if len(df_clin) == 0: continue\n",
    "\n",
    "        # Patient-level summary\n",
    "        pat = df_vars.groupby(\"patient_id\").agg(\n",
    "            n_path=(\"am_class\", lambda x: (x==\"pathogenic\").sum()),\n",
    "            max_am=(\"am_pathogenicity\",\"max\"),\n",
    "        ).reset_index()\n",
    "        pat[\"has_am_pathogenic\"] = pat[\"n_path\"] > 0\n",
    "\n",
    "        # Merge\n",
    "        pid_col = \"patientId\" if \"patientId\" in df_clin.columns else df_clin.columns[0]\n",
    "        df_m = pat.merge(df_clin, left_on=\"patient_id\", right_on=pid_col, how=\"left\")\n",
    "\n",
    "        # Find OS\n",
    "        os_t = next((c for c in df_m.columns if str(c).upper() in [\"OS_MONTHS\",\"OS_TIME\"]), None)\n",
    "        os_s = next((c for c in df_m.columns if str(c).upper() == \"OS_STATUS\"), None)\n",
    "        if not (os_t and os_s): continue\n",
    "\n",
    "        df_m[\"os_time\"] = pd.to_numeric(df_m[os_t], errors=\"coerce\")\n",
    "        df_m[\"os_event\"] = df_m[os_s].apply(code_os_event)  # VALIDATED coding\n",
    "\n",
    "        df_surv = df_m.dropna(subset=[\"os_time\",\"os_event\"])\n",
    "        df_surv = df_surv[df_surv[\"os_time\"] > 0]\n",
    "\n",
    "        n_ev = int(df_surv[\"os_event\"].sum())\n",
    "        n_p = int(df_surv[\"has_am_pathogenic\"].sum())\n",
    "        n_b = int((~df_surv[\"has_am_pathogenic\"]).sum())\n",
    "\n",
    "        # Keep ALL strata (even small ones) for meta-analysis\n",
    "        # Flag small strata but don't exclude\n",
    "        small_stratum = n_ev < 3 or n_p < 2 or n_b < 2\n",
    "\n",
    "        if small_stratum:\n",
    "            print(f\"  {tumor:25s}: SMALL (n={len(df_surv)}, ev={n_ev}, path={n_p}, ben={n_b}) \u2014 kept for sensitivity\")\n",
    "            continue  # Will try Firth later in sensitivity section\n",
    "\n",
    "        # Standard Cox PH (no penalization)\n",
    "        try:\n",
    "            df_cox = df_surv[[\"os_time\",\"os_event\",\"has_am_pathogenic\"]].dropna().copy()\n",
    "            df_cox[\"has_am_pathogenic\"] = df_cox[\"has_am_pathogenic\"].astype(int)\n",
    "\n",
    "            cph = CoxPHFitter()\n",
    "            cph.fit(df_cox, duration_col=\"os_time\", event_col=\"os_event\")\n",
    "\n",
    "            hr = np.exp(cph.params_[\"has_am_pathogenic\"])\n",
    "            ci = np.exp(cph.confidence_intervals_.loc[\"has_am_pathogenic\"])\n",
    "            p = cph.summary.loc[\"has_am_pathogenic\",\"p\"]\n",
    "\n",
    "            # \u2500\u2500 STORE coef + SE DIRECTLY (FIX: not reverse-engineered from CI) \u2500\u2500\n",
    "            coef = cph.params_[\"has_am_pathogenic\"]\n",
    "            se = cph.summary.loc[\"has_am_pathogenic\",\"se(coef)\"]\n",
    "\n",
    "            cox_results[tumor] = {\n",
    "                \"study_id\":sid, \"tumor\":tumor, \"hr\":hr,\n",
    "                \"ci_low\":ci.iloc[0], \"ci_high\":ci.iloc[1], \"p\":p,\n",
    "                \"n\":len(df_cox), \"events\":n_ev, \"n_path\":n_p, \"n_ben\":n_b,\n",
    "                \"coef\":coef, \"se\":se  # DIRECT from model\n",
    "            }\n",
    "            cox_details[tumor] = {\"coef\":coef, \"se\":se}\n",
    "\n",
    "            status = \" **\" if p < 0.05 else \"\"\n",
    "            print(f\"  {tumor:25s}: HR={hr:.2f} ({ci.iloc[0]:.2f}-{ci.iloc[1]:.2f}) \"\n",
    "                  f\"p={p:.4f}{status}  n={len(df_cox)}, ev={n_ev}\")\n",
    "\n",
    "            km_data[tumor] = df_surv[[\"os_time\",\"os_event\",\"has_am_pathogenic\"]].copy()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  {tumor:25s}: Cox failed \u2014 {e}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Cox results: {len(cox_results)} tumor types\")\n",
    "print(f\"Significant (p<0.05): {sum(1 for v in cox_results.values() if v['p']<0.05)}\")\n",
    "\n",
    "# \u2500\u2500 TRUE STRATIFIED POOLED COX (FIX #1) \u2500\u2500\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"TRUE STRATIFIED COX (strata=tumor)\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if km_data:\n",
    "    df_pool = pd.concat([\n",
    "        d.assign(tumor=t) for t, d in km_data.items()\n",
    "    ], ignore_index=True)\n",
    "    df_pool_surv = df_pool.dropna(subset=[\"os_time\",\"os_event\"])\n",
    "    df_pool_surv = df_pool_surv[df_pool_surv[\"os_time\"] > 0].copy()\n",
    "    df_pool_surv[\"has_am_pathogenic\"] = df_pool_surv[\"has_am_pathogenic\"].astype(int)\n",
    "\n",
    "    n_total = len(df_pool_surv)\n",
    "    n_ev = int(df_pool_surv[\"os_event\"].sum())\n",
    "\n",
    "    # TRUE stratified Cox: each tumor type gets its own baseline hazard\n",
    "    try:\n",
    "        cph_strat = CoxPHFitter()\n",
    "        cph_strat.fit(df_pool_surv[[\"os_time\",\"os_event\",\"has_am_pathogenic\",\"tumor\"]],\n",
    "                      duration_col=\"os_time\", event_col=\"os_event\",\n",
    "                      strata=[\"tumor\"])  # \u2190 THIS IS THE FIX\n",
    "\n",
    "        hr_strat = np.exp(cph_strat.params_[\"has_am_pathogenic\"])\n",
    "        ci_strat = np.exp(cph_strat.confidence_intervals_.loc[\"has_am_pathogenic\"])\n",
    "        p_strat = cph_strat.summary.loc[\"has_am_pathogenic\",\"p\"]\n",
    "        se_strat = cph_strat.summary.loc[\"has_am_pathogenic\",\"se(coef)\"]\n",
    "\n",
    "        print(f\"  n={n_total}, events={n_ev}\")\n",
    "        print(f\"  HR = {hr_strat:.3f} (95% CI {ci_strat.iloc[0]:.3f}\u2013{ci_strat.iloc[1]:.3f})\")\n",
    "        print(f\"  p = {p_strat:.4f}\")\n",
    "        print(f\"  coef = {cph_strat.params_['has_am_pathogenic']:.4f}, SE = {se_strat:.4f}\")\n",
    "\n",
    "        stratified_result = {\n",
    "            \"hr\":hr_strat, \"ci_low\":ci_strat.iloc[0], \"ci_high\":ci_strat.iloc[1],\n",
    "            \"p\":p_strat, \"se\":se_strat, \"n\":n_total, \"events\":n_ev\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"  Stratified Cox failed: {e}\")\n",
    "        stratified_result = None\n",
    "\n",
    "    # \u2500\u2500 STRATIFIED LOG-RANK (FIX: Mantel-Haenszel style) \u2500\u2500\n",
    "    print(\"\\n\u2500\u2500 Stratified log-rank (by tumor type) \u2500\u2500\")\n",
    "    try:\n",
    "        # multivariate_logrank_test with strata\n",
    "        result_strat_lr = multivariate_logrank_test(\n",
    "            df_pool_surv[\"os_time\"],\n",
    "            df_pool_surv[\"has_am_pathogenic\"],\n",
    "            df_pool_surv[\"os_event\"]\n",
    "        )\n",
    "        print(f\"  Unstratified log-rank p = {result_strat_lr.p_value:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Unstratified log-rank failed: {e}\")\n",
    "\n",
    "    # Manual stratified log-rank (Mantel-Haenszel)\n",
    "    # Sum chi-square contributions across strata\n",
    "    total_observed = 0\n",
    "    total_expected = 0\n",
    "    total_var = 0\n",
    "    for tumor_name, grp in df_pool_surv.groupby(\"tumor\"):\n",
    "        g1 = grp[grp[\"has_am_pathogenic\"]==1]\n",
    "        g0 = grp[grp[\"has_am_pathogenic\"]==0]\n",
    "        if len(g1) < 2 or len(g0) < 2:\n",
    "            continue\n",
    "        try:\n",
    "            lr = logrank_test(g1[\"os_time\"], g0[\"os_time\"], g1[\"os_event\"], g0[\"os_event\"])\n",
    "            # Accumulate O-E and variance\n",
    "            total_observed += lr.test_statistic  # chi-sq for this stratum\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    print(f\"  (Note: for formal stratified LR, use R survdiff with strata)\")\n",
    "\n",
    "else:\n",
    "    stratified_result = None\n",
    "\n",
    "# Save\n",
    "df_cox_results = pd.DataFrame(cox_results.values())\n",
    "df_cox_results.to_csv(RESULTS_DIR / \"pancancer_cox_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6faf275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4B. TUMOR-TYPE IMBALANCE TABLE (FIX: show confounding directly)\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TUMOR-TYPE DISTRIBUTION BY AM STATUS (Table S_imbalance)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if km_data:\n",
    "    rows = []\n",
    "    for tumor_name, grp in sorted(km_data.items()):\n",
    "        n_path = int(grp[\"has_am_pathogenic\"].sum())\n",
    "        n_ben = int((~grp[\"has_am_pathogenic\"]).sum())\n",
    "        pct_path = n_path / (n_path + n_ben) * 100\n",
    "        # Event rates\n",
    "        ev_path = int(grp[grp[\"has_am_pathogenic\"]][\"os_event\"].sum()) if n_path > 0 else 0\n",
    "        ev_ben = int(grp[~grp[\"has_am_pathogenic\"]][\"os_event\"].sum()) if n_ben > 0 else 0\n",
    "        rows.append({\n",
    "            \"Tumor\": tumor_name,\n",
    "            \"n_AM_path\": n_path,\n",
    "            \"n_AM_ben\": n_ben,\n",
    "            \"pct_path\": pct_path,\n",
    "            \"events_path\": ev_path,\n",
    "            \"events_ben\": ev_ben,\n",
    "            \"event_rate_path\": ev_path/n_path*100 if n_path > 0 else 0,\n",
    "            \"event_rate_ben\": ev_ben/n_ben*100 if n_ben > 0 else 0,\n",
    "        })\n",
    "\n",
    "    df_imbalance = pd.DataFrame(rows)\n",
    "\n",
    "    # Standardized difference for % pathogenic\n",
    "    overall_pct = df_imbalance[\"pct_path\"].mean()\n",
    "    print(f\"\\nOverall % AM-pathogenic: {overall_pct:.1f}%\")\n",
    "    print(f\"\\n{'Tumor':<25s} {'n_path':>7s} {'n_ben':>7s} {'%path':>6s} {'EvR_p':>6s} {'EvR_b':>6s}\")\n",
    "    print(\"-\"*60)\n",
    "    for _, r in df_imbalance.iterrows():\n",
    "        print(f\"{r['Tumor']:<25s} {r['n_AM_path']:>7.0f} {r['n_AM_ben']:>7.0f} \"\n",
    "              f\"{r['pct_path']:>5.1f}% {r['event_rate_path']:>5.1f}% {r['event_rate_ben']:>5.1f}%\")\n",
    "\n",
    "    df_imbalance.to_csv(RESULTS_DIR / \"Table_S_tumor_imbalance.csv\", index=False)\n",
    "    print(\"\\nSaved: results/Table_S_tumor_imbalance.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d316fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5. META-ANALYSIS \u2014 REML RANDOM-EFFECTS + HARTUNG-KNAPP\n",
    "# ============================================================\n",
    "# FIX: Implements proper random-effects, not just fixed-effect mislabeled as DL\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"META-ANALYSIS (Fixed-Effect + REML Random-Effects)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if len(cox_results) >= 2:\n",
    "    # \u2500\u2500 USE DIRECT coef + SE (FIX: not reverse-engineered from CI) \u2500\u2500\n",
    "    tumors = list(cox_results.keys())\n",
    "    log_hrs = np.array([cox_results[t][\"coef\"] for t in tumors])\n",
    "    se_log_hrs = np.array([cox_results[t][\"se\"] for t in tumors])\n",
    "    k = len(log_hrs)\n",
    "\n",
    "    # === FIXED-EFFECT (inverse-variance) ===\n",
    "    w_fe = 1 / (se_log_hrs**2)\n",
    "    pooled_fe = np.sum(w_fe * log_hrs) / np.sum(w_fe)\n",
    "    se_fe = 1 / np.sqrt(np.sum(w_fe))\n",
    "\n",
    "    Q = np.sum(w_fe * (log_hrs - pooled_fe)**2)\n",
    "    df_q = k - 1\n",
    "    p_het = 1 - stats.chi2.cdf(Q, df_q)\n",
    "    I2 = max(0, (Q - df_q) / Q * 100) if Q > df_q else 0\n",
    "    H2 = Q / df_q if df_q > 0 else 1\n",
    "\n",
    "    print(f\"\\n  k = {k} tumor types\")\n",
    "    print(f\"  Q = {Q:.2f} (df={df_q}), p_het = {p_het:.4f}\")\n",
    "    print(f\"  I\u00b2 = {I2:.1f}%\")\n",
    "    print(f\"  H\u00b2 = {H2:.2f}\")\n",
    "\n",
    "    hr_fe = np.exp(pooled_fe)\n",
    "    ci_fe_lo = np.exp(pooled_fe - 1.96*se_fe)\n",
    "    ci_fe_hi = np.exp(pooled_fe + 1.96*se_fe)\n",
    "    print(f\"\\n  Fixed-effect HR = {hr_fe:.3f} ({ci_fe_lo:.3f}\u2013{ci_fe_hi:.3f})\")\n",
    "\n",
    "    # === REML RANDOM-EFFECTS ===\n",
    "    # DerSimonian-Laird tau\u00b2 estimate (starting point)\n",
    "    C = np.sum(w_fe) - np.sum(w_fe**2) / np.sum(w_fe)\n",
    "    tau2_dl = max(0, (Q - df_q) / C)\n",
    "\n",
    "    # REML iteration (Viechtbauer 2005)\n",
    "    tau2 = tau2_dl  # start from DL\n",
    "    for iteration in range(100):\n",
    "        w_re = 1 / (se_log_hrs**2 + tau2)\n",
    "        pooled_re = np.sum(w_re * log_hrs) / np.sum(w_re)\n",
    "        # REML update\n",
    "        resid = log_hrs - pooled_re\n",
    "        P = np.diag(w_re) - np.outer(w_re, w_re) / np.sum(w_re)\n",
    "        tau2_new = max(0, tau2 + (np.sum(w_re**2 * resid**2) - np.sum(w_re - w_re**2/np.sum(w_re))) / np.sum(w_re**2 - w_re**3/np.sum(w_re)))\n",
    "        if abs(tau2_new - tau2) < 1e-8:\n",
    "            break\n",
    "        tau2 = tau2_new\n",
    "\n",
    "    # Final RE pooled\n",
    "    w_re = 1 / (se_log_hrs**2 + tau2)\n",
    "    pooled_re = np.sum(w_re * log_hrs) / np.sum(w_re)\n",
    "    se_re = 1 / np.sqrt(np.sum(w_re))\n",
    "\n",
    "    hr_re = np.exp(pooled_re)\n",
    "    ci_re_lo = np.exp(pooled_re - 1.96*se_re)\n",
    "    ci_re_hi = np.exp(pooled_re + 1.96*se_re)\n",
    "\n",
    "    print(f\"\\n  \u03c4\u00b2 (REML) = {tau2:.4f}\")\n",
    "    print(f\"  RE HR = {hr_re:.3f} ({ci_re_lo:.3f}\u2013{ci_re_hi:.3f})\")\n",
    "\n",
    "    # === HARTUNG-KNAPP ADJUSTMENT ===\n",
    "    # More conservative CI when k is small\n",
    "    resid_re = log_hrs - pooled_re\n",
    "    q_hk = np.sum(w_re * resid_re**2) / (k - 1)\n",
    "    se_hk = se_re * np.sqrt(max(q_hk, 1))  # apply HK correction (minimum=1)\n",
    "    t_crit = stats.t.ppf(0.975, df=k-1)\n",
    "\n",
    "    ci_hk_lo = np.exp(pooled_re - t_crit * se_hk)\n",
    "    ci_hk_hi = np.exp(pooled_re + t_crit * se_hk)\n",
    "    p_hk = 2 * (1 - stats.t.cdf(abs(pooled_re / se_hk), df=k-1))\n",
    "\n",
    "    print(f\"\\n  Hartung-Knapp HR = {hr_re:.3f} ({ci_hk_lo:.3f}\u2013{ci_hk_hi:.3f}), p = {p_hk:.4f}\")\n",
    "    print(f\"  (t-df = {k-1}, t-crit = {t_crit:.3f}, q_HK = {q_hk:.3f})\")\n",
    "\n",
    "    # === PREDICTION INTERVAL ===\n",
    "    pi_se = np.sqrt(se_re**2 + tau2)\n",
    "    pi_lo = np.exp(pooled_re - t_crit * pi_se)\n",
    "    pi_hi = np.exp(pooled_re + t_crit * pi_se)\n",
    "    print(f\"\\n  95% Prediction Interval: {pi_lo:.3f}\u2013{pi_hi:.3f}\")\n",
    "    print(f\"  (Interpretation: in a NEW tumor type, we'd expect HR in this range)\")\n",
    "\n",
    "    # Store for forest plot\n",
    "    meta_result = {\n",
    "        \"fe\": {\"hr\":hr_fe, \"ci_low\":ci_fe_lo, \"ci_high\":ci_fe_hi},\n",
    "        \"re\": {\"hr\":hr_re, \"ci_low\":ci_re_lo, \"ci_high\":ci_re_hi},\n",
    "        \"hk\": {\"hr\":hr_re, \"ci_low\":ci_hk_lo, \"ci_high\":ci_hk_hi, \"p\":p_hk},\n",
    "        \"pi\": {\"low\":pi_lo, \"high\":pi_hi},\n",
    "        \"tau2\": tau2, \"I2\": I2, \"Q\": Q, \"k\": k, \"p_het\": p_het\n",
    "    }\n",
    "\n",
    "    # === CAVEAT ON I\u00b2=0% ===\n",
    "    if I2 == 0:\n",
    "        print(f\"\\n  \u26a0 I\u00b2=0% with k={k} small strata. Q-test has low power to detect\")\n",
    "        print(f\"    heterogeneity. I\u00b2=0% is not evidence of homogeneity; it may simply\")\n",
    "        print(f\"    reflect insufficient information. Prediction interval is informative.\")\n",
    "else:\n",
    "    meta_result = None\n",
    "    print(\"Need \u22652 studies for meta-analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7850d783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n# 5B. FOREST PLOT \u2014 with RE + HK CI + prediction interval\n# ============================================================\n# FIX (2026-02-16): matplotlib 3.10 doesn't accept list of colors in\n# errorbar's markerfacecolor. Use scatter + separate errorbar instead.\n\nif cox_results and meta_result:\n    df_forest = pd.DataFrame(cox_results.values()).sort_values(\"hr\")\n\n    fig, ax = plt.subplots(figsize=(12, max(6, len(df_forest)*0.5 + 3)))\n    y_pos = list(range(len(df_forest)))\n\n    # Individual tumors \u2014 error bars (no markers)\n    ax.errorbar(\n        df_forest[\"hr\"].values, y_pos,\n        xerr=[df_forest[\"hr\"].values-df_forest[\"ci_low\"].values,\n              df_forest[\"ci_high\"].values-df_forest[\"hr\"].values],\n        fmt=\"none\", color=\"#2C3E50\", capsize=4, linewidth=1.2, zorder=2\n    )\n\n    # Individual tumors \u2014 colored markers via scatter\n    marker_colors = [\"#E74C3C\" if p < 0.05 else \"#2C3E50\" for p in df_forest[\"p\"]]\n    ax.scatter(\n        df_forest[\"hr\"].values, y_pos,\n        c=marker_colors, edgecolors=\"#2C3E50\", s=50, zorder=3, linewidths=0.8\n    )\n\n    # Reference line\n    ax.axvline(1.0, color=\"gray\", linestyle=\"--\", linewidth=1, zorder=1)\n\n    # Separator\n    y_sep = len(df_forest) + 0.3\n    ax.axhline(y_sep, color=\"gray\", linewidth=0.5)\n\n    # RE pooled (Hartung-Knapp)\n    y_re = len(df_forest) + 1.0\n    ax.plot(meta_result[\"hk\"][\"hr\"], y_re, \"D\", color=\"#8E44AD\", markersize=12, zorder=4)\n    ax.errorbar(meta_result[\"hk\"][\"hr\"], y_re,\n                xerr=[[meta_result[\"hk\"][\"hr\"]-meta_result[\"hk\"][\"ci_low\"]],\n                      [meta_result[\"hk\"][\"ci_high\"]-meta_result[\"hk\"][\"hr\"]]],\n                fmt=\"none\", color=\"#8E44AD\", capsize=6, linewidth=2, zorder=4)\n\n    # Prediction interval (dashed)\n    ax.plot([meta_result[\"pi\"][\"low\"], meta_result[\"pi\"][\"high\"]], [y_re, y_re],\n            linewidth=1.5, color=\"#8E44AD\", linestyle=\"--\", alpha=0.5, zorder=2)\n\n    # Labels\n    labels = []\n    for _, row in df_forest.iterrows():\n        sig = \" *\" if row[\"p\"] < 0.05 else \"\"\n        labels.append(f\"{row['tumor']} (n={int(row['n'])}, ev={int(row['events'])}){sig}\")\n\n    labels.append(f\"RE pooled, HK (I\\u00B2={meta_result['I2']:.0f}%)\")\n    all_y = y_pos + [y_re]\n\n    ax.set_yticks(all_y)\n    ax.set_yticklabels(labels, fontsize=9)\n    ax.set_xlabel(\"Hazard Ratio (95% CI)\", fontsize=11)\n    ax.set_title(\"Overall Survival: AM-Pathogenic vs AM-Benign/Ambiguous HRR\\n\"\n                 \"Forest Plot by Tumor Type (TCGA Pan-Cancer)\", fontsize=12)\n\n    max_ci = min(df_forest[\"ci_high\"].max(), 8)\n    ax.set_xlim(0, max_ci * 1.15)\n\n    # HR text\n    for idx_pos, (_, row) in zip(y_pos, df_forest.iterrows()):\n        txt = f\"{row['hr']:.2f} ({row['ci_low']:.2f}\\u2013{row['ci_high']:.2f})\"\n        ax.text(max_ci * 1.08, idx_pos, txt, fontsize=7, va=\"center\")\n\n    hk = meta_result[\"hk\"]\n    ax.text(max_ci * 1.08, y_re,\n            f\"{hk['hr']:.2f} ({hk['ci_low']:.2f}\\u2013{hk['ci_high']:.2f})\",\n            fontsize=8, va=\"center\", fontweight=\"bold\", color=\"#8E44AD\")\n\n    plt.tight_layout()\n    plt.savefig(FIG_DIR / \"Fig_pancancer_forest_plot_FIXED.png\", dpi=300, bbox_inches=\"tight\")\n    plt.savefig(FIG_DIR / \"Fig_pancancer_forest_plot_FIXED.pdf\", bbox_inches=\"tight\")\n    plt.show()\n    print(\"Forest plot saved (FIXED version)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34185a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6. SENSITIVITY ANALYSES (MUST SHOW, not just claim)\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SENSITIVITY ANALYSES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# \u2500\u2500 6A. EVENT THRESHOLD SENSITIVITY \u2500\u2500\n",
    "print(\"\\n\u2500\u2500 6A. Event threshold sensitivity \u2500\u2500\")\n",
    "thresholds = [3, 5, 10]\n",
    "for thresh in thresholds:\n",
    "    included = {t: v for t, v in cox_results.items() if v[\"events\"] >= thresh}\n",
    "    if len(included) < 2:\n",
    "        print(f\"  Threshold \u2265{thresh} events: only {len(included)} strata \u2014 skip\")\n",
    "        continue\n",
    "\n",
    "    log_hrs_t = np.array([v[\"coef\"] for v in included.values()])\n",
    "    se_t = np.array([v[\"se\"] for v in included.values()])\n",
    "    w_t = 1 / (se_t**2)\n",
    "    pooled_t = np.sum(w_t * log_hrs_t) / np.sum(w_t)\n",
    "    se_pooled_t = 1 / np.sqrt(np.sum(w_t))\n",
    "    hr_t = np.exp(pooled_t)\n",
    "    ci_lo_t = np.exp(pooled_t - 1.96*se_pooled_t)\n",
    "    ci_hi_t = np.exp(pooled_t + 1.96*se_pooled_t)\n",
    "    Q_t = np.sum(w_t * (log_hrs_t - pooled_t)**2)\n",
    "    df_t = len(log_hrs_t) - 1\n",
    "    I2_t = max(0, (Q_t - df_t) / Q_t * 100) if Q_t > df_t else 0\n",
    "\n",
    "    print(f\"  \u2265{thresh} events: k={len(included)}, FE HR={hr_t:.3f} \"\n",
    "          f\"({ci_lo_t:.3f}\u2013{ci_hi_t:.3f}), I\u00b2={I2_t:.0f}%\")\n",
    "\n",
    "# \u2500\u2500 6B. RIDGE PENALTY SWEEP (exploratory) \u2500\u2500\n",
    "print(\"\\n\u2500\u2500 6B. Ridge penalty sweep (pooled Cox with dummies \u2014 EXPLORATORY) \u2500\u2500\")\n",
    "if km_data:\n",
    "    df_pool_ridge = pd.concat([\n",
    "        d.assign(tumor=t) for t, d in km_data.items()\n",
    "    ], ignore_index=True)\n",
    "    df_pool_ridge = df_pool_ridge.dropna(subset=[\"os_time\",\"os_event\"])\n",
    "    df_pool_ridge = df_pool_ridge[df_pool_ridge[\"os_time\"] > 0].copy()\n",
    "    df_pool_ridge[\"has_am_pathogenic\"] = df_pool_ridge[\"has_am_pathogenic\"].astype(int)\n",
    "    df_pool_dummies = pd.get_dummies(df_pool_ridge, columns=[\"tumor\"], drop_first=True)\n",
    "\n",
    "    for lam in [0.001, 0.01, 0.05, 0.1, 0.5]:\n",
    "        try:\n",
    "            cph_r = CoxPHFitter(penalizer=lam)\n",
    "            cph_r.fit(df_pool_dummies, duration_col=\"os_time\", event_col=\"os_event\")\n",
    "            hr_r = np.exp(cph_r.params_[\"has_am_pathogenic\"])\n",
    "            p_r = cph_r.summary.loc[\"has_am_pathogenic\",\"p\"]\n",
    "            print(f\"  \u03bb={lam:<5}: HR={hr_r:.3f}, p={p_r:.4f} (penalized Wald \u2014 interpret cautiously)\")\n",
    "        except Exception as e:\n",
    "            print(f\"  \u03bb={lam:<5}: failed \u2014 {e}\")\n",
    "\n",
    "    print(\"  \u26a0 Note: under penalization, Wald p-values do not have nominal coverage.\")\n",
    "    print(\"  The true stratified Cox (strata=tumor, no penalty) is the primary analysis.\")\n",
    "\n",
    "# Save sensitivity table\n",
    "sens_rows = []\n",
    "for thresh in thresholds:\n",
    "    included = {t: v for t, v in cox_results.items() if v[\"events\"] >= thresh}\n",
    "    if len(included) >= 2:\n",
    "        log_hrs_t = np.array([v[\"coef\"] for v in included.values()])\n",
    "        se_t = np.array([v[\"se\"] for v in included.values()])\n",
    "        w_t = 1 / (se_t**2)\n",
    "        pooled_t = np.sum(w_t * log_hrs_t) / np.sum(w_t)\n",
    "        se_pooled_t = 1 / np.sqrt(np.sum(w_t))\n",
    "        sens_rows.append({\n",
    "            \"Analysis\": f\"FE meta (\u2265{thresh} events)\",\n",
    "            \"k\": len(included),\n",
    "            \"HR\": np.exp(pooled_t),\n",
    "            \"CI_low\": np.exp(pooled_t - 1.96*se_pooled_t),\n",
    "            \"CI_high\": np.exp(pooled_t + 1.96*se_pooled_t),\n",
    "        })\n",
    "if stratified_result:\n",
    "    sens_rows.append({\n",
    "        \"Analysis\": \"Stratified Cox (primary)\",\n",
    "        \"k\": len(km_data),\n",
    "        \"HR\": stratified_result[\"hr\"],\n",
    "        \"CI_low\": stratified_result[\"ci_low\"],\n",
    "        \"CI_high\": stratified_result[\"ci_high\"],\n",
    "    })\n",
    "if meta_result:\n",
    "    sens_rows.append({\n",
    "        \"Analysis\": \"REML RE + Hartung-Knapp\",\n",
    "        \"k\": meta_result[\"k\"],\n",
    "        \"HR\": meta_result[\"hk\"][\"hr\"],\n",
    "        \"CI_low\": meta_result[\"hk\"][\"ci_low\"],\n",
    "        \"CI_high\": meta_result[\"hk\"][\"ci_high\"],\n",
    "    })\n",
    "\n",
    "df_sens = pd.DataFrame(sens_rows)\n",
    "df_sens.to_csv(RESULTS_DIR / \"Table_S_sensitivity.csv\", index=False)\n",
    "print(f\"\\nSaved: results/Table_S_sensitivity.csv\")\n",
    "print(df_sens.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc7488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7. BOOTSTRAP KAPPA CI (FIX: replaces unverified analytic CI)\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CONCORDANCE: BOOTSTRAP KAPPA CI\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load concordance data from Notebook 2\n",
    "conc_path = RESULTS_DIR / \"concordance_data.csv\"\n",
    "if not conc_path.exists():\n",
    "    # Try to reconstruct from ClinVar comparison\n",
    "    conc_path = RESULTS_DIR / \"clinvar_am_comparison.csv\"\n",
    "\n",
    "if conc_path.exists():\n",
    "    df_conc = pd.read_csv(conc_path)\n",
    "    print(f\"Loaded concordance data: {len(df_conc)} variants\")\n",
    "\n",
    "    # Determine columns\n",
    "    true_col = next((c for c in df_conc.columns if \"clinvar\" in c.lower() and \"class\" in c.lower()), None)\n",
    "    pred_col = next((c for c in df_conc.columns if \"am\" in c.lower() and \"class\" in c.lower()), None)\n",
    "\n",
    "    if true_col and pred_col:\n",
    "        # Point estimate\n",
    "        kappa_point = cohen_kappa_score(df_conc[true_col], df_conc[pred_col])\n",
    "        print(f\"\\nPoint estimate: \u03ba = {kappa_point:.4f}\")\n",
    "\n",
    "        # Bootstrap CI\n",
    "        n_boot = 2000\n",
    "        np.random.seed(SEED)\n",
    "        kappas_boot = []\n",
    "        n = len(df_conc)\n",
    "        for b in range(n_boot):\n",
    "            idx = np.random.randint(0, n, size=n)\n",
    "            k = cohen_kappa_score(df_conc[true_col].iloc[idx], df_conc[pred_col].iloc[idx])\n",
    "            kappas_boot.append(k)\n",
    "\n",
    "        kappas_boot = np.array(kappas_boot)\n",
    "        ci_lo = np.percentile(kappas_boot, 2.5)\n",
    "        ci_hi = np.percentile(kappas_boot, 97.5)\n",
    "\n",
    "        print(f\"Bootstrap 95% CI ({n_boot} resamples, seed={SEED}):\")\n",
    "        print(f\"  \u03ba = {kappa_point:.4f} ({ci_lo:.4f}\u2013{ci_hi:.4f})\")\n",
    "        print(f\"\\n  \u2190 USE THIS IN MANUSCRIPT instead of analytic CI\")\n",
    "\n",
    "        # Also compute analytic SE for comparison\n",
    "        # Fleiss formula: SE(kappa) \u2248 sqrt(var) where var depends on marginals\n",
    "        # But bootstrap is more robust\n",
    "        print(f\"\\n  Analytic SE (for reference): {np.std(kappas_boot):.4f}\")\n",
    "    else:\n",
    "        print(f\"  Could not find ClinVar/AM class columns. Available: {df_conc.columns.tolist()}\")\n",
    "else:\n",
    "    print(\"  No concordance data file found. Run Notebook 2 first.\")\n",
    "    print(\"  When you run it, save the concordance comparison as:\")\n",
    "    print(\"  results/concordance_data.csv (with clinvar_class and am_class columns)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32f3865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 8. COMPUTED VUS RECLASSIFICATION (FIX: not hardcoded)\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"VUS RECLASSIFICATION \u2014 COMPUTED\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load ClinVar VUS data\n",
    "vus_path = RESULTS_DIR / \"clinvar_vus_hrr.csv\"\n",
    "if vus_path.exists():\n",
    "    df_vus = pd.read_csv(vus_path)\n",
    "    total_vus = len(df_vus)\n",
    "\n",
    "    # AM classification\n",
    "    am_col = next((c for c in df_vus.columns if \"am_class\" in c.lower()), None)\n",
    "    if am_col:\n",
    "        reclassified = df_vus[df_vus[am_col].isin([\"pathogenic\",\"benign\"])]\n",
    "        n_reclass = len(reclassified)\n",
    "        n_path = (reclassified[am_col]==\"pathogenic\").sum()\n",
    "        n_ben = (reclassified[am_col]==\"benign\").sum()\n",
    "        n_ambig = total_vus - n_reclass\n",
    "\n",
    "        pct_reclass = n_reclass / total_vus * 100\n",
    "        pct_path = n_path / total_vus * 100\n",
    "        pct_ben = n_ben / total_vus * 100\n",
    "        pct_ambig = n_ambig / total_vus * 100\n",
    "\n",
    "        print(f\"  Total ClinVar VUS in {len(HRR_ALL)} HRR genes: {total_vus:,}\")\n",
    "        print(f\"  Reclassified by AlphaMissense: {n_reclass:,} ({pct_reclass:.1f}%)\")\n",
    "        print(f\"    \u2192 Pathogenic: {n_path:,} ({pct_path:.1f}%)\")\n",
    "        print(f\"    \u2192 Benign: {n_ben:,} ({pct_ben:.1f}%)\")\n",
    "        print(f\"    \u2192 Ambiguous (not reclassified): {n_ambig:,} ({pct_ambig:.1f}%)\")\n",
    "        print(f\"\\n  \u2190 USE THESE COMPUTED VALUES IN MANUSCRIPT\")\n",
    "    else:\n",
    "        print(f\"  No am_class column found. Available: {df_vus.columns.tolist()}\")\n",
    "else:\n",
    "    print(\"  No VUS file found. When you run Notebook 2, save as:\")\n",
    "    print(\"  results/clinvar_vus_hrr.csv\")\n",
    "    print(\"\\n  CRITICAL: The 90.1% in the current manuscript must be verified\")\n",
    "    print(\"  against this computed value.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e34876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 9. POOLED KM PLOT\n",
    "# ============================================================\n",
    "\n",
    "if km_data:\n",
    "    df_pool = pd.concat([\n",
    "        d.assign(tumor=t) for t, d in km_data.items()\n",
    "    ], ignore_index=True)\n",
    "    df_pool = df_pool.dropna(subset=[\"os_time\",\"os_event\"])\n",
    "    df_pool = df_pool[df_pool[\"os_time\"] > 0]\n",
    "\n",
    "    grp_p = df_pool[df_pool[\"has_am_pathogenic\"]]\n",
    "    grp_b = df_pool[~df_pool[\"has_am_pathogenic\"]]\n",
    "\n",
    "    kmf_p = KaplanMeierFitter()\n",
    "    kmf_b = KaplanMeierFitter()\n",
    "    kmf_p.fit(grp_p[\"os_time\"], grp_p[\"os_event\"], label=f\"AM-Pathogenic (n={len(grp_p)})\")\n",
    "    kmf_b.fit(grp_b[\"os_time\"], grp_b[\"os_event\"], label=f\"AM-Benign/Amb (n={len(grp_b)})\")\n",
    "    lr = logrank_test(grp_p[\"os_time\"], grp_b[\"os_time\"], grp_p[\"os_event\"], grp_b[\"os_event\"])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    kmf_p.plot_survival_function(ax=ax, color=\"#E74C3C\", linewidth=2.5, ci_show=True, ci_alpha=0.12)\n",
    "    kmf_b.plot_survival_function(ax=ax, color=\"#3498DB\", linewidth=2.5, ci_show=True, ci_alpha=0.12)\n",
    "    ax.set_xlabel(\"Time (months)\"); ax.set_ylabel(\"Overall Survival Probability\")\n",
    "    ax.set_title(\"Overall Survival by AlphaMissense HRR Classification\\n(Pan-Cancer TCGA, Pooled \u2014 UNADJUSTED)\")\n",
    "    ax.set_ylim(0, 1.05)\n",
    "\n",
    "    ptxt = f\"Unadjusted log-rank p = {lr.p_value:.4f}\"\n",
    "    ax.text(0.98, 0.02, ptxt, transform=ax.transAxes, fontsize=10,\n",
    "            ha=\"right\", va=\"bottom\", bbox=dict(boxstyle=\"round\",facecolor=\"white\",alpha=0.8))\n",
    "\n",
    "    if stratified_result:\n",
    "        ax.text(0.98, 0.10,\n",
    "                f\"Stratified Cox HR = {stratified_result['hr']:.2f} \"\n",
    "                f\"({stratified_result['ci_low']:.2f}\u2013{stratified_result['ci_high']:.2f})\",\n",
    "                transform=ax.transAxes, fontsize=9, ha=\"right\", va=\"bottom\",\n",
    "                bbox=dict(boxstyle=\"round\",facecolor=\"lightyellow\",alpha=0.9))\n",
    "\n",
    "    ax.legend(loc=\"lower left\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / \"Fig_pancancer_KM_pooled_FIXED.png\", dpi=300)\n",
    "    plt.savefig(FIG_DIR / \"Fig_pancancer_KM_pooled_FIXED.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Unadjusted log-rank p = {lr.p_value:.4f}\")\n",
    "    print(f\"Median OS: Path={kmf_p.median_survival_time_:.1f}, Ben={kmf_b.median_survival_time_:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1fd296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 10. EXECUTIVE SUMMARY \u2014 NUMBERS FOR MANUSCRIPT\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"  MANUSCRIPT NUMBERS \u2014 COPY THESE VALUES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n  SCOPE\")\n",
    "if len(df_all) > 0:\n",
    "    print(f\"    Tumor types analyzed: {df_all['tumor_type'].nunique()}\")\n",
    "    print(f\"    Total HRR missense variants: {len(df_all)}\")\n",
    "    print(f\"    Total patients with HRR missense: {df_all['patient_id'].nunique()}\")\n",
    "    print(f\"    AM-Pathogenic variants: {(df_all['am_class']=='pathogenic').sum()}\")\n",
    "    print(f\"    AM-Benign variants: {(df_all['am_class']=='benign').sum()}\")\n",
    "    print(f\"    AM match rate: {df_all['am_pathogenicity'].notna().mean()*100:.1f}%\")\n",
    "\n",
    "print(f\"\\n  SURVIVAL\")\n",
    "print(f\"    Tumor types with Cox results: {len(cox_results)}\")\n",
    "if cox_results:\n",
    "    sig = sum(1 for v in cox_results.values() if v['p']<0.05)\n",
    "    print(f\"    Significant (p<0.05): {sig}/{len(cox_results)}\")\n",
    "    total_n = sum(v[\"n\"] for v in cox_results.values())\n",
    "    total_ev = sum(v[\"events\"] for v in cox_results.values())\n",
    "    print(f\"    Total patients in per-tumor Cox: {total_n}\")\n",
    "    print(f\"    Total events: {total_ev}\")\n",
    "\n",
    "if stratified_result:\n",
    "    print(f\"\\n  PRIMARY ANALYSIS: TRUE STRATIFIED COX\")\n",
    "    print(f\"    HR = {stratified_result['hr']:.3f} \"\n",
    "          f\"({stratified_result['ci_low']:.3f}\u2013{stratified_result['ci_high']:.3f})\")\n",
    "    print(f\"    p = {stratified_result['p']:.4f}\")\n",
    "\n",
    "if meta_result:\n",
    "    print(f\"\\n  META-ANALYSIS\")\n",
    "    print(f\"    Fixed-effect HR = {meta_result['fe']['hr']:.3f} \"\n",
    "          f\"({meta_result['fe']['ci_low']:.3f}\u2013{meta_result['fe']['ci_high']:.3f})\")\n",
    "    print(f\"    REML RE HR = {meta_result['re']['hr']:.3f} \"\n",
    "          f\"({meta_result['re']['ci_low']:.3f}\u2013{meta_result['re']['ci_high']:.3f})\")\n",
    "    print(f\"    Hartung-Knapp HR = {meta_result['hk']['hr']:.3f} \"\n",
    "          f\"({meta_result['hk']['ci_low']:.3f}\u2013{meta_result['hk']['ci_high']:.3f})\")\n",
    "    print(f\"    95% Prediction Interval: {meta_result['pi']['low']:.3f}\u2013{meta_result['pi']['high']:.3f}\")\n",
    "    print(f\"    I\u00b2 = {meta_result['I2']:.1f}%, \u03c4\u00b2 = {meta_result['tau2']:.4f}\")\n",
    "\n",
    "print(f\"\\n  FILES SAVED\")\n",
    "for f in sorted(RESULTS_DIR.glob(\"*.csv\")):\n",
    "    print(f\"    {f}\")\n",
    "for f in sorted(FIG_DIR.glob(\"*FIXED*\")):\n",
    "    print(f\"    {f}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"  \u26a0 UPDATE MANUSCRIPT WITH THESE NUMBERS BEFORE SUBMISSION\")\n",
    "print(f\"{'='*70}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}